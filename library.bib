@article{1993,
  title = {Wavelet Theory and Its Applications},
  year = {1993},
  journal = {Choice Reviews Online},
  volume = {30},
  number = {09},
  pages = {30-5031-30-5031},
  doi = {10.5860/choice.30-5031},
  file = {/home/wouter/Zotero/storage/KNB36HMU/Unknown - 1993 - Wavelet theory and its applications.pdf}
}

@techreport{620952003,
  title = {Electric Cables-{{Calculations}} for Current Ratings-{{Finite}} Element Method},
  author = {62095, CEI/IEC/TR},
  year = {2003},
  file = {/home/wouter/Zotero/storage/IJ53IYKJ/62095 - 2003 - Electric cables-Calculations for current ratings-Finite element method.pdf}
}

@article{adcock2021,
  title = {Learning High-Dimensional {{Hilbert-valued}} Functions with Deep Neural Networks from Limited Data},
  author = {Adcock, Ben and Brugiapaglia, Simone and Dexter, Nick and Moraga, Sebastian},
  year = {2021},
  journal = {CEUR Workshop Proceedings},
  volume = {2964},
  pages = {1--36},
  abstract = {Deep learning (DL) techniques have been successful in many applications, with the most impressive results achieved on problems where the dimension of the underlying data or problem domain is large. In this paper, we describe recent results on both scalar- and Hilbert-valued function approximation via Deep Neural Networks (DNN). This problem arises in many engineering problems, in particular those involving the solution of parametric Partial Differential Equations (PDEs). Such problems are challenging, since point-wise samples are expensive to acquire, and the function is usually high-dimensional. First, we consider a DNN architecture and training procedure for which the resulting DNN is guaranteed to perform as well as current best-in-class schemes for holomorphic, scalar- or Hilbert-valued functions based on polynomial approximations. This result demonstrates the efficacy of DL for this problem, and makes explicit the effect of all sources of error, including discretization error of the underlying Hilbert space and measurement error. Second, we provide several numerical results illustrating the performance of DNNs on both real-valued functions and solutions of parametric PDEs. These results suggest that better approximations can be achieved through careful tuning of the DNN architecture and training algorithm.},
  file = {/home/wouter/Zotero/storage/N5JUPNCH/Adcock et al. - 2021 - Learning high-dimensional Hilbert-valued functions with deep neural networks from limited data.pdf}
}

@book{adcock2022,
  title = {Sparse Polynomial Approximation of High-Dimensional Functions},
  author = {Adcock, Ben and Brugiapaglia, Simone and Webster, Clayton G},
  year = {2022},
  volume = {25},
  publisher = {SIAM}
}

@misc{addy2025,
  title = {Lengthscale-Informed Sparse Grids for Kernel Methods in High Dimensions},
  author = {Addy, Elliot J. and Latz, Jonas and Teckentrup, Aretha L.},
  year = {2025},
  month = jun,
  number = {arXiv:2506.07797},
  eprint = {2506.07797},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2506.07797},
  urldate = {2025-06-19},
  abstract = {Kernel interpolation, especially in the context of Gaussian process emulation, is a widely used technique in surrogate modelling, where the goal is to cheaply approximate an input-output map using a limited number of function evaluations. However, in high-dimensional settings, such methods typically suffer from the curse of dimensionality; the number of required evaluations to achieve a fixed approximation error grows exponentially with the input dimension. To overcome this, a common technique used in high-dimensional approximation methods, such as quasi-Monte Carlo and sparse grids, is to exploit functional anisotropy: the idea that some input dimensions are more 'sensitive' than others. In doing so, such methods can significantly reduce the dimension dependence in the error. In this work, we propose a generalisation of sparse grid methods that incorporates a form of anisotropy encoded by the lengthscale parameter in Mat{\textbackslash}'ern kernels. We derive error bounds and perform numerical experiments that show that our approach enables effective emulation over arbitrarily high dimensions for functions exhibiting sufficient anisotropy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis},
  file = {/home/wouter/Zotero/storage/AQIVLG5A/Addy et al. - 2025 - Lengthscale-informed sparse grids for kernel methods in high dimensions.pdf;/home/wouter/Zotero/storage/NNLF5QFJ/2506.html}
}

@incollection{aggarwal1973,
  title = {On the {{Surprising Behavior}} of {{Distance Metrics}} in {{High Dimensional Space}}},
  booktitle = {Database {{Theory}} -- {{ICDT}} 2001},
  author = {Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
  year = {1973},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {420--435},
  publisher = {Springer},
  abstract = {Abstract. In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a efficiency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the di- stance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lk norm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhat- tan distance metric (L1 norm) is consistently more preferable than the Euclidean distance metric (L2 norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lk norm to fractional distance metrics. We show that the fractional distance metric provides more mea- ningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm},
  isbn = {3-540-41456-8},
  file = {/home/wouter/Zotero/storage/YQUE35C8/Aggarwal et al. - 1973 - On the Surprising Behavior of Distance Metrics in High Dimensional Space.pdf}
}

@article{akinola2014,
  title = {The Calculation of the Distance to a Nearby Defective Matrix},
  author = {Akinola, R. O. and Freitag, M. A. and Spence, A.},
  year = {2014},
  journal = {Numerical Linear Algebra with Applications},
  volume = {21},
  number = {3},
  pages = {403--414},
  doi = {10.1002/nla.1888},
  abstract = {The distance of a matrix to a nearby defective matrix is an important classical problem in numerical linear algebra, as it determines how sensitive or ill-conditioned an eigenvalue decomposition of a matrix is. The concept has been discussed throughout the history of numerical linear algebra, and the problem of computing the nearest defective matrix first appeared in Wilkinsons famous book on the algebraic eigenvalue problem. In this paper, a new fast algorithm for the computation of the distance of a matrix to a nearby defective matrix is presented. The problem is formulated following Alam and Bora introduced in (2005) and reduces to finding when a parameter-dependent matrix is singular subject to a constraint. The solution is achieved by an extension of the implicit determinant method introduced by Spence and Poulton in (2005). Numerical results for several examples illustrate the performance of the algorithm. {\copyright} 2013 John Wiley \& Sons, Ltd.},
  keywords = {Nearest defective matrix,Newton's method,Sensitivity of eigenproblem},
  file = {/home/wouter/Zotero/storage/PA2Q9ZH4/Akinola, Freitag, Spence - 2014 - The calculation of the distance to a nearby defective matrix.pdf}
}

@article{alessandrini2001,
  title = {Univalent {$\sigma$}-{{Harmonic Mappings}}:},
  shorttitle = {Univalent {$\sigma$}-{{Harmonic Mappings}}},
  author = {Alessandrini, Giovanni and Nesi, Vincenzo},
  year = {2001},
  month = jun,
  journal = {Archive for Rational Mechanics and Analysis},
  volume = {158},
  number = {2},
  pages = {155--171},
  issn = {0003-9527},
  doi = {10.1007/PL00004242},
  urldate = {2025-06-16},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/C6G5A2IE/Alessandrini and Nesi - 2001 - Univalent σ-Harmonic Mappings.pdf}
}

@article{alessandrini2021,
  title = {Globally Diffeomorphic \$\${\textbackslash}sigma\$\$-Harmonic Mappings},
  author = {Alessandrini, Giovanni and Nesi, Vincenzo},
  year = {2021},
  month = aug,
  journal = {Annali di Matematica Pura ed Applicata (1923 -)},
  volume = {200},
  number = {4},
  pages = {1625--1635},
  issn = {0373-3114, 1618-1891},
  doi = {10.1007/s10231-020-01050-w},
  urldate = {2025-06-16},
  abstract = {Abstract                            Given a two-dimensional mapping               U               whose components solve a divergence structure elliptic equation, we give necessary and sufficient conditions on the boundary so that               U               is a global diffeomorphism.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/3DRUJ69S/Alessandrini and Nesi - 2021 - Globally diffeomorphic $$sigma$$-harmonic mappings.pdf}
}

@book{alkalah1998,
  title = {Barriers and {{Challenges}} in {{Computational Fluid Dynamics}}},
  author = {Alkalah, Cynthia},
  editor = {Venkatakrishnan, V. and Salas, Manuel D. and Chakravarthy, Sukumar R.},
  year = {1998},
  series = {{{ICASE}}/{{LaRC Interdisciplinary Series}} in {{Science}} and {{Engineering}}},
  volume = {6},
  pages = {23},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-94-011-5169-6},
  abstract = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell ``S'' karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
  isbn = {978-94-010-6173-5},
  keywords = {agreements,legal position,legal subject,people with visual impairment},
  file = {/home/wouter/Zotero/storage/AJBYKCNG/Alkalah - 1998 - Barriers and Challenges in Computational Fluid Dynamics.pdf}
}

@article{alnaes2014,
  title = {Unified Form Language},
  author = {Aln{\ae}s, Martin S. and Logg, Anders and {\O}lgaard, Kristian B. and Rognes, Marie E. and Wells, Garth N.},
  year = {2014},
  month = feb,
  journal = {ACM Transactions on Mathematical Software},
  volume = {40},
  number = {2},
  pages = {1--37},
  doi = {10.1145/2566630},
  abstract = {We present the Unified Form Language (UFL), which is a domain-specific language for representing weak formulations of partial differential equations with a view to numerical approximation. Features of UFL include support for variational forms and functionals, automatic differentiation of forms and expressions, arbitrary function space hierarchies for multifield problems, general differential operators and flexible tensor algebra. With these features, UFL has been used to effortlessly express finite element methods for complex systems of partial differential equations in near-mathematical notation, resulting in compact, intuitive and readable programs. We present in this work the language and its construction. An implementation of UFL is freely available as an open-source software library. The library generates abstract syntax tree representations of variational problems, which are used by other software libraries to generate concrete low-level implementations. Some application examples are presented and libraries that support UFL are highlighted.},
  keywords = {Algorithmic differentiation,Automatic functional differentiation,Discretization,Domain specific language,DSEL,DSL,Einstein notation,Embedded language,FEM,Finite element method,Functional,Implicit summation,Index notation,Mixed element,Partial differential equation,PDE,Symbolic differentiation,Tensor algebra,Weak form,Weak formulation},
  file = {/home/wouter/Zotero/storage/MFVTFA89/Alnæs et al. - 2014 - Unified form language.pdf}
}

@article{alnaes2014a,
  title = {Unified Form Language: {{A}} Domain-Specific Language for Weak Formulations of Partial Differential Equations},
  shorttitle = {Unified Form Language},
  author = {Aln{\ae}s, Martin S. and Logg, Anders and {\O}lgaard, Kristian B. and Rognes, Marie E. and Wells, Garth N.},
  year = {2014},
  month = feb,
  journal = {ACM Transactions on Mathematical Software},
  volume = {40},
  number = {2},
  pages = {1--37},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/2566630},
  urldate = {2024-09-30},
  abstract = {We present the Unified Form Language (UFL), which is a domain-specific language for representing weak formulations of partial differential equations with a view to numerical approximation. Features of UFL include support for variational forms and functionals, automatic differentiation of forms and expressions, arbitrary function space hierarchies for multifield problems, general differential operators and flexible tensor algebra. With these features, UFL has been used to effortlessly express finite element methods for complex systems of partial differential equations in near-mathematical notation, resulting in compact, intuitive and readable programs. We present in this work the language and its construction. An implementation of UFL is freely available as an open-source software library. The library generates abstract syntax tree representations of variational problems, which are used by other software libraries to generate concrete low-level implementations. Some application examples are presented and libraries that support UFL are highlighted.},
  langid = {english}
}

@inproceedings{amyot2006,
  title = {Stochastic Modeling of Tumor Induced Angiogenesis in a Heterogeneous Medium, the Extracellular Matrix},
  booktitle = {2006 {{International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  author = {Amyot, Franck and Small, Alex and Gandjbakhche, Amir H},
  year = {2006},
  pages = {3146--3149}
}

@article{amyot2006a,
  title = {Stochastic Modeling of Tumor Induced Angiogenesis in a Heterogeneous Medium, the Extracellular Matrix},
  author = {Amyot, Franck and Small, Alex and Gandjbakhche, Amir H.},
  year = {2006},
  journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings},
  pages = {3146--3149},
  publisher = {IEEE},
  issn = {1424400325},
  doi = {10.1109/IEMBS.2006.260358},
  abstract = {Angiogenesis, the formation of blood vessels, is a process whereby capillary sprout are formed in response to external stimuli. We model the tumor induced angiogenesis on keys events such of migratory response of endothelial cells to tumor angiogenic factors and the local cell interaction with the extracellular matrix (ECM). We consider the ECM medium as a statistically inhomogeneous two-phase random medium. Numerical simulations of the model are presented. Using this model, we will compare the influence of ECM distribution on vascular network formation. By developing mathematical models of angiogenesis, we hope to provide a deeper insight into the mechanisms underlying angiogenesis. {\copyright} 2006 IEEE.},
  keywords = {Angiogenesis,Apoptosis,Cell migration,Percolation,Vascular network},
  file = {/home/wouter/Zotero/storage/42EL73GG/Amyot, Small, Gandjbakhche - 2006 - Stochastic modeling of tumor induced angiogenesis in a heterogeneous medium, the extracellular matri.pdf}
}

@article{arcos2021,
  title = {The {{Hilbert}} Transform},
  author = {Arcos, Edisson Arley and Castillo, Ren{\'e} Erlin},
  year = {2021},
  journal = {Surveys in Mathematics and its Applications},
  volume = {16},
  pages = {149--192},
  doi = {10.1201/b19222-27},
  abstract = {The Hilbert transform is essentially the only singular operator in one dimension. This undoubtedly make it one of the most important linear operator in harmonic analysis. This is an expository paper about the Hilbert transform aimed to anyone that has even scratched the surface of the theory of integration, and functional analysis as well as a basic rudiments of Fourier transform. We provide a systematic (Although by no means complete) account of the basic results on the Hilbert transform. We want to point out that we present a friendly proof of the remarkable result due to Stein and Weiss (1959) (see [24]) and we use it combined with the Cavalieri principle to obtain an exact formula for the Lp-norm of H({$\chi$}E).},
  keywords = {Cauchy principal value,Fourier transform,Hilbert transform},
  file = {/home/wouter/Zotero/storage/BFUC5HNA/Arcos, Castillo - 2021 - The Hilbert transform.pdf}
}

@article{arsenovic2011,
  title = {H{\"o}lder Continuity of Harmonic Quasiconformal Mappings},
  author = {Arsenovi{\'c}, Milo{\v s} and Manojlovi{\'c}, Vesna and Vuorinen, Matti},
  year = {2011},
  journal = {Journal of Inequalities and Applications},
  volume = {2011},
  pages = {3--7},
  doi = {10.1186/1029-242X-2011-37},
  abstract = {We prove that for harmonic quasiconformal mappings {$\alpha$}-H{\"o}lder continuity on the boundary implies {$\alpha$}-H{\"o}lder continuity of the map itself. Our result holds for the class of uniformly perfect bounded domains, in fact we can allow that a portion of the boundary is thin in the sense of capacity. The problem for general bounded domains remains open. {\copyright} 2011 Arsenovi{\'e}{\'c} et al; licensee Springer.},
  keywords = {H?o?lder continuity,Harmonic mappings,Quasi-conformal maps},
  file = {/home/wouter/Zotero/storage/3KJ8YT8N/Arsenović, Manojlović, Vuorinen - 2011 - Hölder continuity of harmonic quasiconformal mappings.pdf}
}

@article{asarrakos2002,
  title = {Numerical Range: (In) a Matrix Nutshell},
  author = {Asarrakos, P J and Tsatsomeros, M J},
  year = {2002},
  journal = {Preprint},
  pages = {13--13},
  file = {/home/wouter/Zotero/storage/MWA3CUSL/Asarrakos, Tsatsomeros - 2002 - Numerical range (in) a matrix nutshell.pdf}
}

@inproceedings{astudillo2022,
  title = {Thinking inside the Box: {{A}} Tutorial on Grey-Box {{Bayesian}} Optimization},
  shorttitle = {Thinking inside the Box},
  booktitle = {{{WSC}} '21: {{Proceedings}} of the {{Winter Simulation Conference}}},
  author = {Astudillo, Raul and Frazier, Peter I.},
  year = {2022},
  month = jan,
  doi = {10.1109/WSC52266.2021.9715343},
  urldate = {2024-08-27},
  abstract = {Bayesian optimization (BO) is a framework for global optimization of expensive-to-evaluate objective functions. Classical BO methods assume that the objective function is a black box. However, internal information about objective function computation is often available. For example, when optimizing a manufacturing line's throughput with simulation, we observe the number of parts waiting at each workstation, in addition to the overall throughput. Recent BO methods leverage such internal information to dramatically improve performance. We call these "grey-box" BO methods because they treat objective computation as partially observable and even modifiable, blending the black-box approach with so-called "white-box" first-principles knowledge of objective function computation. This tutorial describes these methods, focusing on BO of composite objective functions, where one can observe and selectively evaluate individual constituents that feed into the overall objective; and multi-fidelity BO, where one can evaluate cheaper approximations of the objective function by varying parameters of the evaluation oracle.},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/LQPF26JM/Astudillo and Frazier - 2022 - Thinking inside the box A tutorial on grey-box Bayesian optimization.pdf;/home/wouter/Zotero/storage/2H532AVS/2201.html}
}

@article{aulisa2022,
  title = {A {{Computational Study}} of {{Preconditioning Techniques}} for the {{Stochastic Diffusion Equation With Lognormal Coefficient}}},
  author = {Aulisa, Eugenio and Capodaglio, Giacomo and Ke, Guoyi},
  year = {2022},
  journal = {International Journal of Numerical Analysis and Modeling},
  volume = {19},
  number = {2-3},
  pages = {220--236},
  abstract = {We present a computational study of several preconditioning techniques for the GM-RES algorithm applied to the stochastic diffusion equation with a lognormal coefficient discretized with the stochastic Galerkin method. The clear block structure of the system matrix arising from this type of discretization motivates the analysis of preconditioners designed according to a field-splitting strategy of the stochastic variables. This approach is inspired by a similar procedure used within the framework of physics based preconditioners for deterministic problems, and its application to stochastic PDEs represents the main novelty of this work. Our numerical investigation highlights the superior properties of the field-split type preconditioners over other existing strategies in terms of computational time and stochastic parameter dependence.},
  keywords = {field-split,geometric multigrid,GMRES,lognormal coefficient,preconditioning,Stochastic diffusion equation,stochastic Galerkin method},
  file = {/home/wouter/Zotero/storage/NC2C9UUA/Aulisa, Capodaglio, Ke - 2022 - a Computational Study of Preconditioning Techniques for the Stochastic Diffusion Equation With Lognormal.pdf}
}

@book{axler2546,
  title = {Harmonic {{Function Theory}}},
  author = {Axler, Sheldon and Bourdon, Paul and Ramey, Wade},
  year = {2546},
  isbn = {978-1-4899-1186-5},
  file = {/home/wouter/Zotero/storage/PSDNK72B/Axler, Bourdon, Ramey - 2546 - Harmonic Function Theory.pdf}
}

@article{aylwin2022,
  title = {Multilevel {{Domain Uncertainty Quantification}} in {{Computational Electromagnetics}}},
  author = {Aylwin, Rub{\'e}n and {Jerez-Hanckes}, Carlos and Schwab, Christoph and Zech, Jakob},
  year = {2022},
  number = {2020},
  pages = {1--31},
  abstract = {We continue our study [Domain Uncertainty Quantification in Computational Electromagnetics, JUQ (2020), 8:301--341] of the numerical approximation of time-harmonic electromagnetic fields for the Maxwell lossy cavity problem for uncertain geometries. We adopt the same affine-parametric shape parametrization framework, mapping the physical domains to a nominal polygonal domain with piecewise smooth maps. The regularity of the pullback solutions on the nominal domain is characterized in piecewise Sobolev spaces. We prove error convergence rates and optimize the algorithmic steering of parameters for edge-element discretizations in the nominal domain combined with: (a) multilevel Monte Carlo sampling, and (b) multilevel, sparse-grid quadrature for computing the expectation of the solutions with respect to uncertain domain ensembles. In addition, we analyze sparse-grid interpolation to compute surrogates of the domain-to-solution mappings. All calculations are performed on the polyhedral nominal domain, which enables the use of standard simplicial finite element meshes. We provide a rigorous fully discrete error analysis and show, in all cases, that dimension-independent algebraic convergence is achieved. For the multilevel sparse-grid quadrature methods, we prove higher order convergence rates which are free from the so-called curse of dimensionality, i.e. independent of the number of parameters used to parametrize the admissible shapes. Numerical experiments confirm our theoretical results and verify the superiority of the sparse-grid methods.},
  keywords = {and phrases,computational electromagnetics,finite elements,shape,uncertainty quantification},
  file = {/home/wouter/Zotero/storage/CKMASFWP/Aylwin et al. - 2022 - Multilevel Domain Uncertainty Quantification in Computational Electromagnetics.pdf}
}

@article{babuska1997,
  title = {Is the {{Pollution Effect}} of the {{FEM Avoidable}} for the {{Helmholtz Equation Considering High Wave Numbers}}?},
  author = {Babu{\v s}ka, Ivo M. and Sauter, Stefan A.},
  year = {1997},
  month = dec,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {34},
  number = {6},
  pages = {2392--2423},
  issn = {0036-1429, 1095-7170},
  doi = {10.1137/S0036142994269186},
  urldate = {2025-03-13},
  langid = {english},
  file = {/home/wouter/Zotero/storage/AKGDNFYG/Babuška and Sauter - 1997 - Is the Pollution Effect of the FEM Avoidable for the Helmholtz Equation Considering High Wave Number.pdf}
}

@article{babuska2003,
  title = {Effects of Uncertainties in the Domain on the Solution of {{Dirichlet}} Boundary Value Problems},
  author = {Babu{\v s}ka, Ivo and Chleboun, Jan},
  year = {2003},
  journal = {Numerische Mathematik},
  volume = {93},
  number = {4},
  pages = {583--610},
  doi = {10.1007/s002110200400},
  abstract = {A domain with possibly non-Lipschitz boundary is defined as a limit of monotonically expanding or shrinking domains with Lipschitz boundary. A uniquely solvable Dirichlet boundary value problem (DBVP) is defined on each of the Lipschitz domains and the limit of these solutions is investigated. The limit function also solves a DBVP on the limit domain but the problem can depend on the sequences of domains if the limit domain is unstable with respect to the DBVP. The core of the paper consists in estimates of the difference between the respective solutions of the DBVP on two close domains, one of which is Lipschitz and the other can be unstable. Estimates for starshaped as well as rather general domains are derived. Their numerical evaluation is possible and can be done in different ways.},
  keywords = {and phrases,elliptic equation,neumann boundary condition,uncertainty},
  file = {/home/wouter/Zotero/storage/FU5NGJCC/Babuška, Chleboun - 2003 - Effects of uncertainties in the domain on the solution of Dirichlet boundary value problems.pdf}
}

@article{babuska2004,
  title = {Galerkin Finite Element Approximations of Stochastic Elliptic Partial Differential Equations},
  author = {Babu{\v s}ka, Ivo and Tempone, Ra{\'u}l and Zouraris, Georgios E.},
  year = {2004},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {42},
  number = {2},
  pages = {800--825},
  doi = {10.1137/S0036142902418680},
  abstract = {We describe and analyze two numerical methods for a linear elliptic problem with stochastic coefficients and homogeneous Dirichlet boundary conditions. Here the aim of the computations is to approximate statistical moments of the solution, and, in particular, we give a priori error estimates for the computation of the expected value of the solution. The first method generates independent identically distributed approximations of the solution by sampling the coefficients of the equation and using a standard Galerkin finite element variational formulation. The Monte Carlo method then uses these approximations to compute corresponding sample averages. The second method is based on a finite dimensional approximation of the stochastic coefficients, turning the original stochastic problem into a deterministic parametric elliptic problem. A Galerkin finite element method, of either the h- or p-version, then approximates the corresponding deterministic solution, yielding approximations of the desired statistics. We present a priori error estimates and include a comparison of the computational work required by each numerical approximation to achieve a given accuracy. This comparison suggests intuitive conditions for an optimal selection of the numerical approximation. {\copyright} 2004 Society for Industrial and Applied Mathematics.},
  keywords = {Error estimates,Expected value,Finite elements,K  h-version,Karhunen-Loeve expansion,Monte Carlo method,P  h-version,Perturbation estimates,Stochastic elliptic equation},
  file = {/home/wouter/Zotero/storage/CD4NAP3T/Babuška, Tempone, Zouraris - 2004 - Galerkin finite element approximations of stochastic elliptic partial differential equations.pdf}
}

@article{babuska2014,
  title = {A {{Stochastic Collocation Method}} for {{Delay Differential Equations}} with {{Random Input}}},
  author = {Babu{\v s}ka, Ivo and Nobile, Fabio and Tempone, Ra{\'u}l},
  year = {2014},
  journal = {Advances in Applied Mathematics and Mechanics},
  volume = {6},
  number = {4},
  pages = {403--418},
  doi = {10.4208/aamm.2012.m38},
  abstract = {In this work, we concern with the numerical approach for delay differential equations with random coefficients. We first show that the exact solution of the problem considered admits good regularity in the random space, provided that the given data satisfy some reasonable assumptions. A stochastic collocation method is proposed to approximate the solution in the random space, and we use the Legendre spectral collocation method to solve the resulting deterministic delay differential equations. Convergence property of the proposedmethod is analyzed. It is shown that the numerical method yields the familiar exponential order of convergence in both the random space and the time space. Numerical examples are given to illustrate the theoretical results.},
  keywords = {Delay differential equations,Legendre spectral method,Sparse grid,Stochastic collocation},
  file = {/home/wouter/Zotero/storage/QMGBMH5H/Babuška, Nobile, Tempone - 2014 - A Stochastic Collocation Method for Delay Differential Equations with Random Input.pdf}
}

@article{bachmayr2017,
  title = {Fully Discrete Approximation of Parametric and Stochastic Elliptic {{PDES}}},
  author = {Bachmayr, Markus and Cohen, Albert and Dung, Dinh and Schwab, Christoph},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {55},
  number = {5},
  pages = {2151--2186},
  doi = {10.1137/17M111626X},
  abstract = {It has recently been demonstrated that locality of spatial supports in the parametrization of coefficients in elliptic PDEs can lead to improved convergence rates of sparse polynomial expansions of the corresponding parameter-dependent solutions. These results by themselves do not yield practically realizable approximations, since they do not cover the approximation of the arising expansion coefficients, which are functions of the spatial variable. In this work, we study the combined spatial and parametric approximability for elliptic PDEs with affine or lognormal parametrizations of the diffusion coefficients and corresponding Taylor, Jacobi, and Hermite expansions, to obtain fully discrete approximations. Our analysis yields convergence rates of the fully discrete approximation in terms of the total number of degrees of freedom. The main vehicle consists of 'p summability results for the coefficient sequences measured in higher-order Hilbertian Sobolev norms. We also discuss similar results for non-Hilbertian Sobolev norms which arise naturally when using adaptive spatial discretizations.},
  keywords = {Affine coefficients,Finite elements,Lognormal coefficients,Nterm approximation,Sparse tensor product polynomials,Wavelets},
  file = {/home/wouter/Zotero/storage/4TCJNJYB/Bachmayr et al. - 2017 - Fully discrete approximation of parametric and stochastic elliptic PDES.pdf}
}

@article{bachmayr2017a,
  title = {Sparse Polynomial Approximation of Parametric Elliptic {{PDEs}}. {{Part I}}: {{Affine}} Coefficients},
  author = {Bachmayr, Markus and Cohen, Albert and Migliorati, Giovanni},
  year = {2017},
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  volume = {51},
  number = {1},
  pages = {321--339},
  doi = {10.1051/m2an/2016045},
  abstract = {We consider the linear elliptic equation ?div(a{$\delta$}u) = f on some bounded domain D, where a has the affine form a = a(y) = {\=a}+ {$\sigma$}j{$\geq$}1 yj{$\psi$}j for some parameter vector y = (yj)j{$\geq$}1 {\texteuro} U = [?1, 1]N. We study the summability properties of polynomial expansions of the solution map y {$\rightarrow$} u(y) {\texteuro} V := H10 (D). We consider both Taylor series and Legendre series. Previous results [A. Cohen, R. DeVore and C. Schwab, Anal. Appl. 9 (2011) 11-47] show that, under a uniform ellipticity assuption, for any 0 {$<$} p {$<$} 1, the {$\ell$}p summability of the ({\textbar}{\textbar}{$\psi$}j{\textbar}{\textbar}L{$\infty$})j{$\geq$}1 implies the {$\ell$}p summability of the V-norms of the Taylor or Legendre coefficients. Such results ensure convergence rates n?s of polynomial approximations obtained by best n-Term truncation of such series, with s = 1p ?1 in L {$\infty$} (U, V ) or s = 1p ? 1 2 in L2(U, V ). In this paper we considerably improve these results by providing sufficient conditions of {$\ell$}p summability of the coefficient V-norm sequences expressed in terms of the pointwise summability properties of the ({\textbar}{$\psi$}j {\textbar})j{$\geq$}1. The approach in the present paper strongly differs from that of [A. Cohen, R. DeVore and C. Schwab, Anal. Appl. 9 (2011) 11-47], which is based on individual estimates of the coefficient norms obtained by the Cauchy formula applied to a holomorphic extension of the solution map. Here, we use weighted summability estimates, obtained by real-variable arguments. While the obtained results imply those of [7] as a particular case, they lead to a refined analysis which takes into account the amount of overlap between the supports of the {$\psi$}j . For instance, in the case of disjoint supports, these results imply that for all 0 {$<$} p {$<$} 2, the {$\ell$}p summability of the coefficient V-norm sequences follows from the weaker assumption that ({\textbar}{\textbar}{$\psi\vert\vert$}L{$\infty$})j{$\geq$}1 is {$\ell$}q summable for q = q(p) := 2p 2-p {$>$} p. We provide a simple analytic example showing that this result is in general optimal and illustrate our findings by numerical experiments. The analysis in the present paper applies to other types of linear PDEs with similar affine parametrization of the coefficients, and to more general Jacobi polynomial expansions.},
  keywords = {Affine coefficients,Legendre polynomials,N-Term approximation,Parametric PDEs},
  file = {/home/wouter/Zotero/storage/RQ886V6D/Bachmayr, Cohen, Migliorati - 2017 - Sparse polynomial approximation of parametric elliptic PDEs. Part I Affine coefficients.pdf}
}

@article{bachmayr2017b,
  title = {Sparse Polynomial Approximation of Parametric Elliptic Pdes. Part {{II}}: {{Lognormal}} Coefficients},
  author = {Bachmayr, Markus and Cohen, Albert and DeVore, Ronald and Migliorati, Giovanni},
  year = {2017},
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  volume = {51},
  number = {1},
  pages = {341--363},
  doi = {10.1051/m2an/2016051},
  abstract = {We consider the linear elliptic equation ?div(aVu) = f on some bounded domain D, where a has the form a = exp(b) with b a random function defined as b(y) = {$\sigma$}j{$\geq$}1 yj{$\psi$}j where y = (yj) {\texteuro} RN are i.i.d. standard scalar Gaussian variables and ({$\psi$}j )j{$\geq$}1 is a given sequence of functions in L {$\infty$} (D). We study the summability properties of Hermite-Type expansions of the solution map y {$\rightarrow$}u(y) {\textbar}{\textbar} V := H1 0 (D), that is, expansions of the form u(y) = {$\sigma$}F u-H-(y), where Hp (y) = {\textbar}{\textbar} j{$\geq$}1 H?j (yj) are the tensorized Hermite polynomials indexed by the set F of finitely supported sequences of nonnegative integers. Previous results [V.H. Hoang and C. Schwab, M3AS 24 (2014) 797-826] have demonstrated that, for any 0 1 2 , which still represents an improvement over the condition in [V.H. Hoang and C. Schwab, M3AS 24 (2014) 797?826]. We also explore intermediate cases of functions with local yet overlapping supports, such as wavelet bases. One interesting observation following from our analysis is that for certain relevant examples, the use of the Karhunen-Loeve basis for the representation of b might be suboptimal compared to other representations, in terms of the resulting summability properties of ({\textbar}{\textbar}uv{\textbar}{\textbar}V )F{\texteuro}. While we focus on the diffusion equation, our analysis applies to other type of linear PDEs with similar lognormal dependence in the coefficients.},
  keywords = {Hermite polynomials,lognormal coefficients,n-Term approximation,Stochastic PDEs},
  file = {/home/wouter/Zotero/storage/TTJUC47R/Bachmayr et al. - 2017 - Sparse polynomial approximation of parametric elliptic pdes. part II Lognormal coefficients.pdf}
}

@article{bachmayr2018,
  title = {Representations of {{Gaussian Random Fields}} and {{Approximation}} of {{Elliptic PDEs}} with {{Lognormal Coefficients}}},
  author = {Bachmayr, Markus and Cohen, Albert and Migliorati, Giovanni},
  year = {2018},
  journal = {Journal of Fourier Analysis and Applications},
  volume = {24},
  number = {3},
  pages = {621--649},
  publisher = {Springer US},
  doi = {10.1007/s00041-017-9539-5},
  abstract = {Approximation of elliptic PDEs with random diffusion coefficients typically requires a representation of the diffusion field in terms of a sequence y=(yj)j{$\geq$}1 of scalar random variables. One may then apply high-dimensional approximation methods to the solution map y{$\mapsto$} u(y). Although Karhunen--Lo{\`e}ve representations are commonly used, it was recently shown, in the relevant case of lognormal diffusion fields, that multilevel-type expansions may yield better approximation rates. Motivated by these results, we construct wavelet-type representations of stationary Gaussian random fields defined on arbitrary bounded domains. The size and localization properties of these wavelets are studied, and used to obtain polynomial approximation results for the related elliptic PDE which outperform those achievable when using Karhunen--Lo{\`e}ve representations. Our construction is based on a periodic extension of the stationary random field, and the expansion on the domain is then obtained by simple restriction. This makes the approach easily applicable even when the computational domain of the PDE has a complicated geometry. In particular, we apply this construction to the class of Gaussian processes defined by the family of Mat{\'e}rn covariances. The proposed periodic continuation technique has other relevant applications such as fast simulation of trajectories. It can be regarded as a continuous analog of circulant embedding techniques introduced for Toeplitz matrices. One of its specific features is that the rate of decay of the eigenvalues of the covariance operator of the periodized process provably matches that of the Fourier transform of the covariance function of the original process.},
  keywords = {Gaussian random fields,Karhunen-Loeve expansions,Lognormal diffusion problems,Periodic continuation,Wavelets},
  file = {/home/wouter/Zotero/storage/K5MIUJTC/Bachmayr, Cohen, Migliorati - 2018 - Representations of Gaussian Random Fields and Approximation of Elliptic PDEs with Lognormal Coeffic.pdf}
}

@article{bachmayr2021,
  title = {An Adaptive Stochastic {{Galerkin}} Method Based on Multilevel Expansions of Random Fields: {{Convergence}} and Optimality},
  author = {Bachmayr, Markus and Voulis, Igor},
  year = {2021},
  pages = {1--35},
  abstract = {The subject of this work is a new stochastic Galerkin method for second-order elliptic partial differential equations with random diffusion coefficients. It combines operator compression in the stochastic variables with tree-based spline wavelet approximation in the spatial variables. Relying on a multilevel expansion of the given random diffusion coefficient, the method is shown to achieve optimal computational complexity up to a logarithmic factor. In contrast to existing results, this holds in particular when the achievable convergence rate is limited by the regularity of the random field, rather than by the spatial approximation order. The convergence and complexity estimates are illustrated by numerical experiments.},
  keywords = {35j25,35r60,41a10,41a25,41a63,42c10,65d99,a posteriori error estimation,A posteriori error estimation,adaptive methods,Adaptive methods,complexity analysis,Complexity analysis,equations,mathematics subject classification,method,parameter-dependent elliptic partial differential,Parameter-dependent elliptic partial differential,stochastic galerkin,Stochastic Galerkin method},
  file = {/home/wouter/Zotero/storage/FWXG67G7/Bachmayr, Voulis - 2021 - An adaptive stochastic Galerkin method based on multilevel expansions of random fields Convergence and optimal.pdf;/home/wouter/Zotero/storage/RAAUP3A2/Bachmayr, Voulis - 2022 - An adaptive stochastic Galerkin method based on multilevel expansions of random fields Convergence and optimal.pdf}
}

@misc{bachmayr2025,
  title = {Adaptive Stochastic {{Galerkin}} Finite Element Methods: {{Optimality}} and Non-Affine Coefficients},
  shorttitle = {Adaptive Stochastic {{Galerkin}} Finite Element Methods},
  author = {Bachmayr, Markus and Eisenmann, Henrik and Voulis, Igor},
  year = {2025},
  month = mar,
  number = {arXiv:2503.18704},
  eprint = {2503.18704},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.18704},
  urldate = {2025-06-03},
  abstract = {Near-optimal computational complexity of an adaptive stochastic Galerkin method with independently refined spatial meshes for elliptic partial differential equations is shown. The method takes advantage of multilevel structure in expansions of random diffusion coefficients and combines operator compression in the stochastic variables with error estimation using finite element frames in space. A new operator compression strategy is introduced for nonlinear coefficient expansions, such as diffusion coefficients with log-affine structure.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis},
  file = {/home/wouter/Zotero/storage/893J9I4P/Bachmayr et al. - 2025 - Adaptive stochastic Galerkin finite element methods Optimality and non-affine coefficients.pdf;/home/wouter/Zotero/storage/RZ5F2W9S/2503.html}
}

@article{baglama1998,
  title = {Adaptively {{Preconditioned GMRES Algorithms}}},
  author = {Baglama, J. and Calvetti, D. and Golub, G. H. and Reichel, L.},
  year = {1998},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {20},
  number = {1},
  pages = {243--269},
  doi = {10.1137/S1064827596305258},
  file = {/home/wouter/Zotero/storage/U4MV2WZ8/Baglama et al. - 1998 - Adaptively Preconditioned GMRES Algorithms.pdf}
}

@article{bai2024,
  title = {Gaussian Processes for {{Bayesian}} Inverse Problems Associated with Linear Partial Differential Equations},
  author = {Bai, Tianming and Teckentrup, Aretha L. and Zygalakis, Konstantinos C.},
  year = {2024},
  month = aug,
  journal = {Statistics and Computing},
  volume = {34},
  number = {4},
  pages = {139},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-024-10452-2},
  urldate = {2025-04-30},
  abstract = {Abstract             This work is concerned with the use of Gaussian surrogate models for Bayesian inverse problems associated with linear partial differential equations. A particular focus is on the regime where only a small amount of training data is available. In this regime the type of Gaussian prior used is of critical importance with respect to how well the surrogate model will perform in terms of Bayesian inversion. We extend the framework of Raissi et. al. (2017) to construct PDE-informed Gaussian priors that we then use to construct different approximate posteriors. A number of different numerical experiments illustrate the superiority of the PDE-informed Gaussian priors over more traditional priors.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/H8WFP7JT/Bai et al. - 2024 - Gaussian processes for Bayesian inverse problems associated with linear partial differential equatio.pdf}
}

@inproceedings{baker1999,
  title = {Dynamic Adaptation for Deforming Tetrahedral Meshes},
  booktitle = {14th {{Computational Fluid Dynamics Conference}}},
  author = {Baker, Timothy and Cavallo, Peter},
  year = {1999},
  month = nov,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  address = {Norfolk,VA,U.S.A.},
  doi = {10.2514/6.1999-3253},
  urldate = {2025-04-28},
  langid = {english}
}

@article{balder1996,
  title = {The Solution of Multidimensional Real {{Helmholtz}} Equations on Sparse Grids},
  author = {Balder, Robert and Zenger, Christoph},
  year = {1996},
  month = may,
  journal = {SIAM Journal on Scientific Computing},
  volume = {17},
  number = {3},
  pages = {631--646},
  doi = {10.1137/S1064827593247035},
  abstract = {Sparse grids provide a very efficient method for the multilinear approximation of functions, especially in higher-dimensional spaces. In the d-dimensional space, the nodal multilinear basis on a grid with mesh size h = 2-n consists of O(2nd) basis functions and leads to an L\_2-error of order O(4-n) and an H\_1-error of order O(2-n). With sparse grids we get an L\_2-error of order O(4-nnd-1) and an H\_1-error of order O(2-n) with only O(2nnd-1) basis functions, if the function u fulfills the condition {$\partial$}2d/{$\partial$}x12{$\partial$}x22{$\cdots\partial$}xd2 u {$<$} {$\infty$}. Therefore, we can achieve much more accurate approximations with the same amount of storage. A data structure for the sparse grid representation of functions defined on cubes of arbitrary dimension and a finite element approach for the Helmholtz equation with sparse grid functions are introduced. Special emphasis is taken in the development of an efficient algorithm for the multiplication with the stiffness matrix. With an appropriate preconditioned conjugate gradient method (cg-method), the linear systems can be solved efficiently. Numerical experiments are presented for Helmholtz equations and eigenvalue problems for the Laplacian in two and three dimensions, and for a six-dimensional Poisson problem. The results support the assertion that the L\_2-error bounds for the sparse-grid approximation are also valid for sparse grid finite element solutions of elliptic differential equations. Problems with nonsmooth solutions are treated with adaptive sparse grids.},
  keywords = {Helmholtz equation,Hierarchical finite elements,Sparse grids},
  file = {/home/wouter/Zotero/storage/JCCBHPB9/Balder, Zenger - 1996 - The solution of multidimensional real Helmholtz equations on sparse grids.pdf}
}

@article{ballio2004,
  title = {Convergence Assessment of Numerical {{Monte Carlo}} Simulations in Groundwater Hydrology},
  author = {Ballio, Francesco and Guadagnini, Alberto},
  year = {2004},
  month = apr,
  journal = {Water Resources Research},
  volume = {40},
  number = {4},
  pages = {2003WR002876},
  issn = {0043-1397, 1944-7973},
  doi = {10.1029/2003WR002876},
  urldate = {2025-04-15},
  abstract = {Numerical Monte Carlo simulation is considered to be one of the main tools to be used in groundwater hydrology (1) to quantify the uncertainty in the flow predictions due to imperfect knowledge of aquifer architecture, hydraulic parameters, and forcing terms or (2) to assess the reliability of approximated moment-based equations for flow and/or transport. While the Monte Carlo framework is conceptually straightforward and very flexible, it is recognized as lacking well-established convergence criteria. Here we propose a methodology for convergence analysis of Monte Carlo simulations and therefore for the reliability assessment of the inferred statistical moments. The methodology, based on simple rules of statistical inference, is described with reference to a typical groundwater flow problem and can be extended to different application fields.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/home/wouter/Zotero/storage/EPNLSS47/Ballio and Guadagnini - 2004 - Convergence assessment of numerical Monte Carlo simulations in groundwater hydrology.pdf}
}

@misc{baratta2023,
  title = {{{DOLFINx}}: {{The}} next Generation {{FEniCS}} Problem Solving Environment},
  shorttitle = {{{DOLFINx}}},
  author = {Baratta, Igor A. and Dean, Joseph P. and Dokken, J{\o}rgen S. and Habera, Michal and Hale, Jack S. and Richardson, Chris N. and Rognes, Marie E. and Scroggs, Matthew W. and Sime, Nathan and Wells, Garth N.},
  year = {2023},
  month = dec,
  publisher = {Zenodo},
  doi = {10.5281/ZENODO.10447666},
  urldate = {2024-09-30},
  abstract = {DOLFINx is the next generation problem solving environment from the~FEniCS Project; it provides an expressive and performant environment~for solving partial differential equations using the finite element~method. We present the modern design principles that underpin the~DOLFINx library, and describe approaches used in DOLFINx that preserve~the high level of mathematical abstraction associated with FEniCS~Project libraries, yet support extensibility and specialized~customization. At the core of DOLFINx is a data- and function-oriented~design, in contrast with the object-oriented design of more~traditional libraries. We argue that this novel design approach leads~to a compact and maintainable library, which is flexible in use and~makes possible the creation of high performance programs in different~languages.},
  archiveprefix = {Zenodo},
  copyright = {Creative Commons Attribution 4.0 International},
  langid = {english}
}

@book{barbu2020,
  title = {Monte {{Carlo}} Methods},
  author = {Barbu, Adrian G. and Zhu, Song-Chun},
  year = {2020},
  series = {Springer {{eBook Collection}}},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-13-2971-5},
  isbn = {978-981-13-2971-5},
  langid = {english}
}

@article{bardenet2013,
  title = {Collaborative Hyperparameter Tuning},
  author = {Bardenet, R{\'e}mi and Brendel, M{\'a}ty{\'a}s and K{\'e}gl, Bal{\'a}zs and Sebag, Mich{\`e}le},
  year = {2013},
  journal = {Proceedings of the 30th International Conference on Machine Learning},
  volume = {28},
  pages = {199--207},
  file = {/home/wouter/Zotero/storage/CGWZJXV2/Bardenet et al. - Collaborative hyperparameter tuning.pdf}
}

@article{barfoot2020,
  title = {Exactly Sparse {{Gaussian}} Variational Inference with Application to Derivative-Free Batch Nonlinear State Estimation},
  author = {Barfoot, Timothy D. and Forbes, James R. and Yoon, David J.},
  year = {2020},
  journal = {International Journal of Robotics Research},
  volume = {39},
  number = {13},
  pages = {1473--1502},
  doi = {10.1177/0278364920937608},
  abstract = {We present a Gaussian variational inference (GVI) technique that can be applied to large-scale nonlinear batch state estimation problems. The main contribution is to show how to fit both the mean and (inverse) covariance of a Gaussian to the posterior efficiently, by exploiting factorization of the joint likelihood of the state and data, as is common in practical problems. This is different than maximum a posteriori (MAP) estimation, which seeks the point estimate for the state that maximizes the posterior (i.e., the mode). The proposed exactly sparse Gaussian variational inference (ESGVI) technique stores the inverse covariance matrix, which is typically very sparse (e.g., block-tridiagonal for classic state estimation). We show that the only blocks of the (dense) covariance matrix that are required during the calculations correspond to the non-zero blocks of the inverse covariance matrix, and further show how to calculate these blocks efficiently in the general GVI problem. ESGVI operates iteratively, and while we can use analytical derivatives at each iteration, Gaussian cubature can be substituted, thereby producing an efficient derivative-free batch formulation. ESGVI simplifies to precisely the Rauch--Tung--Striebel (RTS) smoother in the batch linear estimation case, but goes beyond the `extended' RTS smoother in the nonlinear case because it finds the best-fit Gaussian (mean and covariance), not the MAP point estimate. We demonstrate the technique on controlled simulation problems and a batch nonlinear simultaneous localization and mapping problem with an experimental dataset.},
  keywords = {derivative-free state estimation,exact sparsity,Gaussian variational inference},
  file = {/home/wouter/Zotero/storage/5DHSHTK8/Barfoot, Forbes, Yoon - 2020 - Exactly sparse Gaussian variational inference with application to derivative-free batch nonlinear state e.pdf}
}

@article{barfoot2020a,
  title = {Multivariate {{Gaussian Variational Inference}} by {{Natural Gradient Descent}}},
  author = {Barfoot, Timothy D.},
  year = {2020},
  number = {2},
  abstract = {This short note reviews so-called Natural Gradient Descent (NGD) for multivariate Gaussians. The Fisher Information Matrix (FIM) is derived for several different parameterizations of Gaussians. Careful attention is paid to the symmetric nature of the covariance matrix when calculating derivatives. We show that there are some advantages to choosing a parameterization comprising the mean and inverse covariance matrix and provide a simple NGD update that accounts for the symmetric (and sparse) nature of the inverse covariance matrix.},
  file = {/home/wouter/Zotero/storage/W7XYVDL9/Barfoot - 2020 - Multivariate Gaussian Variational Inference by Natural Gradient Descent.pdf}
}

@article{barnes2009,
  title = {Comparing Experiment and Theory in Plasmonics},
  author = {Barnes, W. L.},
  year = {2009},
  journal = {Journal of Optics A: Pure and Applied Optics},
  volume = {11},
  number = {11},
  doi = {10.1088/1464-4258/11/11/114002},
  abstract = {Progress in plasmonics has been greatly assisted by developments in experimental techniques and in numerical modelling. In this paper I look at some of the difficulties that emerge when comparisons are made between experiment and theory. Using four examples I illustrate what some of these difficulties are, from the perspective of both experiment and of modelling. Although there are many aspects to consider, two seem to be of particular concern at the time of writing; identifying the most appropriate relative permittivity (dielectric function) to describe the optical response of the metals used, and how best to make space discrete when using numerical models that rely on this approach. {\copyright} 2009 IOP Publishing Ltd.},
  keywords = {Experiment numerical simulation plasmonics theory},
  file = {/home/wouter/Zotero/storage/WTBSWXRI/Barnes - 2009 - Comparing experiment and theory in plasmonics.pdf}
}

@article{barth2011,
  title = {Multi-Level {{Monte Carlo Finite Element}} Method for Elliptic {{PDEs}} with Stochastic Coefficients},
  author = {Barth, Andrea and Schwab, Christoph and Zollinger, Nathaniel},
  year = {2011},
  journal = {Numerische Mathematik},
  volume = {119},
  number = {1},
  pages = {123--161},
  doi = {10.1007/s00211-011-0377-0},
  abstract = {In Monte Carlo methods quadrupling the sample size halves the error. In simulations of stochastic partial differential equations (SPDEs), the total work is the sample size times the solution cost of an instance of the partial differential equation. A Multi-level Monte Carlo method is introduced which allows, in certain cases, to reduce the overall work to that of the discretization of one instance of the deterministic PDE. The model problem is an elliptic equation with stochastic coefficients. Multi-level Monte Carlo errors and work estimates are given both for the mean of the solutions and for higher moments. The overall complexity of computing mean fields as well as k-point correlations of the random solution is proved to be of log-linear complexity in the number of unknowns of a single Multi-level solve of the deterministic elliptic problem. Numerical examples complete the theoretical analysis. {\copyright} 2011 Springer-Verlag.},
  file = {/home/wouter/Zotero/storage/L9IZQXQU/Barth, Schwab, Zollinger - 2011 - Multi-level Monte Carlo Finite Element method for elliptic PDEs with stochastic coefficients.pdf}
}

@article{barth2012,
  title = {Simulation of Stochastic Partial Differential Equations Using Finite Element Methods},
  author = {Barth, Andrea and Lang, Annika},
  year = {2012},
  journal = {Stochastics},
  volume = {84},
  number = {2-3},
  pages = {217--231},
  doi = {10.1080/17442508.2010.523466},
  abstract = {These notes describe numerical issues that may arise when implementing a simulation method for a stochastic partial differential equation (SPDE). It is shown that an additional approximation of the noise does not necessarily affect the order of convergence of a discretization method for a SPDE driven by L{\'e}vy noise. Furthermore, finite element methods are explicitly given and simulations are done. In statistical tests, it is shown that the simulations obey the theoretical orders of convergence. {\copyright} 2012 Copyright Taylor and Francis Group, LLC.},
  keywords = {finite element method,Galerkin's method,Levy process,stochastic partial differential equation},
  file = {/home/wouter/Zotero/storage/U5SLK8CJ/Barth, Lang - 2012 - Simulation of stochastic partial differential equations using finite element methods.pdf}
}

@article{baskin2016,
  title = {Sharp {{High-Frequency Estimates}} for the {{Helmholtz Equation}} and {{Applications}} to {{Boundary Integral Equations}}},
  author = {Baskin, Dean and Spence, Euan A. and Wunsch, Jared},
  year = {2016},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {48},
  number = {1},
  pages = {229--267},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/15M102530X},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/SY8GZID5/Baskin et al. - 2016 - Sharp High-Frequency Estimates for the Helmholtz Equation and Applications to Boundary Integral Equa.pdf}
}

@book{basu2003,
  title = {Perfectly Matched Layers for Time-Harmonic Elastodynamics of Unbounded Domains: {{Theory}} and Finite-Element Implementation},
  author = {Basu, Ushnish and Chopra, Anil K.},
  year = {2003},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {192},
  pages = {1375},
  doi = {10.1016/S0045-7825(02)00642-4},
  abstract = {One approach to the numerical solution of a wave equation on an unbounded domain uses a bounded domain surrounded by an absorbing boundary or layer that absorbs waves propagating outwards from the bounded domain. A perfectly matched layer (PML) is an unphysical absorbing layer model for linear wave equations that absorbs, almost perfectly, outgoing waves of all non-tangential angles-of-incidence and of all non-zero frequencies. This paper develops the PML concept for time-harmonic elastodynamics in Cartesian coordinates, utilising insights obtained with electromagnetics PMLs, and presents a novel displacement-based, symmetric finite-element implementation of the PML for time-harmonic plane-strain or three-dimensional motion. The PML concept is illustrated through the example of a one-dimensional rod on elastic foundation and through the anti-plane motion of a two-dimensional continuum. The concept is explored in detail through analytical and numerical results from a PML model of the semi-infinite rod on elastic foundation, and through numerical results for the anti-plane motion of a semi-infinite layer on a rigid base. Numerical results are presented for the classical soil-structure interaction problems of a rigid strip-footing on a (i) half-plane, (ii) layer on a half-plane, and (iii) layer on a rigid base. The analytical and numerical results obtained for these canonical problems demonstrate the high accuracy achievable by PML models even with small bounded domains. {\copyright} 2003 Elsevier Science B.V. All rights reserved.},
  isbn = {1-5106-4212-9},
  keywords = {Absorbing boundary,Elastic waves,Finite elements,Frequency domain,Helmholtz equation,Perfectly matched layers},
  file = {/home/wouter/Zotero/storage/7PW5CWQM/Basu, Chopra - 2003 - Perfectly matched layers for time-harmonic elastodynamics of unbounded domains Theory and finite-element implement.pdf}
}

@phdthesis{basu2010,
  title = {{{QUASI-MONTE CARLO METHODS IN NON-CUBICAL SPACES}}},
  author = {Basu, Kinjal},
  year = {2010},
  number = {October},
  file = {/home/wouter/Zotero/storage/CZ6IYX9K/Basu - 2010 - QUASI-MONTE CARLO METHODS IN NON-CUBICAL SPACES.pdf}
}

@article{beck2012,
  title = {On the Optimal Polynomial Approximation of Stochastic {{PDEs}} by {{Galerkin}} and Collocation Methods},
  author = {Beck, Joakim and Tempone, Raul and Nobile, Fabio and Tamellini, Lorenzo},
  year = {2012},
  journal = {Mathematical Models and Methods in Applied Sciences},
  volume = {22},
  number = {09},
  pages = {1250023--1250023},
  publisher = {World Scientific}
}

@article{beck2014,
  title = {Convergence of Quasi-Optimal Stochastic {{Galerkin}} Methods for a Class of {{PDEs}} with Random Coefficients},
  author = {Beck, Joakim and Nobile, Fabio and Tamellini, Lorenzo and Tempone, Ra{\'u}l},
  year = {2014},
  journal = {Computers \& Mathematics with Applications},
  volume = {67},
  number = {4},
  pages = {732--751},
  publisher = {Elsevier}
}

@article{beck2015,
  title = {Weiszfeld's {{Method}}: {{Old}} and {{New Results}}},
  shorttitle = {Weiszfeld's {{Method}}},
  author = {Beck, Amir and Sabach, Shoham},
  year = {2015},
  month = jan,
  journal = {Journal of Optimization Theory and Applications},
  volume = {164},
  number = {1},
  pages = {1--40},
  issn = {0022-3239, 1573-2878},
  doi = {10.1007/s10957-014-0586-7},
  urldate = {2024-10-02},
  langid = {english},
  file = {/home/wouter/Zotero/storage/N55I8KP6/Beck and Sabach - 2015 - Weiszfeld’s Method Old and New Results.pdf}
}

@article{beckermann2005,
  title = {Some Remarks on the {{Elman}} Estimate for {{GMRES}}},
  author = {Beckermann, Bernhard and Goreinov, Sergei and Tyrtyshnikov, Evgeny E.},
  year = {2005},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {27},
  number = {3},
  pages = {772--778},
  doi = {10.1137/040618849},
  abstract = {Starting from a GMRES error estimate proposed by Elman In terms of the ratio of the smallest eigenvalue of the hermitian part and the norm of some nonaymmetric matrix, we propose some asymptotically tighter bound In terms of the same ratio. Here we make use of a recent deep result of Cromeix and others on the norm of functions of matrices. {\copyright} 2006 Society for Industrial and Applied Mathematics.},
  keywords = {Error estimates,Field of values,GMRES,Nonsymmetric systems},
  file = {/home/wouter/Zotero/storage/H24HFYSX/Beckermann, Goreinov, Tyrtyshnikov - 2005 - Some remarks on the Elman estimate for GMRES.pdf}
}

@article{behrndt2015,
  title = {Dirichlet-to-{{Neumann}} Maps on Bounded {{Lipschitz}} Domains},
  author = {Behrndt, J. and {ter Elst}, A. F.M.},
  year = {2015},
  journal = {Journal of Differential Equations},
  volume = {259},
  number = {11},
  pages = {5903--5926},
  doi = {10.1016/j.jde.2015.07.012},
  abstract = {The Dirichlet-to-Neumann map associated to an elliptic partial differential equation becomes multivalued when the underlying Dirichlet problem is not uniquely solvable. The main objective of this paper is to present a systematic study of the Dirichlet-to-Neumann map and its inverse, the Neumann-to-Dirichlet map, in the framework of linear relations in Hilbert spaces. Our treatment is inspired by abstract methods from extension theory of symmetric operators, utilizes the general theory of linear relations and makes use of some deep results on the regularity of the solutions of boundary value problems on bounded Lipschitz domains.},
  keywords = {Dirichlet-to-Neumann map,Linear relation,Lipschitz domain,Neumann-to-Dirichlet map,Schrodinger operator},
  file = {/home/wouter/Zotero/storage/XXVE9WNA/Behrndt, ter Elst - 2015 - Dirichlet-to-Neumann maps on bounded Lipschitz domains.pdf}
}

@article{benamou1997,
  title = {A {{Domain Decomposition Method}} for the {{Helmholtz Equation}} and {{Related Optimal Control Problems}}},
  author = {Benamou, Jean-David and Despr{\`e}s, Bruno},
  year = {1997},
  month = sep,
  journal = {Journal of Computational Physics},
  volume = {136},
  number = {1},
  pages = {68--82},
  doi = {10.1006/jcph.1997.5742},
  file = {/home/wouter/Zotero/storage/ASXXWYTM/Benamou, Desprès - 1997 - A Domain Decomposition Method for the Helmholtz Equation and Related Optimal Control Problems.pdf}
}

@article{benner2015,
  title = {A {{Survey}} of {{Projection-Based Model Reduction Methods}} for {{Parametric Dynamical Systems}}},
  author = {Benner, Peter and Gugercin, Serkan and Willcox, Karen},
  year = {2015},
  month = jan,
  journal = {SIAM Review},
  volume = {57},
  number = {4},
  pages = {483--531},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/130932715},
  urldate = {2025-05-13},
  langid = {english},
  file = {/home/wouter/Zotero/storage/Q25C3CDR/Benner et al. - 2015 - A Survey of Projection-Based Model Reduction Methods for Parametric Dynamical Systems.pdf}
}

@book{berenger2007,
  title = {Perfectly {{Matched Layer}} ({{PML}}) for {{Computational Electromagnetics}}},
  author = {B{\'e}renger, Jean Pierre},
  year = {2007},
  series = {Synthesis {{Lectures}} on {{Computational Electromagnetics}}},
  publisher = {Morgan \& Claypool Publishers},
  address = {San Rafael},
  doi = {10.2200/S00030ED1V01Y200605CEM008},
  isbn = {978-1-59829-082-0 978-1-59829-083-7},
  langid = {english}
}

@article{beriot2009,
  title = {On the Locally-Conformal Perfectly Matched Layer Implementation for {{Helmholtz}} Equation},
  author = {Beriot, Hadrien and Tournour, Michel},
  year = {2009},
  journal = {Noise and Vibration: Emerging Methods},
  pages = {1--11},
  file = {/home/wouter/Zotero/storage/KZHUKV2N/Beriot, Tournour - 2009 - On the locally-conformal perfectly matched layer implementation for Helmholtz equation.pdf}
}

@article{bernards2020,
  title = {Analysis of Energy Transition Impact on the Low-Voltage Network Using Stochastic Load and Generation Models},
  author = {Bernards, Raoul and Van Westering, Werner and Morren, Johan and Slootweg, Han},
  year = {2020},
  journal = {Energies},
  volume = {13},
  number = {22},
  pages = {6097--6097},
  publisher = {MDPI}
}

@article{berrut2004,
  title = {Barycentric {{Lagrange}} Interpolation},
  author = {Berrut, Jean Paul and Trefethen, Lloyd N.},
  year = {2004},
  journal = {SIAM Review},
  volume = {46},
  number = {3},
  pages = {501--517},
  doi = {10.1137/S0036144502417715},
  abstract = {Barycentric interpolation is a variant of Lagrange polynomial interpolation that is fast and stable. It deserves to be known as the standard method of polynomial interpolation.},
  keywords = {Barycentric formula,Interpolation},
  file = {/home/wouter/Zotero/storage/FXZYAX48/Berrut, Trefethen - 2004 - Barycentric Lagrange interpolation.pdf}
}

@article{beskos2009,
  title = {Optimal Scalings for Local Metropolis-Hastings Chains on Nonproduct Targets in High Dimensions},
  author = {Beskos, Alexandros and Roberts, Gareth and Stuart, Andrew},
  year = {2009},
  journal = {Annals of Applied Probability},
  volume = {19},
  number = {3},
  pages = {863--898},
  doi = {10.1214/08-AAP563},
  abstract = {We investigate local MCMC algorithms, namely the random-walk Metropolis and the Langevin algorithms, and identify the optimal choice of the local step-size as a function of the dimension n of the state space, asymptotically as n {$\rightarrow$} {$\infty$}. We consider target distributions defined as a change of measure from a product law. Such structures arise, for instance, in inverse problems or Bayesian contexts when a product prior is combined with the likelihood. We state analytical results on the asymptotic behavior of the algorithms under general conditions on the change of measure. Our theory is motivated by applications on conditioned diffusion processes and inverse problems related to the 2D Navier-Stokes equation. {\copyright} Institute of Mathematical Statistics, 2009.},
  keywords = {Diffusion,Gaussian law on hilbert space,Karhunen-loeve,Langevin,Navier-stokes pde,Random-walk Metropolis,Squared-jump-distance},
  file = {/home/wouter/Zotero/storage/DAPC7FVH/Beskos, Roberts, Stuart - 2009 - Optimal scalings for local metropolis-hastings chains on nonproduct targets in high dimensions.pdf}
}

@article{beskos2015,
  title = {Sequential {{Monte Carlo}} Methods for {{Bayesian}} Elliptic Inverse Problems},
  author = {Beskos, Alexandros and Jasra, Ajay and Muzaffer, Ege A. and Stuart, Andrew M.},
  year = {2015},
  journal = {Statistics and Computing},
  volume = {25},
  number = {4},
  pages = {727--737},
  publisher = {Springer US},
  doi = {10.1007/s11222-015-9556-7},
  abstract = {In this article, we consider a Bayesian inverse problem associated to elliptic partial differential equations in two and three dimensions. This class of inverse problems is important in applications such as hydrology, but the complexity of the link function between unknown field and measurements can make it difficult to draw inference from the associated posterior. We prove that for this inverse problem a basic sequential Monte Carlo (SMC) method has a Monte Carlo rate of convergence with constants which are independent of the dimension of the discretization of the problem; indeed convergence of the SMC method is established in a function space setting. We also develop an enhancement of the SMC methods for inverse problems which were introduced in Kantas et al. (SIAM/ASA J Uncertain Quantif 2:464--489, 2014); the enhancement is designed to deal with the additional complexity of this elliptic inverse problem. The efficacy of the methodology and its desirable theoretical properties, are demonstrated for numerical examples in both two and three dimensions.},
  keywords = {Adaptive SMC,Elliptic PDEs,Groundwater flow,Inverse problems,Markov chain Monte Carlo},
  file = {/home/wouter/Zotero/storage/9GDJN6YC/Beskos et al. - 2015 - Sequential Monte Carlo methods for Bayesian elliptic inverse problems(2).pdf;/home/wouter/Zotero/storage/V8TMK3LH/Beskos et al. - 2015 - Sequential Monte Carlo methods for Bayesian elliptic inverse problems.pdf}
}

@article{bhattacharya2014,
  title = {Anisotropic Function Estimation Using Multi-Bandwidth {{Gaussian}} Processes},
  author = {Bhattacharya, Anirban and Pati, Debdeep and Dunson, David},
  year = {2014},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {42},
  number = {1},
  eprint = {1111.1044},
  primaryclass = {math},
  issn = {0090-5364},
  doi = {10.1214/13-AOS1192},
  urldate = {2024-12-13},
  abstract = {In nonparametric regression problems involving multiple predictors, there is typically interest in estimating an anisotropic multivariate regression surface in the important predictors while discarding the unimportant ones. Our focus is on defining a Bayesian procedure that leads to the minimax optimal rate of posterior contraction (up to a log factor) adapting to the unknown dimension and anisotropic smoothness of the true surface. We propose such an approach based on a Gaussian process prior with dimension-specific scalings, which are assigned carefully-chosen hyperpriors. We additionally show that using a homogenous Gaussian process with a single bandwidth leads to a sub-optimal rate in anisotropic cases.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Statistics Theory,Statistics - Statistics Theory},
  file = {/home/wouter/Zotero/storage/TXCQIDRA/Bhattacharya et al. - 2014 - Anisotropic function estimation using multi-bandwidth Gaussian processes.pdf;/home/wouter/Zotero/storage/NXSD4M8A/1111.html}
}

@article{binois2022,
  title = {A {{Survey}} on {{High-dimensional Gaussian Process Modeling}} with {{Application}} to {{Bayesian Optimization}}},
  author = {Binois, Micka{\"e}l and Wycoff, Nathan},
  year = {2022},
  month = jun,
  journal = {ACM Transactions on Evolutionary Learning and Optimization},
  volume = {2},
  number = {2},
  pages = {1--26},
  issn = {2688-299X, 2688-3007},
  doi = {10.1145/3545611},
  urldate = {2024-09-24},
  abstract = {Bayesian Optimization (BO), the application of Bayesian function approximation to finding optima of expensive functions, has exploded in popularity in recent years. In particular, much attention has been paid to improving its efficiency on problems with many parameters to optimize. This attention has trickled down to the workhorse of high-dimensional BO, high-dimensional Gaussian process regression, which is also of independent interest. The great flexibility that the Gaussian process prior implies is a boon when modeling complicated, low-dimensional surfaces but simply says too little when dimension grows too large. A variety of structural model assumptions have been tested to tame high dimensions, from variable selection and additive decomposition to low-dimensional embeddings and beyond. Most of these approaches in turn require modifications of the acquisition function optimization strategy as well. Here, we review the defining structural model assumptions and discuss the benefits and drawbacks of these approaches in practice.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/CID4NCAI/Binois and Wycoff - 2022 - A Survey on High-dimensional Gaussian Process Modeling with Application to Bayesian Optimization.pdf}
}

@book{bishop2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-31073-2},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception},
  file = {/home/wouter/Zotero/storage/83GM9DLP/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{blanchet-scalliet2017,
  title = {A Specific Kriging Kernel for Dimensionality Reduction: {{Isotropic}} by Group Kernel},
  author = {{Blanchet-Scalliet}, Christophette and Helbert, C{\'e}line and Ribaud, M{\'e}lina and Vial, C{\'e}line},
  year = {2017},
  file = {/home/wouter/Zotero/storage/TUIRUKGQ/_.pdf}
}

@article{blei2017,
  title = {Variational {{Inference}}: {{A Review}} for {{Statisticians}}},
  author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
  year = {2017},
  journal = {Journal of the American Statistical Association},
  volume = {112},
  number = {518},
  pages = {859--877},
  doi = {10.1080/01621459.2017.1285773},
  abstract = {One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this article, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to first posit a family of densities and then to find a member of that family which is close to the target density. Closeness is measured by Kullback--Leibler divergence. We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this article is to catalyze statistical research on this class of algorithms. Supplementary materials for this article are available online.},
  keywords = {Algorithms,Computationally intensive methods,Statistical computing},
  file = {/home/wouter/Zotero/storage/K63Y66K5/Blei, Kucukelbir, McAuliffe - 2017 - Variational Inference A Review for Statisticians.pdf}
}

@inproceedings{bloodgood2009,
  title = {A {{Method}} for {{Stopping Active Learning Based}} on {{Stabilizing Predictions}} and the {{Need}} for {{User-Adjustable Stopping}}},
  booktitle = {Proceedings of the {{Thirteenth Conference}} on {{Computational Natural Language Learning}} ({{CoNLL-2009}})},
  author = {Bloodgood, Michael and Shanker, Vijay K.},
  year = {2009},
  pages = {39--47},
  publisher = {Association for Computational Linguistics},
  address = {Boulder, Colorado},
  file = {/home/wouter/Zotero/storage/DZAXTSJC/Bloodgood, Michael and Vijay-Shanker - 2009 - A Method for Stopping Active Learning Based on Stabilizing Predictions and the Need for User-Adjusta.pdf}
}

@article{blyth2003,
  title = {Heat Conduction across Irregular and Fractal-like Surfaces},
  author = {Blyth, M. G. and Pozrikidis, C.},
  year = {2003},
  journal = {International Journal of Heat and Mass Transfer},
  volume = {46},
  number = {8},
  pages = {1329--1339},
  doi = {10.1016/S0017-9310(02)00419-2},
  abstract = {The effect of irregularities on the rate of heat conduction from a two-dimensional isothermal surface into a semi infinite medium is considered. The effect of protrusions, depressions, and surface roughness is quantified in terms of the displacement of the linear temperature profile prevailing far from the surface. This shift, coined the displacement length, is designated as an appropriate global measure of the effect of the surface indentations incorporating the particular details of the possibly intricate geometry. To compute the displacement length, Laplace's equation describing the temperature distribution in the semi-infinite space above the surface is solved numerically by a modified Schwarz-Christoffel transformation whose computation requires solving a system of highly non-linear algebraic equations by iterative methods, and an integral equation method originating from the single-layer integral representation of a harmonic function involving the periodic Green's function. The conformal mapping method is superior in that it is capable of handling with high accuracy a large number of vertices and intricate wall geometries. On the other hand, the boundary integral method yields the displacement length as part of the solution. Families of polygonal wall shapes composed of segments in regular, irregular, and random arrangement are considered, and pre-fractal geometries consisting of large numbers of vertices are analyzed. The results illustrate the effect of wall geometry on the flux distribution and on the overall enhancement in the rate of transport for regular and complex wall shapes. {\copyright} 2002 Elsevier Science Ltd. All rights reserved.},
  file = {/home/wouter/Zotero/storage/J43UK46Q/Blyth, Pozrikidis - 2003 - Heat conduction across irregular and fractal-like surfaces.pdf}
}

@article{bonazzoli2021,
  title = {Analysis of the {{SORAS Domain Decomposition Preconditioner}} for {{Non-self-adjoint}} or {{Indefinite Problems}}},
  author = {Bonazzoli, Marcella and Claeys, Xavier and Nataf, Fr{\'e}d{\'e}ric and Tournier, Pierre Henri},
  year = {2021},
  journal = {Journal of Scientific Computing},
  volume = {89},
  number = {1},
  doi = {10.1007/s10915-021-01631-8},
  abstract = {We analyze the convergence of the one-level overlapping domain decomposition preconditioner SORAS (Symmetrized Optimized Restricted Additive Schwarz) applied to a generic linear system whose matrix is not necessarily symmetric/self-adjoint nor positive definite. By generalizing the theory for the Helmholtz equation developed in Graham et al. (SIAM J Numer Anal 58(5):2515--2543, 2020. https://doi.org/10.1137/19M1272512), we identify a list of assumptions and estimates that are sufficient to obtain an upper bound on the norm of the preconditioned matrix, and a lower bound on the distance of its field of values from the origin. We stress that our theory is general in the sense that it is not specific to one particular boundary value problem. Moreover, it does not rely on a coarse mesh whose elements are sufficiently small. As an illustration of this framework, we prove new estimates for overlapping domain decomposition methods with Robin-type transmission conditions for the heterogeneous reaction--convection--diffusion equation (to prove the stability assumption for this equation we consider the case of a coercive bilinear form, which is non-symmetric, though).},
  keywords = {Domain decomposition,Field of values,Indefinite problems,Non-self-adjoint problems,Preconditioners,Reaction-convection-diffusion equation},
  file = {/home/wouter/Zotero/storage/MH3E435I/Bonazzoli et al. - 2021 - Analysis of the SORAS Domain Decomposition Preconditioner for Non-self-adjoint or Indefinite Problems.pdf}
}

@article{bootland2021,
  title = {A Comparison of Coarse Spaces for {{Helmholtz}} Problems in the High Frequency Regime},
  author = {Bootland, Niall and Dolean, Victorita and Jolivet, Pierre and Tournier, Pierre-Henri},
  year = {2021},
  month = sep,
  journal = {Computers \& Mathematics with Applications},
  volume = {98},
  pages = {239--253},
  doi = {10.1016/j.camwa.2021.07.011},
  abstract = {Solving time-harmonic wave propagation problems in the frequency domain and within heterogeneous media brings many mathematical and computational challenges, especially in the high frequency regime. We will focus here on computational challenges and try to identify the best algorithm and numerical strategy for a few well-known benchmark cases arising in applications. The aim is to cover, through numerical experimentation and consideration of the best implementation strategies, the main two-level domain decomposition methods developed in recent years for the Helmholtz equation. The theory for these methods is either out of reach with standard mathematical tools or does not cover all cases of practical interest. More precisely, we will focus on the comparison of three coarse spaces that yield two-level methods: the grid coarse space, DtN coarse space, and GenEO coarse space. We will show that they display different pros and cons, and properties depending on the problem and particular numerical setting.},
  keywords = {Coarse spaces,Domain decomposition methods,Helmholtz equations,High frequency,Two-level methods},
  file = {/home/wouter/Zotero/storage/UZ8G8FCW/Bootland et al. - 2021 - A comparison of coarse spaces for Helmholtz problems in the high frequency regime.pdf}
}

@article{box1958,
  title = {A Note on the Generation of Normal Random Deviates},
  author = {Box, G E P},
  year = {1958},
  journal = {Ann. Math. Statist.},
  volume = {29},
  pages = {610--613}
}

@article{braconnier1996,
  title = {Computing the Field of Values and Pseudospectra Using the {{Lanczos}} Method with Continuation},
  author = {Braconnier, Thierry and Higham, Nicholas J.},
  year = {1996},
  journal = {BIT Numerical Mathematics},
  volume = {36},
  number = {3},
  pages = {422--440},
  doi = {10.1007/BF01731925},
  abstract = {The field of values and pseudospectra are useful tools for understanding the behaviour of various matrix processes. To compute these subsets of the complex plane it is necessary to estimate one or two eigenvalues of a large number of parametrized Hermitian matrices; these computations are prohibitively expensive for large, possibly sparse, matrices, if done by use of the QR algorithm. We describe an approach based on the Lanczos method with selective reorthogonalization and Chebyshev acceleration that, when combined with continuation and a shift and invert technique, enables efficient and reliable computation of the field of values and pseudospectra for large matrices. The idea of using the Lanczos method with continuation to compute pseudospectra is not new, but in experiments reported here our algorithm is faster and more accurate than existing algorithms of this type.},
  keywords = {Chebyshev acceleration,Continuation,Field of values,Lanczos method,Pseudospectra},
  file = {/home/wouter/Zotero/storage/4PBH6LLT/Braconnier, Higham - 1996 - Computing the field of values and pseudospectra using the Lanczos method with continuation.pdf}
}

@article{bramble1986,
  title = {The {{Construction}} of {{Preconditioners}} for {{Elliptic Problems}} by {{Substructuring}}. {{I}}},
  author = {Bramble, J. H. and Pasciak, J. E. and Schatz, A. H.},
  year = {1986},
  month = jul,
  journal = {Mathematics of Computation},
  volume = {47},
  number = {175},
  eprint = {2008084},
  eprinttype = {jstor},
  pages = {103--103},
  doi = {10.2307/2008084},
  abstract = {We consider the problem of solving the algebraic system of equations which arise from the discretization of symmetric elliptic boundary value problems via finite element methods. A new class of preconditioners for these discrete systems is developed based on substructuring (also known as domain decomposition). The resulting preconditioned algorithms are well suited to emerging parallel computing architectures. The proposed methods are applicable to problems on general domains involving differential operators with rather general coefficients. A basic theory for the analysis of the condition number of the preconditioned system (which determines the iterative convergence rate of the algorithm) is given. Techniques for applying the theory and algorithms to problems with irregular geometry are discussed and the results of extensive numerical experiments are reported.},
  file = {/home/wouter/Zotero/storage/2TRHKZ7R/Bramble, Pasciak, Schatz - 1986 - The Construction of Preconditioners for Elliptic Problems by Substructuring. I.pdf}
}

@article{bramble1987,
  title = {The {{Construction}} of {{Preconditioners}} for {{Elliptic Problems}} by {{Substructuring}}. {{II}}},
  author = {Bramble, J. H. and Pasciak, J. E. and Schatz, A. H.},
  year = {1987},
  month = jul,
  journal = {Mathematics of Computation},
  volume = {49},
  number = {179},
  eprint = {2008246},
  eprinttype = {jstor},
  pages = {1--1},
  doi = {10.2307/2008246},
  abstract = {We give a method for constructing preconditioners for the discrete systems arising in the approximation of solutions of elliptic boundary value problems. These preconditioners are based on domain decomposition techniques and lead to algorithms which are well suited for parallel computing environments. The method presented in this paper leads to a preconditioned system with condition number proportional to \$d/h\$ where \$d\$ is the subdomain size and \$h\$ is the mesh size. These techniques are applied to singularly perturbed problems and problems in three dimensions. The results of numerical experiments illustrating the performance of the method on problems in two and three dimensions are given.},
  file = {/home/wouter/Zotero/storage/NM7F3VAZ/Bramble, Pasciak, Schatz - 1987 - The Construction of Preconditioners for Elliptic Problems by Substructuring. II.pdf}
}

@article{bramble1988,
  title = {The {{Construction}} of {{Preconditioners}} for {{Elliptic Problems}} by {{Substructuring}}, {{III}}},
  author = {Bramble, James H. and Pasciak, Joseph E. and Schatz, Alfred H.},
  year = {1988},
  month = oct,
  journal = {Mathematics of Computation},
  series = {Applied {{Mathematical Sciences}}},
  volume = {51},
  number = {184},
  eprint = {2008756},
  eprinttype = {jstor},
  pages = {415--415},
  publisher = {Springer New York},
  address = {New York, NY},
  issn = {978-0-387-22073-4},
  doi = {10.2307/2008756},
  abstract = {We consider the problem of solving the algebraic system of equations which arise from the discretization of symmetric elliptic boundary value problems via finite element methods. A new class of preconditioners for these discrete systems is developed based on substructuring (also known as domain decomposition). The resulting preconditioned algorithms are well suited to emerging parallel computing architectures. The proposed methods are applicable to problems on general domains involving differential operators with rather general coefficients. A basic theory for the analysis of the condition number of the preconditioned system (which determines the iterative convergence rate of the algorithm) is given. Techniques for applying the theory and algorithms to problems with irregular geometry are discussed and the results of extensive numerical experiments are reported.},
  file = {/home/wouter/Zotero/storage/CUCIMXSQ/Bramble, Pasciak, Schatz - 1988 - The Construction of Preconditioners for Elliptic Problems by Substructuring, III.pdf}
}

@article{bramble1989,
  title = {The {{Construction}} of {{Preconditioners}} for {{Elliptic Problems}} by {{Substructuring}}, {{IV}}},
  author = {Bramble, James H. and Pasciak, Joseph E. and Schatz, Alfred H.},
  year = {1989},
  month = jul,
  journal = {Mathematics of Computation},
  volume = {53},
  number = {187},
  eprint = {2008346},
  eprinttype = {jstor},
  pages = {1--1},
  doi = {10.2307/2008346},
  file = {/home/wouter/Zotero/storage/ETNJGHEZ/Bramble, Pasciak, Schatz - 1989 - The Construction of Preconditioners for Elliptic Problems by Substructuring, IV.pdf}
}

@book{brenner2008,
  title = {The {{Mathematical Theory}} of {{Finite Element Methods}}},
  author = {Brenner, Susanne C. and Scott, L. Ridgway},
  year = {2008},
  series = {Texts in {{Applied Mathematics}}},
  volume = {15},
  pages = {2015},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-0-387-75934-0},
  abstract = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell ``S'' karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
  isbn = {978-0-387-75933-3},
  file = {/home/wouter/Zotero/storage/XCES2ETW/Brenner, Scott - 2008 - The Mathematical Theory of Finite Element Methods(2).pdf}
}

@article{brimberg2008,
  title = {A Survey of Solution Methods for the Continuous Location Allocation Problem},
  author = {Brimberg, Jack and Hansen, Pierre and Mladonovic, Nedad and Salhi, Said},
  year = {2008},
  journal = {International Journal of Operational Research},
  volume = {5},
  number = {1},
  pages = {1--12},
  abstract = {In this survey, we examine an important class of facility location problems known as the multisource Weber problem (also referred to as the continuous location-allocation problem). We also show how recent advances in the use of metaheuristic rules have significantly improved the ability to solve problems of this type. The new solution methods are discussed for both the well known multisource Weber problem and its counterpart the capacitated case. Research issues which we believe to be worthwhile exploring in future are also highlighted.},
  keywords = {Operations Research - Theory},
  file = {/home/wouter/Zotero/storage/EVS97J6F/Brimberg et al. - 2008 - A survey of solution methods for the continuous location allocation problem.pdf}
}

@misc{brown2022,
  title = {{{PETSc Web}} Page},
  author = {Brown, Satish B. and Abhyankar, Shrirang and Adams, Mark F. and Benson, Steven and Dener, Jed and Brune, Peter and Buschelman, Kris and Constantinescu, Emil M. and Dalcin, Lisandro and Jolivet, Alp},
  year = {2022}
}

@article{buffon,
  title = {Editor's Note Concerning a Lecture given 1733 to the {{Royal Academy}} of {{Sciences}} in {{Paris}}},
  author = {Buffon, G},
  journal = {Histoire de l'Acad{\'e}mie Royale des Sciences},
  pages = {43--45}
}

@article{buffon1777,
  title = {Essai d'arithm{\'e}tique Morale},
  author = {Buffon, G},
  year = {1777},
  journal = {Suppl{\'e}menta l'Histoire naturelle},
  volume = {4},
  pages = {1777--1777}
}

@article{bulte2018,
  title = {A Practical Example for the Non-Linear {{Bayesian}} Filtering of Model Parameters},
  author = {Bult{\'e}, Matthieu and Latz, Jonas and Ullmann, Elisabeth},
  year = {2018},
  month = jul,
  journal = {Lecture Notes in Computational Science and Engineering},
  volume = {137},
  pages = {241--272},
  doi = {10.1007/978-3-030-48721-8_11},
  abstract = {In this tutorial we consider the non-linear Bayesian filtering of static parameters in a time-dependent model. We outline the theoretical background and discuss appropriate solvers. We focus on particle-based filters and present Sequential Importance Sampling (SIS) and Sequential Monte Carlo (SMC). Throughout the paper we illustrate the concepts and techniques with a practical example using real-world data. The task is to estimate the gravitational acceleration of the Earth \$g\$ by using observations collected from a simple pendulum. Importantly, the particle filters enable the adaptive updating of the estimate for \$g\$ as new observations become available. For tutorial purposes we provide the data set and a Python implementation of the particle filters.},
  keywords = {Model parameters,Non-linear Bayesian filtering,Particle-based filters,Sequential importance sampling,Sequential Monte Carlo,Time-dependent model},
  file = {/home/wouter/Zotero/storage/4HT9DIM3/Bulté, Latz, Ullmann - 2018 - A practical example for the non-linear Bayesian filtering of model parameters.pdf}
}

@book{bulte2020,
  title = {A Practical Example for the Non-Linear Bayesian Filtering of Model Parameters},
  author = {Bult{\'e}, Matthieu and Latz, Jonas and Ullmann, Elisabeth},
  year = {2020},
  journal = {Lecture Notes in Computational Science and Engineering},
  volume = {137},
  pages = {272},
  doi = {10.1007/978-3-030-48721-8_11},
  abstract = {In this tutorial we consider the non-linear Bayesian filtering of static parameters in a time-dependent model. We outline the theoretical background and discuss appropriate solvers. We focus on particle-based filters and present Sequential Importance Sampling (SIS) and Sequential Monte Carlo (SMC). Throughout the paper we illustrate the concepts and techniques with a practical example using real-world data. The task is to estimate the gravitational acceleration of the Earth g by using observations collected from a simple pendulum. Importantly, the particle filters enable the adaptive updating of the estimate for g as new observations become available. For tutorial purposes we provide the data set and a Python implementation of the particle filters.},
  isbn = {978-3-030-48720-1},
  keywords = {Model parameters,Non-linear Bayesian filtering,Particle-based filters,Sequential importance sampling,Sequential Monte Carlo,Time-dependent model},
  file = {/home/wouter/Zotero/storage/QED6P6QW/Bulté, Latz, Ullmann - 2020 - A practical example for the non-linear bayesian filtering of model parameters.pdf}
}

@phdthesis{bumb2002,
  title = {Approximation {{Algorithms For Facility Location Problems}}},
  author = {Bumb, Adriana},
  year = {2002},
  isbn = {9036517877},
  file = {/home/wouter/Zotero/storage/53B8AAFS/Bumb - 2002 - Approximation Algorithms For Facility Location Problems.pdf}
}

@article{bungartz2004,
  title = {Sparse Grids},
  author = {Bungartz, Hans J. and Griebel, Michael},
  year = {2004},
  journal = {Acta Numerica},
  volume = {13},
  pages = {147--269},
  doi = {10.1017/S0962492904000182},
  abstract = {We present a survey of the fundamentals and the applications of sparse grids, with a focus on the solution of partial differential equations (PDEs). The sparse grid approach, introduced in Zenger (1991), is based on a higher-dimensional multiscale basis, which is derived from a one-dimensional multi-scale basis by a tensor product construction. Discretizations on sparse grids involve O(N {$\cdot$} (log N)d-1) degrees of freedom only, where d denotes the under-lying problem's dimensionality and where N is the number of grid points in one coordinate direction at the boundary. The accuracy obtained with piece-wise linear basis functions, for example, is O(N -2 {$\cdot$} (log N)d-1) with respect to the L 2- and L{$\infty$}-norm, if the solution has bounded second mixed derivatives. This way, the curse of dimensionality, i.e., the exponential dependence O(Nd) of conventional approaches, is overcome to some extent. For the energy norm, only O(N) degrees of freedom are needed to give an accuracy of O(N-1). That is why sparse grids are especially well-suited for problems of very high dimensionality. The sparse grid approach can be extended to nonsmooth solutions by adaptive refinement methods. Furthermore, it can be generalized from piecewise linear to higher-order polynomials. Also, more sophisticated basis functions like interpolets, prewavelets, or wavelets can be used in a straightforward way. We describe the basic features of sparse grids and report the results of various numerical experiments for the solution of elliptic PDEs as well as for other selected problems such as numerical quadrature and data mining.},
  file = {/home/wouter/Zotero/storage/6E3WLF2N/Bungartz, Griebel - 2004 - Sparse grids.pdf}
}

@article{caflisch1998,
  title = {Monte {{Carlo}} and Quasi-{{Monte Carlo}} Methods},
  author = {Caflisch, Russel E.},
  year = {1998},
  journal = {Acta Numerica},
  volume = {7},
  pages = {1--49},
  publisher = {Universiteitsbibliotheek Nijmegen},
  doi = {10.1017/S0962492900002804},
  abstract = {Monte Carlo is one of the most versatile and widely used numerical methods. Its convergence rate, O(N-1/2), is independent of dimension, which shows Monte Carlo to be very robust but also slow. This article presents an introduction to Monte Carlo methods for integration problems, including convergence theory, sampling methods and variance reduction techniques. Accelerated convergence for Monte Carlo quadrature is attained using quasi-random (also called low-discrepancy) sequences, which are a deterministic alternative to random or pseudo-random sequences. The points in a quasi-random sequence are correlated to provide greater uniformity. The resulting quadrature method, called quasi-Monte Carlo, has a convergence rate of approximately O((logN)kN-1). For quasi-Monte Carlo, both theoretical error estimates and practical limitations are presented. Although the emphasis in this article is on integration, Monte Carlo simulation of rarefied gas dynamics is also discussed. In the limit of small mean free path (that is, the fluid dynamic limit), Monte Carlo loses its effectiveness because the collisional distance is much less than the fluid dynamic length scale. Computational examples are presented throughout the text to illustrate the theory. A number of open problems are described. {\copyright} 1998, Cambridge University Press. All rights reserved.},
  file = {/home/wouter/Zotero/storage/FYPMHV4P/Caflisch - 1998 - Monte Carlo and quasi-Monte Carlo methods.pdf}
}

@article{cai1992,
  title = {Domain {{Decomposition Algorithms}} for {{Indefinite Elliptic Problems}}},
  author = {Cai, Xiao-Chuan and Widlund, Olof B.},
  year = {1992},
  month = jan,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {13},
  number = {1},
  pages = {243--258},
  doi = {10.1137/0913013},
  file = {/home/wouter/Zotero/storage/QUPMEATN/Cai, Widlund - 1992 - Domain Decomposition Algorithms for Indefinite Elliptic Problems.pdf}
}

@article{calderon1985,
  title = {Boundary {{Value Problems}} for the {{Laplace Equation}} in {{Lipschitzian Domains}}},
  author = {Calder{\'o}n, A. P.},
  year = {1985},
  journal = {North-Holland Mathematics Studies},
  volume = {111},
  number = {C},
  pages = {33--48},
  doi = {10.1016/S0304-0208(08)70278-0},
  abstract = {This chapter considers the problem of finding solutions G of the Laplace equation in D taking prescribed values g on {$\partial$}D (Dirichlet problem), with (∇G.v) = g where v is a prescribed continuous unit vector valued function on {$\partial$}D(oblique derivative problem). The precise sense in which these conditions are to be satisfied is described in the chapter. {\copyright} 1985, Elsevier Inc. All rights reserved.},
  file = {/home/wouter/Zotero/storage/PMS3UUM4/Calderón - 1985 - Boundary Value Problems for the Laplace Equation in Lipschitzian Domains.pdf}
}

@article{calixto2006,
  title = {Wavelet Transform on the Circle and the Real Line: {{A}} Unified Group-Theoretical Treatment},
  author = {Calixto, M. and Guerrero, J.},
  year = {2006},
  journal = {Applied and Computational Harmonic Analysis},
  volume = {21},
  number = {2},
  pages = {204--229},
  doi = {10.1016/j.acha.2006.02.001},
  abstract = {We present a unified group-theoretical derivation of the continuous wavelet transform (CWT) on the circle S1 and the real line R, following the general formalism of coherent states (CS) associated to unitary square integrable (modulo a subgroup, possibly) representations of the group SL (2, R). A general procedure for obtaining unitary representations of a group G of affine transformations on a space of signals L2 (X, d x) is described, relating carrier spaces X to (first- or higher-order) "polarization subalgebras" PX. We also provide explicit admissibility and continuous frame conditions for wavelets on S1 and discuss the Euclidean limit in terms of group contraction. {\copyright} 2006 Elsevier Inc. All rights reserved.},
  file = {/home/wouter/Zotero/storage/SVQEYKMV/Calixto, Guerrero - 2006 - Wavelet transform on the circle and the real line A unified group-theoretical treatment.pdf}
}

@article{calvetti2007,
  title = {Preconditioned Iterative Methods for Linear Discrete Ill-Posed Problems from a {{Bayesian}} Inversion Perspective},
  author = {Calvetti, Daniela},
  year = {2007},
  journal = {Journal of Computational and Applied Mathematics},
  volume = {198},
  number = {2},
  pages = {378--395},
  doi = {10.1016/j.cam.2005.10.038},
  abstract = {In this paper we revisit the solution of ill-posed problems by preconditioned iterative methods from a Bayesian statistical inversion perspective. After a brief review of the most popular Krylov subspace iterative methods for the solution of linear discrete ill-posed problems and some basic statistics results, we analyze the statistical meaning of left and right preconditioners, as well as projected-restarted strategies. Computed examples illustrating the interplay between statistics and preconditioning are also presented. {\copyright} 2005 Elsevier B.V. All rights reserved.},
  keywords = {Bayesian inversion,Ill-posed problems,Iterative solvers,Krylov subspace,Preconditioners},
  file = {/home/wouter/Zotero/storage/27VXCGX4/Calvetti - 2007 - Preconditioned iterative methods for linear discrete ill-posed problems from a Bayesian inversion perspective.pdf}
}

@article{canuto2007,
  title = {A Fictitious Domain Approach to the Numerical Solution of {{PDEs}} in Stochastic Domains},
  author = {Canuto, Claudio and Kozubek, Tomas},
  year = {2007},
  journal = {Numerische Mathematik},
  volume = {107},
  number = {2},
  pages = {257--293},
  doi = {10.1007/s00211-007-0086-x},
  abstract = {We present an efficient method for the numerical realization of elliptic PDEs in domains depending on random variables. Domains are bounded, and have finite fluctuations. The key feature is the combination of a fictitious domain approach and a polynomial chaos expansion. The PDE is solved in a larger, fixed domain (the fictitious domain), with the original boundary condition enforced via a Lagrange multiplier acting on a random manifold inside the new domain. A (generalized) Wiener expansion is invoked to convert such a stochastic problem into a deterministic one, depending on an extra set of real variables (the stochastic variables). Discretization is accomplished by standard mixed finite elements in the physical variables and a Galerkin projection method with numerical integration (which coincides with a collocation scheme) in the stochastic variables. A stability and convergence analysis of the method, as well as numerical results, are provided. The convergence is "spectral" in the polynomial chaos order, in any subdomain which does not contain the random boundaries. {\copyright} 2007 Springer-Verlag.},
  file = {/home/wouter/Zotero/storage/TN45XPPJ/Canuto, Kozubek - 2007 - A fictitious domain approach to the numerical solution of PDEs in stochastic domains.pdf}
}

@article{caratelli2013,
  title = {The {{Dirichlet}} Problem for the {{Laplace}} Equation in Supershaped Annuli},
  author = {Caratelli, Diego and Gielis, Johan and Tavkhelidze, Ilia and Ricci, Paolo E.},
  year = {2013},
  journal = {Boundary Value Problems},
  volume = {2013},
  pages = {1--10},
  doi = {10.1186/1687-2770-2013-113},
  abstract = {The Dirichlet problem for the Laplace equation in normal-polar annuli is addressed by using a suitable Fourier-like technique. Attention is in particular focused on the wide class of domains whose boundaries are defined by the so-called 'superformula' introduced by Gielis. A dedicated numerical procedure based on the computer algebra system Mathematica{\copyright} is developed in order to validate the proposed methodology. In this way, highly accurate approximations of the solution, featuring properties similar to the classical ones, are obtained. {\copyright} 2013 Caratelli et al.; licensee Springer.},
  file = {/home/wouter/Zotero/storage/LIA9J2VN/Caratelli et al. - 2013 - The Dirichlet problem for the Laplace equation in supershaped annuli.pdf}
}

@article{castaneda1995,
  title = {The Effect of Spatial Distribution on the Effective Behavior of Composite Materials and Cracked Media},
  author = {Casta{\~n}eda, P Ponte and Willis, John R},
  year = {1995},
  journal = {Journal of the Mechanics and Physics of Solids},
  volume = {43},
  number = {12},
  pages = {1919--1951},
  publisher = {Elsevier}
}

@article{castrillon-candas2016,
  title = {Analytic Regularity and Collocation Approximation for Elliptic {{PDEs}} with Random Domain Deformations},
  author = {{Castrill{\'o}n-Cand{\'a}s}, Julio E. and Nobile, Fabio and Tempone, Ra{\'u}l F.},
  year = {2016},
  journal = {Computers and Mathematics with Applications},
  volume = {71},
  number = {6},
  pages = {1173--1197},
  publisher = {Elsevier Ltd},
  doi = {10.1016/j.camwa.2016.01.005},
  abstract = {In this work we consider the problem of approximating the statistics of a given Quantity of Interest (QoI) that depends on the solution of a linear elliptic PDE defined over a random domain parameterized by N random variables. The elliptic problem is remapped onto a corresponding PDE with a fixed deterministic domain. We show that the solution can be analytically extended to a well defined region in CN with respect to the random variables. A sparse grid stochastic collocation method is then used to compute the mean and variance of the QoI. Finally, convergence rates for the mean and variance of the QoI are derived and compared to those obtained in numerical experiments.},
  keywords = {Complex analysis,Finite elements,Smolyak sparse grids,Stochastic collocation,Stochastic PDEs,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/HKQ6L22K/Castrillón-Candás, Nobile, Tempone - 2016 - Analytic regularity and collocation approximation for elliptic PDEs with random domain (2).pdf}
}

@article{castrillon-candas2021,
  title = {A Stochastic Collocation Approach for Parabolic {{PDEs}} with Random Domain Deformations},
  author = {{Castrill{\'o}n-Cand{\'a}s}, Julio E. and Xu, Jie},
  year = {2021},
  month = jul,
  journal = {Computers and Mathematics with Applications},
  volume = {93},
  number = {5},
  pages = {32--49},
  publisher = {Elsevier Ltd},
  doi = {10.1016/j.camwa.2021.04.005},
  abstract = {In this article we analyze the linear parabolic partial differential equation with a stochastic domain deformation. In particular, we concentrate on the problem of numerically approximating the statistical moments of a given Quantity of Interest (QoI). The geometry is assumed to be random. The parabolic problem is remapped to a fixed deterministic domain with random coefficients and shown to admit an extension on a well defined region embedded in the complex hyperplane. The stochastic moments of the QoI are computed by employing a collocation method in conjunction with an isotropic Smolyak sparse grid. Theoretical sub-exponential convergence rates as a function to the number of collocation interpolation knots are derived. Numerical experiments are performed and they confirm the theoretical error estimates.},
  keywords = {Complex analysis,Parabolic PDEs,Smolyak sparse grids,Stochastic collocation,Stochastic PDEs,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/7BPSZCT4/Castrillón-Candás, Xu - 2021 - A stochastic collocation approach for parabolic PDEs with random domain deformations.pdf}
}

@article{cawley2008,
  title = {Efficient Approximate Leave-One-out Cross-Validation for Kernel Logistic Regression},
  author = {Cawley, Gavin C. and Talbot, Nicola L. C.},
  year = {2008},
  month = jun,
  journal = {Machine Learning},
  volume = {71},
  number = {2-3},
  pages = {243--264},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-008-5055-9},
  urldate = {2025-01-20},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/Q8ADXCBR/Cawley and Talbot - 2008 - Efficient approximate leave-one-out cross-validation for kernel logistic regression.pdf}
}

@article{chandler-wilde2008,
  title = {Wave-{{Number-Explicit Bounds}} in {{Time-Harmonic Scattering}}},
  author = {{Chandler-Wilde}, Simon N. and Monk, Peter},
  year = {2008},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {39},
  number = {5},
  pages = {1428--1455},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/060662575},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/IF4W5IS5/Chandler-Wilde and Monk - 2008 - Wave-Number-Explicit Bounds in Time-Harmonic Scattering.pdf}
}

@article{chandler-wilde2012,
  title = {Numerical-Asymptotic Boundary Integral Methods in High-Frequency Acoustic Scattering},
  author = {{Chandler-Wilde}, Simon N. and Graham, Ivan G. and Langdon, Stephen and Spence, Euan A.},
  year = {2012},
  month = may,
  journal = {Acta Numerica},
  volume = {21},
  pages = {89--305},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492912000037},
  urldate = {2025-02-04},
  abstract = {In this article we describe recent progress on the design, analysis and implementation of hybrid numerical-asymptotic boundary integral methods for boundary value problems for the Helmholtz equation that model time harmonic acoustic wave scattering in domains exterior to impenetrable obstacles. These hybrid methods combine conventional piecewise polynomial approximations with high-frequency asymptotics to build basis functions suitable for representing the oscillatory solutions. They have the potential to solve scattering problems accurately in a computation time that is (almost) independent of frequency and this has been realized for many model problems. The design and analysis of this class of methods requires new results on the analysis and numerical analysis of highly oscillatory boundary integral operators and on the high-frequency asymptotics of scattering problems. The implementation requires the development of appropriate quadrature rules for highly oscillatory integrals. This article contains a historical account of the development of this currently very active field, a detailed account of recent progress and, in addition, a number of original research results on the design, analysis and implementation of these methods.},
  copyright = {https://www.cambridge.org/core/terms},
  langid = {english},
  file = {/home/wouter/Zotero/storage/NUMHLLZW/Chandler-Wilde et al. - 2012 - Numerical-asymptotic boundary integral methods in high-frequency acoustic scattering.pdf}
}

@article{chandler-wilde2020,
  title = {High-Frequency {{Bounds}} for the {{Helmholtz Equation Under Parabolic Trapping}} and {{Applications}} in {{Numerical Analysis}}},
  author = {{Chandler-Wilde}, S. N. and Spence, E. A. and Gibbs, A. and Smyshlyaev, V. P.},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {52},
  number = {1},
  pages = {845--893},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/18M1234916},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/CEQSAPI8/Chandler-Wilde et al. - 2020 - High-frequency Bounds for the Helmholtz Equation Under Parabolic Trapping and Applications in Numeri.pdf}
}

@article{chaudhry2018,
  title = {Efficient Distribution Estimation and Uncertainty Quantification for Elliptic Problems on Domains with Stochastic Boundaries},
  author = {Chaudhry, Jehanzeb H. and Burch, Nathanial and Estep, Donald},
  year = {2018},
  journal = {SIAM-ASA Journal on Uncertainty Quantification},
  volume = {6},
  number = {3},
  pages = {1127--1150},
  doi = {10.1137/17M112230X},
  abstract = {We study the problem of uncertainty quantification for the numerical solution of elliptic partial differential equation boundary value problems posed on domains with stochastically varying boundaries. We also use the uncertainty quantification results to tackle the efficient solution of such problems. We introduce simple transformations that map a family of domains with stochastic boundaries to a fixed reference domain. We exploit the transformations to carry out prior and a posteriori error analyses and to derive an efficient Monte Carlo sampling procedure.},
  keywords = {A posteriori error estimate,Adaptive error control,Cumulative distribution function,Elliptic problem,Stochastic boundary,Stochastic geometry},
  file = {/home/wouter/Zotero/storage/ZIIWXUNA/Chaudhry, Burch, Estep - 2018 - Efficient distribution estimation and uncertainty quantification for elliptic problems on domains with s.pdf}
}

@article{chaudhury2009,
  title = {Construction of {{Hilbert Transform Pairs}} of {{Wavelet Bases}} and {{Gabor-Like Transforms}}},
  author = {Chaudhury, K.N. and Unser, Michael},
  year = {2009},
  month = sep,
  journal = {IEEE Transactions on Signal Processing},
  volume = {57},
  number = {9},
  pages = {3411--3425},
  doi = {10.1109/TSP.2009.2020767},
  abstract = {We propose a novel method for constructing Hilbert transform (HT) pairs of wavelet bases based on a fundamental approximation-theoretic characterization of scaling functions-the B-spline factorization theorem. In particular, starting from well-localized scaling functions, we construct HT pairs of biorthogonal wavelet bases of L2(R) by relating the corresponding wavelet filters via a discrete form of the continuous HT filter. As a concrete application of this methodology, we identify HT pairs of spline wavelets of a specific flavor, which are then combined to realize a family of complex wavelets that resemble the optimally-localized Gabor function for sufficiently large orders. Analytic wavelets, derived from the complexification of HT wavelet pairs, exhibit a one-sided spectrum. Based on the tensor-product of such analytic wavelets, and, in effect, by appropriately combining four separable biorthogonal wavelet bases of L2(R2), we then discuss a methodology for constructing 2-D directional-selective complex wavelets. In particular, analogous to the HT correspondence between the components of the 1-D counterpart, we relate the real and imaginary components of these complex wavelets using a multidimensional extension of the HT-the directional HT. Next, we construct a family of complex spline wavelets that resemble the directional Gabor functions proposed by Daugman. Finally, we present an efficient fast Fourier transform (FFT)-based filterbank algorithm for implementing the associated complex wavelet transform. {\copyright} 2009 IEEE.},
  keywords = {Analytic signal,B-spline multiresolution,Biorthogonal wavelet basis,Directional Hilbert transform,Dual-tree complex wavelet transform,Gabor function,Hilbert transform,Time-frequency localization},
  file = {/home/wouter/Zotero/storage/FDWTB4WH/Chaudhury, Unser - 2009 - Construction of Hilbert Transform Pairs of Wavelet Bases and Gabor-Like Transforms.pdf}
}

@article{chaudhury2011,
  title = {On the {{Hilbert Transform}} of {{Wavelets}}},
  author = {Chaudhury, Kunal N. and Unser, Michael},
  year = {2011},
  month = apr,
  journal = {IEEE Transactions on Signal Processing},
  volume = {59},
  number = {4},
  pages = {1890--1894},
  doi = {10.1109/TSP.2010.2103072},
  abstract = {A wavelet is a localized function having a prescribed number of vanishing moments. In this correspondence, we provide precise arguments as to why the Hilbert transform of a wavelet is again a wavelet. In particular, we provide sharp estimates of the localization, vanishing moments, and smoothness of the transformed wavelet. We work in the general setting of non-compactly supported wavelets. Our main result is that, in the presence of some minimal smoothness and decay, the Hilbert transform of a wavelet is again as smooth and oscillating as the original wavelet, whereas its localization is controlled by the number of vanishing moments of the original wavelet. We motivate our results using concrete examples. {\copyright} 2010 IEEE.},
  keywords = {Hilbert transform,localization,smoothness,vanishing moments,wavelets},
  file = {/home/wouter/Zotero/storage/6RMPX7VR/Chaudhury, Unser - 2011 - On the Hilbert Transform of Wavelets.pdf}
}

@article{chaumont-frelet2023,
  title = {Explicit Bounds for the High-Frequency Time-Harmonic {{Maxwell}} Equations in Heterogeneous Media},
  author = {{Chaumont-Frelet}, Th{\'e}ophile and Moiola, Andrea and Spence, Euan A.},
  year = {2023},
  journal = {Journal de Math{\'e}matiques Pures et Appliqu{\'e}es},
  volume = {179},
  pages = {183--218},
  publisher = {arXiv},
  issn = {0021-7824},
  doi = {10.1016/j.matpur.2023.09.004},
  urldate = {2025-03-24},
  abstract = {We consider the time-harmonic Maxwell equations posed in \${\textbackslash}mathbb\{R\}{\textasciicircum}3\$. We prove a priori bounds on the solution for \$L{\textasciicircum}{\textbackslash}infty\$ coefficients \${$\varepsilon\$$} and \${$\mu\$$} satisfying certain monotonicity properties, with these bounds valid for arbitrarily-large frequency, and explicit in the frequency and properties of \${$\varepsilon\$$} and \${$\mu\$$}. The class of coefficients covered includes (i) certain \${$\varepsilon\$$} and \${$\mu\$$} for which well-posedness of the time-harmonic Maxwell equations had not previously been proved, and (ii) scattering by a penetrable \$C{\textasciicircum}0\$ star-shaped obstacle where \${$\varepsilon\$$} and \${$\mu\$$} are smaller inside the obstacle than outside. In this latter setting, the bounds are uniform across all such obstacles, and the first sharp frequency-explicit bounds for this problem at high-frequency.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Analysis of PDEs (math.AP),FOS: Mathematics}
}

@article{chen1997,
  title = {Spline {{Wavelets}} on the {{Unit Circle}}},
  author = {Chen, Han Lin},
  year = {1997},
  journal = {Results in Mathematics},
  volume = {31},
  number = {3-4},
  pages = {322--336},
  doi = {10.1007/BF03322168},
  abstract = {An orthonormal wavelet basis on the circle {$\gamma$} is constructed. By estabishing some new theorems on complex spline functions, the (Formula presented.) space can be decomposed into different orthogonal subspaces. Formulas of decomposition and reconstruction imply only two terms.},
  keywords = {65D07,65E05,Complex Splines on the Circle,Decomposition,Fourier-transform,Reconstruction,Wavelets},
  file = {/home/wouter/Zotero/storage/5WGQ93FL/Chen - 1997 - Spline Wavelets on the Unit Circle.pdf}
}

@article{chen1999,
  title = {Real-Valued Periodic Wavelets: Construction and Relation with Fourier Series},
  author = {Chen, Han Lin and Liang, Xue Zhang and Peng, Si Long and Xiao, Shao Liang},
  year = {1999},
  journal = {Journal of Computational Mathematics},
  volume = {17},
  number = {5},
  pages = {509--522},
  abstract = {In this paper, we construct the real-valued periodic orthogonal wavelets. The method presented here is new. The decomposition and reconstruction formulas involve only 4 terms respectively. It demonstrates that the formulas are simpler than that in other kinds of periodic wavelets. Our wavelets are useful in applications since it is real valued. The relation between the periodic wavelets and the Fourier series is also discussed.},
  keywords = {Fourier series,Linear independence,Multiresolution,Periodic wavelet},
  file = {/home/wouter/Zotero/storage/K4FPLRF4/Chen et al. - 1999 - Real-valued periodic wavelets construction and relation with fourier series.pdf}
}

@article{chen2014,
  title = {Parametric Analytical Preconditioning and Its Applications to the Reduced Collocation Methods},
  author = {Chen, Yanlai and Gottlieb, Sigal and Maday, Yvon},
  year = {2014},
  journal = {Comptes Rendus Mathematique},
  volume = {352},
  number = {7-8},
  pages = {661--666},
  publisher = {Elsevier Masson SAS},
  doi = {10.1016/j.crma.2014.06.001},
  abstract = {In this paper, we extend the recently developed reduced collocation method [3] to the nonlinear case, and propose two analytical preconditioning strategies. One is parameter independent and easy to implement, the other one has the traditional affinity with respect to the parameters, which allows an efficient implementation through an offline-online decomposition. Overall, preconditioning improves the quality of the error estimation uniformly on the parameter domain, and speeds up the convergence of the reduced solution to the truth approximation. {\copyright} 2014 Acad{\'e}mie des sciences.},
  file = {/home/wouter/Zotero/storage/GMGSWY2V/Chen, Gottlieb, Maday - 2014 - Parametric analytical preconditioning and its applications to the reduced collocation methods.pdf}
}

@article{chen2015,
  title = {Lengths, Areas and {{Lipschitz-type}} Spaces of Planar Harmonic Mappings},
  author = {Chen, Shaolin and Ponnusamy, Saminathan and Rasila, Antti},
  year = {2015},
  journal = {Nonlinear Analysis, Theory, Methods and Applications},
  volume = {115},
  pages = {62--70},
  publisher = {Elsevier Ltd},
  doi = {10.1016/j.na.2014.12.005},
  abstract = {In this paper, we give bounds for length and area distortion for harmonic K-quasiconformal mappings, and investigate certain Lipschitz-type spaces on harmonic mappings.},
  keywords = {Area function,Hardy and lipschitz spaces,Harmonic and bloch mappings,Length,Quasiconformal mappings},
  file = {/home/wouter/Zotero/storage/HME9QDZR/Chen, Ponnusamy, Rasila - 2015 - Lengths, areas and Lipschitz-type spaces of planar harmonic mappings.pdf}
}

@article{chen2019,
  title = {Lipschitz Continuity for Solutions of the {{Triharmonic}} Equation},
  author = {Chen, Xingdi},
  year = {2019},
  journal = {Science China Mathematics},
  volume = {62},
  number = {10},
  pages = {1935--1946},
  publisher = {Hindawi},
  doi = {10.1007/s11425-016-9300-5},
  abstract = {In this paper, we study the Lipschitz continuity for solutions of the {\=undefined}-Poisson equation. After characterizing the boundary conditions for the Lipschitz continuity of {\=undefined}-harmonic mappings, we present four equivalent conditions for the (K,K{$\prime$})-quasiconformal solutions of the {\=undefined}-Poisson equation with a nonhomogeneous term to be Lipschitz continuous.},
  keywords = {(K,30C40,30C65,31A05,35J25,Dirichlet boundary problem,harmonic mapping,K')-quasiconformal mapping,Lipschitz continuity,weighted Laplacian operator}
}

@article{chen2024,
  title = {A Matrix-Free Parallel Solution Method for the Three-Dimensional Heterogeneous {{Helmholtz}} Equation},
  author = {Chen, J. and Dwarka, V. and Vuik, Cees},
  year = {2024},
  journal = {ETNA - Electronic Transactions on Numerical Analysis},
  volume = {59},
  number = {Ic},
  pages = {270--294},
  doi = {10.1553/etna_vol59s270},
  abstract = {In the ddCOSMO solvation model for the numerical simulation of molecules (chains of atoms), the unusual observation was made that the associated Schwarz domain-decomposition method converges independently of the number of subdomains (atoms) and this without coarse correction, i.e., the one-level Schwarz method is scalable. We analyzed this unusual property for the simplified case of a rectangular molecule and square subdomains using Fourier analysis, leading to robust convergence estimates in the L2-norm and later also for chains of subdomains represented by disks using maximum principle arguments, leading to robust convergence estimates in L{$\infty$}. A convergence analysis in the more natural H1-setting proving convergence independently of the number of subdomains was, however, missing. We close this gap in this paper using tools from the theory of alternating projection methods and estimates introduced by P.-L. Lions for the study of domain decomposition methods. We prove that robust convergence independently of the number of subdomains is possible also in H1 and show furthermore that even for certain two-dimensional domains with holes, Schwarz methods can be scalable without coarse-space corrections. As a by-product, we review some of the results of P.-L. Lions [On the Schwarz alternating method. I, in Domain Decomposition Methods for Partial Differential Equations, SIAM, Philadelphia, 1988, pp. 1--42] and in some cases provide simpler proofs.},
  keywords = {Chain of subdomains,COSMO solvation model,Domain decomposition methods,Elliptic PDE,Laplace equation,Schwarz methods},
  file = {/home/wouter/Zotero/storage/CS89W26W/Chen, Dwarka, Vuik - 2024 - A matrix-free parallel solution method for the three-dimensional heterogeneous Helmholtz equation.pdf}
}

@inproceedings{chew1985,
  title = {Voronoi Diagrams Based on Convex Distance Functions},
  booktitle = {Proceedings of the First Annual Symposium on {{Computational}} Geometry  - {{SCG}} '85},
  author = {Chew, Paul and Dyrsdale, Robert L.},
  year = {1985},
  pages = {235--244},
  publisher = {ACM Press},
  address = {Baltimore, Maryland, United States},
  doi = {10.1145/323233.323264},
  urldate = {2024-10-02},
  isbn = {978-0-89791-163-4},
  langid = {english}
}

@article{chkifa2012,
  title = {Sparse Adaptive {{Taylor}} Approximation Algorithms for Parametric and Stochastic Elliptic {{PDEs}}},
  author = {Chkifa, Abdellah and Cohen, Albert and Devore, Ronald and Schwab, Christoph},
  year = {2012},
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  volume = {47},
  number = {1},
  pages = {253--280},
  doi = {10.1051/m2an/2012027},
  abstract = {The numerical approximation of parametric partial differential equations is a computational challenge, in particular when the number of involved parameter is large. This paper considers a model class of second order, linear, parametric, elliptic PDEs on a bounded domain D with diffusion coefficients depending on the parameters in an affine manner. For such models, it was shown in [9, 10] that under very weak assumptions on the diffusion coefficients, the entire family of solutions to such equations can be simultaneously approximated in the Hilbert space V = H01(D) by multivariate sparse polynomials in the parameter vector y with a controlled number N of terms. The convergence rate in terms of N does not depend on the number of parameters in V, which may be arbitrarily large or countably infinite, thereby breaking the curse of dimensionality. However, these approximation results do not describe the concrete construction of these polynomial expansions, and should therefore rather be viewed as benchmark for the convergence analysis of numerical methods. The present paper presents an adaptive numerical algorithm for constructing a sequence of sparse polynomials that is proved to converge toward the solution with the optimal benchmark rate. Numerical experiments are presented in large parameter dimension, which confirm the effectiveness of the adaptive approach. {\copyright} 2012 EDP Sciences, SMAI.},
  keywords = {Adaptive algorithms,High dimensional problems,Parametric and stochastic PDE's,Sparse polynomial approximation},
  file = {/home/wouter/Zotero/storage/RANQJLKZ/Chkifa et al. - 2012 - Sparse adaptive Taylor approximation algorithms for parametric and stochastic elliptic PDEs.pdf}
}

@article{chkifa2013,
  title = {On the {{Lebesgue}} Constant of {{Leja}} Sequences for the Complex Unit Disk and of Their Real Projection},
  author = {Chkifa, Moulay Abdellah},
  year = {2013},
  journal = {Journal of Approximation Theory},
  volume = {166},
  number = {1},
  pages = {176--200},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jat.2012.11.005},
  abstract = {We consider Leja sequences of points for polynomial interpolation on the complex unit disk U and the corresponding sequences for polynomial interpolation on the real interval [ - 1, 1] obtained by projection. It was proved by Calvi and Phung in Calvi and Phung (2011, 2012) [3,4] that the Lebesgue constants for such sequences are asymptotically bounded in O(klogk) and O(k3logk) respectively, where k is the number of points. In this paper, we establish the sharper bound 5k2 log k in the real interval case. We also give sharper bounds in the complex unit disk case, in particular 2k. Our motivation for producing such sharper bounds is the use of these sequences in the framework of adaptive sparse polynomial interpolation in high dimension. {\copyright} 2012 Elsevier Inc.},
  keywords = {Gauss-Lobatto points,Lagrange interpolation,Lebesgue constant,Leja sequences,Roots of unity},
  file = {/home/wouter/Zotero/storage/IRYGUVZM/Chkifa - 2013 - On the Lebesgue constant of Leja sequences for the complex unit disk and of their real projection.pdf}
}

@article{chkifa2014,
  title = {High-{{Dimensional Adaptive Sparse Polynomial Interpolation}} and {{Applications}} to {{Parametric PDEs}}},
  author = {Chkifa, Abdellah and Cohen, Albert and Schwab, Christoph},
  year = {2014},
  journal = {Foundations of Computational Mathematics},
  volume = {14},
  number = {4},
  pages = {601--633},
  doi = {10.1007/s10208-013-9154-z},
  abstract = {We consider the problem of Lagrange polynomial interpolation in high or countably infinite dimension, motivated by the fast computation of solutions to partial differential equations (PDEs) depending on a possibly large number of parameters which result from the application of generalised polynomial chaos discretisations to random and stochastic PDEs. In such applications there is a substantial advantage in considering polynomial spaces that are sparse and anisotropic with respect to the different parametric variables. In an adaptive context, the polynomial space is enriched at different stages of the computation. In this paper, we study an interpolation technique in which the sample set is incremented as the polynomial dimension increases, leading therefore to a minimal amount of PDE solving. This construction is based on the standard principle of tensorisation of a one-dimensional interpolation scheme and sparsification. We derive bounds on the Lebesgue constants for this interpolation process in terms of their univariate counterpart. For a class of model elliptic parametric PDE's, we have shown in Chkifa et al. (Mod{\'e}l. Math. Anal. Num{\'e}r. 47(1):253-280, 2013) that certain polynomial approximations based on Taylor expansions converge in terms of the polynomial dimension with an algebraic rate that is robust with respect to the parametric dimension. We show that this rate is preserved when using our interpolation algorithm. We also propose a greedy algorithm for the adaptive selection of the polynomial spaces based on our interpolation scheme, and illustrate its performance both on scalar valued functions and on parametric elliptic PDE's. {\copyright} 2013 SFoCM.},
  keywords = {Adaptive algorithms,High-dimensional problems,Lebesgue constants,Leja points,Parametric and stochastic PDEs,Sparse polynomial approximation},
  file = {/home/wouter/Zotero/storage/AAWQK4AS/Chkifa, Cohen, Schwab - 2014 - High-Dimensional Adaptive Sparse Polynomial Interpolation and Applications to Parametric PDEs.pdf}
}

@article{chkifa2015,
  title = {Breaking the Curse of Dimensionality in Sparse Polynomial Approximation of Parametric {{PDEs}}},
  author = {Chkifa, Abdellah and Cohen, Albert and Schwab, Christoph},
  year = {2015},
  journal = {Journal des Mathematiques Pures et Appliquees},
  volume = {103},
  number = {2},
  pages = {400--428},
  doi = {10.1016/j.matpur.2014.04.009},
  abstract = {The numerical approximation of parametric partial differential equations D(u,y)=0 is a computational challenge when the dimension d of the parameter vector y is large, due to the so-called curse of dimensionality. It was recently shown in [1,2] that, for a certain class of elliptic PDEs with diffusion coefficients depending on the parameters in an affine manner, there exist polynomial approximations to the solution map y{$\mapsto$}u(y) with an algebraic convergence rate that is independent of the parametric dimension d. The analysis in [1,2] used, however, the affine parameter dependence of the operator. The present paper proposes a strategy for establishing similar results for classes of parametric PDEs that do not necessarily fall in this category. Our approach is based on building an analytic extension z{$\mapsto$}u(z) of the solution map on certain tensor product of ellipses in the complex domain, and using this extension to estimate the Legendre coefficients of u. The varying semi-axes lengths of the ellipses in each coordinate zj reflect the anisotropy of the solution map with respect to the corresponding parametric variables yj. This allows us to derive algebraic convergence rates for tensorized Legendre expansions in the case d={$\infty$}. We also show that such rates are preserved when using certain interpolation procedures, which is an instance of a non-intrusive method. As examples of parametric PDEs that are covered by this approach, we consider (i) elliptic diffusion equations with coefficients that depend on the parameter vector y in a not necessarily affine manner, (ii) parabolic diffusion equations with similar dependence of the coefficient on y, (iii) nonlinear, monotone parametric elliptic PDEs, and (iv) elliptic equations set on a domain that is parametrized by the vector y. We give general strategies that allow us to derive the analytic extension in a unified abstract way for all these examples, in particular based on the holomorphic version of the implicit function theorem in Banach spaces. We expect that this approach can be applied to a large variety of parametric PDEs, showing that the curse of dimensionality can be overcome under mild assumptions.},
  keywords = {Curse of dimensionality,Parametric PDEs,Sparse high dimensional interpolation,Sparse Legendre series},
  file = {/home/wouter/Zotero/storage/CDH2QVGK/Chkifa, Cohen, Schwab - 2015 - Breaking the curse of dimensionality in sparse polynomial approximation of parametric PDEs.pdf}
}

@article{chui1991,
  title = {A {{Cardinal Spline Approach}} to {{Wavelets}}},
  author = {Chui, Charles K. and Wang, Jian-Zhong},
  year = {1991},
  journal = {Proceedings of the American Mathematical Society},
  volume = {113},
  number = {3},
  pages = {785--785},
  doi = {10.2307/2048616},
  abstract = {While it is well known that the mth order B-spline N(m)(x) with integer knots generates a multiresolution analysis, ... subset-of V-1 subset-of V0 subset-of ..., with the mth order of approximation, we prove that psi(x):  = L2m(m)(2x - 1), where L2m(x) denotes the (2m)th order fundamental cardinal interpolatory spline, generates the orthogonal complementary wavelet spaces W(k).  Note that for m = 1, when the B-spline N1(x) is the characteristic function of the unit interval [0, 1), our basic wavelet L2'(2x - 1) is simply the well-known Haar wavelet.  In proving that V(k+1) = V(k) + W(k), we give the exact formulation of N(m)(2x - j), j is-an-element-of Z, in terms of integer translates of N(m)(x) and psi(x).  This allows us to derive a wavelet decomposition algorithm without relying on orthogonality nor construction of a dual basis.},
  file = {/home/wouter/Zotero/storage/M7TBIF7P/Chui, Wang - 1991 - A Cardinal Spline Approach to Wavelets.pdf}
}

@article{chui1992,
  title = {A General Framework of Compactly Supported Splines and Wavelets},
  author = {Chui, Charles K. and zhong Wang, Jian},
  year = {1992},
  journal = {Journal of Approximation Theory},
  volume = {71},
  number = {3},
  pages = {263--304},
  doi = {10.1016/0021-9045(92)90120-D},
  abstract = {Let \{Vk\} be a nested sequence of closed subspaces that constitute a multiresolution analysis of L2(R). We characterize the family {$\Phi$} = \{{$\varphi$}\} where each {$\varphi$} generates this multiresolution analysis such that the two-scale relation of {$\varphi$} is governed by a finite sequence. In particular, we identify the {\texttheta}\{symbol\} {$\varepsilon$}\{lunate\} {$\Phi$} that has minimum support. We also characterize the collection {$\Psi$} of functions {$\eta$} such that each {$\eta$} generates the orthogonal complementary subspaces Wk of Vk, {$\in$}Z. In particular, the minimally supported {$\psi$} {$\varepsilon$}\{lunate\} {$\Psi$} is determined. Hence, the "B-spline" and "B-wavelet" pair ({\texttheta}\{symbol\}, {$\psi$}) provides the most economical and computational efficient "spline" representations and "wavelet" decompositions of L2 functions from the "spline" spaces Vk and "wavelet" spaces Wk, k{$\in$}Z. A very general duality principle, which yields the dual bases of both \{{\texttheta}\{symbol\}({$\cdot$}-j):j{$\in$}Z and \{{$\eta$}({$\cdot$}-j):j{$\in$}Z\} for any {$\eta$} {$\varepsilon$}\{lunate\} {$\Psi$} by essentially interchanging the pair of two-scale sequences with the pair of decomposition sequences, is also established. For many filtering applications, it is very important to select a multiresolution for which both {\texttheta}\{symbol\} and {$\psi$} have linear phases. Hence, "non-symmetric" {\texttheta}\{symbol\} and {$\psi$}, such as the compactly supported orthogonal ones introduced by Daubechies, are sometimes undesirable for these applications. Conditions on linear-phase {$\varphi$} and {$\psi$} are established in this paper. In particular, even-order polynomial B-splines and B-wavelets {$\varphi$}m and {$\psi$}m have linear phases, but the odd-order B-wavelet only has generalized linear phases. {\copyright} 1992.\vphantom\}},
  file = {/home/wouter/Zotero/storage/ME6DLZ56/Chui, Wang - 1992 - A general framework of compactly supported splines and wavelets.pdf}
}

@article{chui1992a,
  title = {On Compactly Supported Spline Wavelets and a {{Duality Principle}}},
  author = {Chui, Charles K. and Wang, Jian-zhong},
  year = {1992},
  volume = {330},
  number = {2},
  pages = {903--915},
  keywords = {and phrases,compactly supported wavelets,decomposition,dms 89-0-01345,dual bases,duality principle,reconstruc-,ss-splines,supported by nsf grants,tion},
  file = {/home/wouter/Zotero/storage/BZQQNUAS/Chui, Wang - 1992 - On Compactly Supported Spline Wavelets and a Duality Principle.pdf;/home/wouter/Zotero/storage/XI96AYFE/Chui, Wang - 1992 - On compactly supported spline wavelets and a Duality Principle.pdf}
}

@article{chui1996,
  title = {A Study of Orthonormal Multi-Wavelets},
  author = {Chui, Charles K. and Lian, Jian Ao},
  year = {1996},
  journal = {Applied Numerical Mathematics},
  volume = {20},
  number = {3},
  pages = {273--298},
  doi = {10.1016/0168-9274(95)00111-5},
  abstract = {A general scheme for constructing symmetric and/or antisymmetric compactly supported orthonormal multi-scaling functions and multi-wavelets is introduced. The main emphasis is on maximum order of polynomial-reproduction by the scaling functions, or equivalently maximum number of vanishing moments for the corresponding wavelets; particularly for those that have small supports and those that satisfy certain Hermite interpolating conditions. As an application, we recover the Geronimo-Hardin-Massopust multi-scaling function without using fractal interpolation, and consequently the corresponding Strang-Strela multi-wavelet. Explicit formulations of the two-scale relations and polynomial-reproduction identities for the scaling functions with supports [0,2] and [0,3] and multiplicity 2 as well as their corresponding multi-wavelet are also derived by following our general constructive scheme.},
  keywords = {Compactly supported functions,Multi-scaling functions,Multi-wavelets,Symmetric and antisymmetric functions,Two-scale symbols},
  file = {/home/wouter/Zotero/storage/M927CHKA/Chui, Lian - 1996 - A study of orthonormal multi-wavelets.pdf}
}

@article{church2022,
  title = {Extensions to the {{Weber}} Problem},
  author = {Church, Richard L. and Drezner, Zvi and Tamir, Arie},
  year = {2022},
  month = jul,
  journal = {Computers \& Operations Research},
  volume = {143},
  pages = {105786},
  issn = {03050548},
  doi = {10.1016/j.cor.2022.105786},
  urldate = {2024-09-13},
  abstract = {One of the classics in the field of Location Science is the book on the theory of industrial location by Weber (1909). Weber used a simple construct comprised of a 3-point triangle to describe important issues, including where raw materials for manufacturing are sourced. Virtually all of the research conducted in the last 50 years related to Weber's construct has overlooked major elements of his work. This includes the issue of sourcing needed raw materials, which can be limited, as an integral part the location problem. This paper explores one form of raw material sourcing first described by Weber in which each raw material source is limited by a fixed capacity. We show that most instances of this location problem are non-convex as well as propose a solution procedure. We also explore a related problem where the facility itself can be of limited capacity and not all demands can be served. These two models can serve as building blocks for a greater exploration of many of the important problem facets proposed by Weber in his seminal work.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/PPL9SSVX/Church et al. - 2022 - Extensions to the Weber problem.pdf}
}

@article{cimpeanu2015,
  title = {A Parameter-Free Perfectly Matched Layer Formulation for the Finite-Element-Based Solution of the {{Helmholtz}} Equation},
  author = {Cimpeanu, Radu and Martinsson, Anton and Heil, Matthias},
  year = {2015},
  journal = {Journal of Computational Physics},
  volume = {296},
  pages = {329--347},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jcp.2015.05.006},
  abstract = {This paper presents a parameter-free perfectly matched layer (PML) method for the finite-element-based solution of the Helmholtz equation. We employ one of Berm{\'u}dez et al.'s unbounded absorbing functions for the complex coordinate mapping underlying the PML. With this choice, the only free parameter that controls the accuracy of the numerical solution for a fixed numerical cost (characterised by the number of elements in the bulk and the PML regions) is the thickness of the perfectly matched layer, {$\delta$}PML. We show that, for the case of planar waves, the absorbing function performs best for PMLs whose thickness is much smaller than the wavelength. We then perform extensive numerical experiments to explore its performance for non-planar waves, considering domain shapes with smooth and polygonal boundaries, different solution types (smooth and singular), and a wide range of wavenumbers, k, to identify an optimal range for the normalised PML thickness, k{$\delta$}PML, such that, within this range, the error introduced by the presence of the PML is consistently small and insensitive to change. This implies that if the PML thickness is chosen from within this range no further PML optimisation is required, i.e. the method is parameter-free. We characterise the dependence of the error on the discretisation parameters and establish the conditions under which the convergence of the solution under mesh refinement is controlled exclusively by the discretisation of the bulk mesh.},
  keywords = {Acoustic scattering,Finite element method,Helmholtz equation,Perfectly matched layers},
  file = {/home/wouter/Zotero/storage/VWJN2FYP/Cimpeanu, Martinsson, Heil - 2015 - A parameter-free perfectly matched layer formulation for the finite-element-based solution of the He.pdf}
}

@article{cizmas2008,
  title = {Mesh {{Generation}} and {{Deformation Algorithm}} for {{Aeroelasticity Simulations}}},
  author = {Cizmas, Paul G. A. and Gargoloff, Joaquin I.},
  year = {2008},
  month = may,
  journal = {Journal of Aircraft},
  volume = {45},
  number = {3},
  pages = {1062--1066},
  doi = {10.2514/1.30896}
}

@article{cliffe2011,
  title = {Multilevel {{Monte Carlo}} Methods and Applications to Elliptic {{PDEs}} with Random Coefficients},
  author = {Cliffe, K. A. and Giles, M. B. and Scheichl, R. and Teckentrup, A. L.},
  year = {2011},
  journal = {Computing and Visualization in Science},
  volume = {14},
  number = {1},
  pages = {3--15},
  doi = {10.1007/s00791-011-0160-x},
  abstract = {We consider the numerical solution of elliptic partial differential equations with random coefficients. Such problems arise, for example, in uncertainty quantification for groundwater flow. We describe a novel variance reduction technique for the standard Monte Carlo method, called the multilevel Monte Carlo method, and demonstrate numerically its superiority. The asymptotic cost of solving the stochastic problem with the multilevel method is always significantly lower than that of the standard method and grows only proportionally to the cost of solving the deterministic problem in certain circumstances. Numerical calculations demonstrating the effectiveness of the method for one- and two-dimensional model problems arising in groundwater flow are presented. {\copyright} 2011 Springer-Verlag.},
  keywords = {Monte Carlo,Multilevel,Stochastic PDE},
  file = {/home/wouter/Zotero/storage/E8GHYZHB/Cliffe et al. - 2011 - Multilevel Monte Carlo methods and applications to elliptic PDEs with random coefficients.pdf}
}

@article{clines2022,
  title = {Efficient {{Order-Optimal Preconditioners}} for {{Implicit Runge-Kutta}} and {{Runge-Kutta-Nystr}}{\textbackslash}"om {{Methods Applicable}} to a {{Large Class}} of {{Parabolic}} and {{Hyperbolic PDEs}}},
  author = {Clines, Michael R. and Howle, Victoria E. and Long, Katharine R.},
  year = {2022},
  month = jun,
  journal = {SIAM J. Sci. Comp. v},
  volume = {29},
  pages = {475--495},
  abstract = {We generalize previous work by Mardal, Nilssen, and Staff (2007, SIAM J. Sci. Comp. v. 29, pp. 361-375) and Rana, Howle, Long, Meek, and Milestone (2021, SIAM J. Sci. Comp. v. 43, p. 475-495) on order-optimal preconditioners for parabolic PDEs to a larger class of differential equations and methods. The problems considered are those of the forms \$u\_\{t\}=-{\textbackslash}mathcal\{K\}u+g\$ and \$u\_\{tt\}=-{\textbackslash}mathcal\{\{K\}\}u+g\$, where the operator \${\textbackslash}mathcal\{\{K\}\}\$ is defined by \${\textbackslash}mathcal\{\{K\}\}u:=-{\textbackslash}nabla{\textbackslash}cdot{\textbackslash}left({\textbackslash}alpha{\textbackslash}nabla u{\textbackslash}right)+{\textbackslash}beta u\$ and the functions \${\textbackslash}alpha\$ and \${\textbackslash}beta\$ are restricted so that \${\textbackslash}alpha{$>$}0\$, and \${\textbackslash}beta{\textbackslash}ge0\$. The methods considered are A-stable implicit Runge--Kutta methods for the parabolic equation and implicit Runge--Kutta--Nystr{\textbackslash}"om methods for the hyperbolic equation. We prove the order optimality of a class of block preconditioners for the stage equation system arising from these problems, and furthermore we show that the LD and DU preconditioners of Rana et al. are in this class. We carry out numerical experiments on several test problems in this class -- the 2D diffusion equation, Pennes bioheat equation, the wave equation, and the Klein--Gordon equation, with both constant and variable coefficients. Our experiments show that these preconditioners, particularly the LD preconditioner, are successful at reducing the condition number of the systems as well as improving the convergence rate and solve time for GMRES applied to the stage equations.},
  keywords = {65L06,65N30,Implicit Runge-Kutta,Iterative Methods,Preconditioners,Runge-Kutta-Nystrom AMS subject classifications 65},
  file = {/home/wouter/Zotero/storage/BKI5K4E8/Clines, Howle, Long - 2022 - Efficient Order-Optimal Preconditioners for Implicit Runge-Kutta and Runge-Kutta-Nystrom Methods Applicable.pdf}
}

@article{clunie1984,
  title = {Harmonic Univalent Functions},
  author = {Clunie, J. and {Sheil-Small}, T.},
  year = {1984},
  journal = {Annales Academiae Scientiarum Fennicae Series A I Mathematica},
  volume = {9},
  pages = {3--25},
  doi = {10.5186/aasfm.1984.0905},
  file = {/home/wouter/Zotero/storage/NA92HFHD/Clunie, Sheil-Small - 1984 - Harmonic univalent functions.pdf}
}

@article{cocquet2017,
  title = {How Large a Shift Is Needed in the Shifted {{Helmholtz}} Preconditioner for Its Effective Inversion by Multigrid?},
  author = {Cocquet, Pierre Henri and Gander, Martin J.},
  year = {2017},
  journal = {SIAM Journal on Scientific Computing},
  volume = {39},
  number = {2},
  pages = {A438-A478},
  doi = {10.1137/15M102085X},
  abstract = {The shifted Helmholtz operator has received a lot of attention over the past decade as a preconditioner for the iterative solution of the Helmholtz equation. The idea is that if one uses a small complex shift, the shifted Helmholtz operator is still close to the original Helmholtz operator and could thus be an effective preconditioner. It was shown in [M. J. Gander, I. G. Graham, and E. A. Spence, Numer. Math., 53(2015), pp. 573-579] that the shift can be at most O(k) to prove rigorously wave number independent convergence of the preconditioned system solved with GMRES, provided the preconditioner is inverted exactly. In practice, however, the preconditioner is inverted only approximately, and if one shifts enough, this can be done effectively by standard multigrid methods. We show in this paper that for a finite element discretization, the shift has to be at least O(k2) to be able to invert the shifted Helmholtz preconditioner using multigrid. There is therefore a gap between being a good preconditioning operator (shift at most O(k)) and being able to effectively invert the preconditioner by multigrid (shift at least O(k2)). So what shift should be chosen in practice, and when is the preconditioner not inverted exactly? By studying the numerical range of the preconditioned operator, we show that one cannot obtain analytical results for this case with currently available tools. We thus test the preconditioner extensively numerically for a wave guide type square domain in the range of shifts between O({\textsurd}k) and O(k2) with approximate inversion by one multigrid V-cycle. We find in our experiments that preconditioned GMRES iteration numbers will then inevitably grow like O(k2). We also see that in contrast to common practice where shifts of O(k2) are used, it might be beneficial for the wave guide to use a smaller shift, e.g., O(k3/2), especially when several smoothing steps are used.},
  keywords = {Finite element,Helmholtz equation,Multigrid methods,Shifted Helmholtz preconditioner},
  file = {/home/wouter/Zotero/storage/NZHFNSWJ/Cocquet, Gander - 2017 - How large a shift is needed in the shifted Helmholtz preconditioner for its effective inversion by multigrid.pdf}
}

@article{cohen1960,
  title = {A {{Coefficient}} of {{Agreement}} for {{Nominal Scales}}},
  author = {Cohen, Jacob},
  year = {1960},
  month = apr,
  journal = {Educational and Psychological Measurement},
  volume = {20},
  number = {1},
  pages = {37--46},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/001316446002000104},
  urldate = {2025-03-05},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english}
}

@book{cohen2003,
  title = {Numerical {{Analysis}} of {{Wavelet Methods}}},
  author = {Cohen, Albert},
  year = {2003},
  pages = {357},
  publisher = {Elsevier B.V.},
  abstract = {Since their introduction in the 1980's, wavelets have become a powerful tool in mathematical analysis, with applications such as image compression, statistical estimation and numerical simulation of partial differential equations. One of their main attractive features is the ability to accurately represent fairly general functions with a small number of adaptively chosen wavelet coefficients, as well as to characterize the smoothness of such functions from the numerical behaviour of these coefficients. The theoretical pillar that underlies such properties involves approximation theory and function spaces, and plays a pivotal role in the analysis of wavelet-based numerical methods. This book offers a self-contained treatment of wavelets, which includes this theoretical pillar and it applications to the numerical treatment of partial differential equations. Its key features are: 1. Self-contained introduction to wavelet bases and related numerical algorithms, from the simplest examples to the most numerically useful general constructions. 2. Full treatment of the theoretical foundations that are crucial for the analysis of wavelets and other related multiscale methods : function spaces, linear and nonlinear approximation, interpolation theory. 3. Applications of these concepts to the numerical treatment of partial differential equations : multilevel preconditioning, sparse approximations of differential and integral operators, adaptive discretization strategies.},
  isbn = {978-0-08-053785-6},
  file = {/home/wouter/Zotero/storage/6LNY5W99/Cohen - 2003 - Numerical Analysis of Wavelet Methods.pdf}
}

@article{cohen2010,
  title = {Convergence {{Rates}} of {{Best N-term Galerkin Approximations}} for a {{Class}} of {{Elliptic sPDEs}}},
  author = {Cohen, Albert and DeVore, Ronald and Schwab, Christoph},
  year = {2010},
  journal = {Foundations of Computational Mathematics},
  volume = {10},
  number = {6},
  pages = {615--646},
  doi = {10.1007/s10208-010-9072-2},
  abstract = {Deterministic Galerkin approximations of a class of second order elliptic PDEs with random coefficients on a bounded domain D{$\subset\mathbb{R}$}d are introduced and their convergence rates are estimated. The approximations are based on expansions of the random diffusion coefficients in L2(D)-orthogonal bases, and on viewing the coefficients of these expansions as random parameters y = y({$\omega$}) = (yi({$\omega$})). This yields an equivalent parametric deterministic PDE whose solution u(x,y) is a function of both the space variable x{$\in$}D and the in general countably many parameters y. We establish new regularity theorems describing the smoothness properties of the solution u as a map from y{$\in$}U = (-1,1){$\infty$} to V = H01(D). These results lead to analytic estimates on the V norms of the coefficients (which are functions of x) in a so-called "generalized polynomial chaos" (gpc) expansion of u. Convergence estimates of approximations of u by best N-term truncated V valued polynomials in the variable y{$\in$}U are established. These estimates are of the form N-r, where the rate of convergence r depends only on the decay of the random input expansion. It is shown that r exceeds the benchmark rate 1/2 afforded by Monte Carlo simulations with N "samples" (i.e., deterministic solves) under mild smoothness conditions on the random diffusion coefficients. A class of fully discrete approximations is obtained by Galerkin approximation from a hierarchic family \{Vl\}l=0{$\infty$} {$\subseteq$} V of finite element spaces in D of the coefficients in the N-term truncated gpc expansions of u(x,y). In contrast to previous works, the level l of spatial resolution is adapted to the gpc coefficient. New regularity theorems describing the smoothness properties of the solution u as a map from y{$\in$}U = (-1,1){$\infty$} to a smoothness space W {$\subset$} V are established leading to analytic estimates on the W norms of the gpc coefficients and on their space discretization error. The space W coincides with H2 (D) {$\cap$} H01 (D) in the case where D is a smooth or convex domain. Our analysis shows that in realistic settings a convergence rate Ndof-s in terms of the total number of degrees of freedom Ndof can be obtained. Here the rate s is determined by both the best N-term approximation rate r and the approximation order of the space discretization in D. {\copyright} 2010 SFoCM.},
  keywords = {Approximation rates,Nonlinear approximation,Sparsity,Stochastic and parametric elliptic equations,Wiener polynomial chaos},
  file = {/home/wouter/Zotero/storage/IQFWBPHS/Cohen, DeVore, Schwab - 2010 - Convergence Rates of Best N-term Galerkin Approximations for a Class of Elliptic sPDEs.pdf}
}

@article{cohen2011,
  title = {Analytic Regularity and Polynomial Approximation of Parametric and Stochastic Elliptic {{PDE}}'{{S}}},
  author = {Cohen, Albert and Devore, Ronald and Schwab, Christoph},
  year = {2011},
  journal = {Analysis and Applications},
  volume = {9},
  number = {1},
  pages = {11--47},
  doi = {10.1142/S0219530511001728},
  abstract = {Parametric partial differential equations are commonly used to model physical systems. They also arise when Wiener chaos expansions are used as an alternative to Monte Carlo when solving stochastic elliptic problems. This paper considers a model class of second order, linear, parametric, elliptic PDE's in a bounded domain D with coefficients depending on possibly countably many parameters. It shows that the dependence of the solution on the parameters in the diffusion coefficient is analytically smooth. This analyticity is then exploited to prove that under very weak assumptions on the diffusion coefficients, the entire family of solutions to such equations can be simultaneously approximated by multivariate polynomials (in the parameters) with coefficients taking values in the Hilbert space V = H10(D) of weak solutions of the elliptic problem with a controlled number of terms N. The convergence rate in terms of N does not depend on the number of parameters in V which may be countable, therefore breaking the curse of dimensionality. The discretization of the coefficients from a family of continuous, piecewise linear finite element functions in D is shown to yield finite dimensional approximations whose convergence rate in terms of the overall number Ndof of degrees of freedom is the minimum of the convergence rates afforded by the best N-term sequence approximations in the parameter space and the rate of finite element approximations in D for a single instance of the parametric problem. {\copyright} 2011 World Scientific Publishing Company.},
  keywords = {adaptivity and sparsity,multivariate polynomial approximation,Stochastic and parametric elliptic equations},
  file = {/home/wouter/Zotero/storage/FYDIX9P9/Cohen, Devore, Schwab - 2011 - Analytic regularity and polynomial approximation of parametric and stochastic elliptic PDE'S.pdf}
}

@article{cohen2015,
  title = {Approximation of High-Dimensional Parametric {{PDEs}}},
  author = {Cohen, Albert and DeVore, Ronald},
  year = {2015},
  journal = {Acta Numerica},
  volume = {24},
  pages = {1--159},
  doi = {10.1017/S0962492915000033},
  abstract = {Parametrized families of PDEs arise in various contexts such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. In most of these applications, the number of parameters is large or perhaps even infinite. Thus, the development of numerical methods for these parametric problems is faced with the possible curse of dimensionality. This article is directed at (i) identifying and understanding which properties of parametric equations allow one to avoid this curse and (ii) developing and analysing effective numerical methods which fully exploit these properties and, in turn, are immune to the growth in dimensionality. Part I of this article studies the smoothness and approximability of the solution map, that is, the map a \{mapping\} u(a), where a is the parameter value and u(a) is the corresponding solution to the PDE. It is shown that for many relevant parametric PDEs, the parametric smoothness of this map is typically holomorphic and also highly anisotropic, in that the relevant parameters are of widely varying importance in describing the solution. These two properties are then exploited to establish convergence rates of n-term approximations to the solution map, for which each term is separable in the parametric and physical variables. These results reveal that, at least on a theoretical level, the solution map can be well approximated by discretizations of moderate complexity, thereby showing how the curse of dimensionality is broken. This theoretical analysis is carried out through concepts of approximation theory such as best n-term approximation, sparsity, and n-widths. These notions determine a priori the best possible performance of numerical methods and thus serve as a benchmark for concrete algorithms. Part II of this article turns to the development of numerical algorithms based on the theoretically established sparse separable approximations. The numerical methods studied fall into two general categories. The first uses polynomial expansions in terms of the parameters to approximate the solution map. The second one searches for suitable low-dimensional spaces for simultaneously approximating all members of the parametric family. The numerical implementation of these approaches is carried out through adaptive and greedy algorithms. An a priori analysis of the performance of these algorithms establishes how well they meet the theoretical benchmarks.},
  file = {/home/wouter/Zotero/storage/2BDBA8S2/Cohen, DeVore - 2015 - Approximation of high-dimensional parametric PDEs.pdf}
}

@article{cohen2018,
  title = {Shape {{Holomorphy}} of the {{Stationary Navier--Stokes Equations}}},
  author = {Cohen, Albert and Schwab, Christoph and Zech, Jakob},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {50},
  number = {2},
  pages = {1720--1752},
  doi = {10.1137/16M1099406},
  file = {/home/wouter/Zotero/storage/GBPUUM4N/Cohen, Schwab, Zech - 2018 - Shape Holomorphy of the Stationary Navier--Stokes Equations.pdf}
}

@article{cohen2021,
  title = {Near-Optimal Approximation Methods for Elliptic {{PDEs}} with Lognormal Coefficients},
  author = {Cohen, Albert and Migliorati, Giovanni},
  year = {2021},
  pages = {1--23},
  abstract = {This paper studies numerical methods for the approximation of elliptic PDEs with lognormal coefficients of the form \$-\{{\textbackslash}rm div\}(a{\textbackslash}nabla u)=f\$ where \$a={\textbackslash}exp(b)\$ and \$b\$ is a Gaussian random field. The approximant of the solution \$u\$ is an \$n\$-term polynomial expansion in the scalar Gaussian random variables that parametrize \$b\$. We present a general convergence analysis of weighted least-squares approximants for smooth and arbitrarily rough random field, using a suitable random design, for which we prove optimality in the following sense: their convergence rate matches exactly or closely the rate that has been established in {\textbackslash}cite\{BCDM\} for best \$n\$-term approximation by Hermite polynomials, under the same minimial assumptions on the Gaussian random field. This is in contrast with the current state of the art results for the stochastic Galerkin method that suffers the lack of coercivity due to the lognormal nature of the diffusion field. Numerical tests with \$b\$ as the Brownian bridge confirm our theoretical findings.},
  file = {/home/wouter/Zotero/storage/DXZNIVVT/Cohen, Migliorati - 2021 - Near-optimal approximation methods for elliptic PDEs with lognormal coefficients.pdf}
}

@article{collier2015,
  title = {A Continuation Multilevel {{Monte Carlo}} Algorithm},
  author = {Collier, Nathan and {Haji-Ali}, Abdul Lateef and Nobile, Fabio and {von Schwerin}, Erik and Tempone, Ra{\'u}l},
  year = {2015},
  journal = {BIT Numerical Mathematics},
  volume = {55},
  number = {2},
  pages = {399--432},
  publisher = {Springer Netherlands},
  doi = {10.1007/s10543-014-0511-3},
  abstract = {We propose a novel Continuation Multi Level Monte Carlo (CMLMC) algorithm for weak approximation of stochastic models. The CMLMC algorithm solves the given approximation problem for a sequence of decreasing tolerances, ending when the required error tolerance is satisfied. CMLMC assumes discretization hierarchies that are defined a priori for each level and are geometrically refined across levels. The actual choice of computational work across levels is based on parametric models for the average cost per sample and the corresponding variance and weak error. These parameters are calibrated using Bayesian estimation, taking particular notice of the deepest levels of the discretization hierarchy, where only few realizations are available to produce the estimates. The resulting CMLMC estimator exhibits a non-trivial splitting between bias and statistical contributions. We also show the asymptotic normality of the statistical error in the MLMC estimator and justify in this way our error estimate that allows prescribing both required accuracy and confidence in the final result. Numerical results substantiate the above results and illustrate the corresponding computational savings in examples that are described in terms of differential equations either driven by random measures or with random coefficients.},
  keywords = {Bayesian inference,Monte Carlo,Multilevel Monte Carlo,Partial differential equations with random data,Stochastic differential equations},
  file = {/home/wouter/Zotero/storage/L9EGGDNH/Collier et al. - 2015 - A continuation multilevel Monte Carlo algorithm.pdf}
}

@article{collino1998,
  title = {The Perfectly Matched Layer in Curvilinear Coordinates},
  author = {Collino, Francis and Monk, Peter},
  year = {1998},
  journal = {SIAM Journal of Scientific Computing},
  volume = {19},
  number = {6},
  pages = {2061--2090},
  doi = {10.1137/S1064827596301406},
  abstract = {In 1994 B{\'e}renger showed how to construct a perfectly matched absorbing layer for the Maxwell system in rectilinear coordinates. This layer absorbs waves of any wavelength and any frequency without reflection and thus can be used to artificially terminate the domain of scattering calculations. In this paper we show how to derive and implement the B{\'e}renger layer in curvilinear coordinates (in two space dimensions). We prove that an infinite layer of this type can be used to solve time harmonic scattering problems. We also show that the truncated B{\'e}renger problem has a solution except at a discrete set of exceptional frequencies (which might be empty). Finally numerical results show that the curvilinear layer can produce accurate solutions in the time and frequency domain.},
  keywords = {Absorbing layer,Finite element,Perfectly matched layer},
  file = {/home/wouter/Zotero/storage/9JJKKV6S/Collino, Monk - 1998 - The perfectly matched layer in curvilinear coordinates.pdf}
}

@article{comon2014,
  title = {Tensors : {{A}} Brief Introduction},
  author = {Comon, Pierre},
  year = {2014},
  month = may,
  journal = {IEEE Signal Processing Magazine},
  volume = {31},
  number = {3},
  pages = {44--53},
  doi = {10.1109/MSP.2014.2298533},
  abstract = {Tensor decompositions are at the core of many blind source separation (BSS) algorithms, either explicitly or implicitly. In particular, the canonical polyadic (CP) tensor decomposition plays a central role in the identification of underdetermined mixtures. Despite some similarities, CP and singular value decomposition (SVD) are quite different. More generally, tensors and matrices enjoy different properties, as pointed out in this brief introduction. {\copyright} 1991-2012 IEEE.},
  file = {/home/wouter/Zotero/storage/KPLRHQN8/Comon - 2014 - Tensors A brief introduction.pdf}
}

@article{contreras2018,
  title = {Parallel {{Domain Decomposition Strategies}} for {{Stochastic Elliptic Equations Part B}}: {{Accelerated Monte Carlo Sampling}} with {{Local PC Expansions}}},
  shorttitle = {Parallel {{Domain Decomposition Strategies}} for {{Stochastic Elliptic Equations Part B}}},
  author = {Contreras, Andres A. and Mycek, Paul and Le Ma{\^i}tre, Olivier P. and Rizzi, Francesco and Debusschere, Bert and Knio, Omar M.},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {4},
  pages = {C547-C580},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/17M1132197},
  urldate = {2025-03-28},
  langid = {english},
  file = {/home/wouter/Zotero/storage/FM6DN2UG/Contreras et al. - 2018 - Parallel Domain Decomposition Strategies for Stochastic Elliptic Equations Part B Accelerated Monte.pdf}
}

@article{cooper1963,
  title = {Location-{{Allocation Problems}}},
  author = {Cooper, Leon},
  year = {1963},
  month = jun,
  journal = {Operations Research},
  volume = {11},
  number = {3},
  pages = {331--343},
  issn = {0030-364X, 1526-5463},
  doi = {10.1287/opre.11.3.331},
  urldate = {2024-09-13},
  abstract = {The calculational aspects of solving certain classes of location-allocation problems are presented. Both exact extremal equations and a heuristic method are presented for solving these problems. Directions for further investigation are also indicated because of the need for methods to shorten the total amount of calculation involved.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/5KGSLH82/Cooper - 1963 - Location-Allocation Problems.pdf}
}

@article{cooper1972,
  title = {The {{Transportation-Location Problem}}},
  author = {Cooper, Leon},
  year = {1972},
  month = feb,
  journal = {Operations Research},
  volume = {20},
  number = {1},
  pages = {94--108},
  issn = {0030-364X, 1526-5463},
  doi = {10.1287/opre.20.1.94},
  urldate = {2024-09-13},
  abstract = {This paper defines a problem type, called the transportation-location problem, that can be considered a generalization of the Hitchcock transportation problem in which, in addition to seeking the amounts to be shipped from origins to destinations, it is also necessary to find, at the same time, the optimal locations of these sources with respect to a fixed and known set of destinations. This new problem is characterized mathematically, and exact and approximate methods are presented for its solution.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/B54Q7NSA/Cooper - 1972 - The Transportation-Location Problem.pdf}
}

@article{cooper1981,
  title = {The {{Weber}} Problem Revisited},
  author = {Cooper, Leon and Katz, Norman},
  year = {1981},
  journal = {Computers \& Mathematics with Applications},
  volume = {7},
  number = {3},
  pages = {225--234},
  issn = {08981221},
  doi = {10.1016/0898-1221(81)90082-1},
  urldate = {2024-10-03},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/G6HD5LYY/Cooper and Katz - 1981 - The Weber problem revisited.pdf}
}

@article{correnty2023,
  title = {Chebyshev {{HOPGD}} with Sparse Grid Sampling for Parameterized Linear Systems},
  author = {Correnty, Siobh{\'a}n and Freitag, Melina A. and Soodhalter, Kirk M.},
  year = {2023},
  month = sep,
  volume = {1},
  abstract = {We consider approximating solutions to parameterized linear systems of the form \$A({\textbackslash}mu\_1,{\textbackslash}mu\_2) x({\textbackslash}mu\_1,{\textbackslash}mu\_2) = b\$, where \$({\textbackslash}mu\_1, {\textbackslash}mu\_2) {\textbackslash}in {\textbackslash}mathbb\{R\}{\textasciicircum}2\$. Here the matrix \$A({\textbackslash}mu\_1,{\textbackslash}mu\_2) {\textbackslash}in {\textbackslash}mathbb\{R\}{\textasciicircum}\{n {\textbackslash}times n\}\$ is nonsingular, large, and sparse and depends nonlinearly on the parameters \${\textbackslash}mu\_1\$ and \${\textbackslash}mu\_2\$. Specifically, the system arises from a discretization of a partial differential equation and \$x({\textbackslash}mu\_1,{\textbackslash}mu\_2) {\textbackslash}in {\textbackslash}mathbb\{R\}{\textasciicircum}n\$, \$b {\textbackslash}in {\textbackslash}mathbb\{R\}{\textasciicircum}n\$. This work combines companion linearization with the Krylov subspace method preconditioned bi-conjugate gradient (BiCG) and a decomposition of a tensor matrix of precomputed solutions, called snapshots. As a result, a reduced order model of \$x({\textbackslash}mu\_1,{\textbackslash}mu\_2)\$ is constructed, and this model can be evaluated in a cheap way for many values of the parameters. Tensor decompositions performed on a set of snapshots can fail to reach a certain level of accuracy, and it is not known a priori if a decomposition will be successful. Moreover, the selection of snapshots can affect both the quality of the produced model and the computation time required for its construction. This new method offers a way to generate a new set of solutions on the same parameter space at little additional cost. An interpolation of the model is used to produce approximations on the entire parameter space, and this method can be used to solve a parameter estimation problem. Numerical examples of a parameterized Helmholtz equation show the competitiveness of our approach. The simulations are reproducible, and the software is available online.},
  keywords = {65f10,65f55,65n22,ams subject classifications,companion linearization,krylov methods,model,parameter estimation,reduced order,shifted linear systems,tensor decomposition},
  file = {/home/wouter/Zotero/storage/N4BRCJK2/Correnty, Freitag, Soodhalter - 2023 - Chebyshev HOPGD with sparse grid sampling for parameterized linear systems.pdf}
}

@article{cortes2006,
  title = {{{ON OUTGOING SOLUTIONS FOR A SYSTEM OF TIME-HARMONIC ELASTIC WAVE IN THE EXTERIOR OF A STAR-SHAPED DOMAIN}}},
  author = {Cort{\'e}s, Luis and Fern{\'a}ndez, Claudio and Perla, Gustavo},
  year = {2006},
  month = aug,
  journal = {Proyecciones (Antofagasta)},
  volume = {25},
  number = {2},
  issn = {0716-0917},
  doi = {10.4067/S0716-09172006000200006},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/JAQM26Z7/Cortés et al. - 2006 - ON OUTGOING SOLUTIONS FOR A SYSTEM OF TIME-HARMONIC ELASTIC WAVE IN THE EXTERIOR OF A STAR-SHAPED DO.pdf}
}

@article{cox1946,
  title = {Probability, {{Frequency}} and {{Reasonable Expectation}}},
  author = {Cox, R. T.},
  year = {1946},
  journal = {American Journal of Physics},
  volume = {14},
  number = {1},
  pages = {1--13},
  doi = {10.1119/1.1990764},
  abstract = {The concept of probability has from the beginning of the theroy involved two ideas: the idea of frequency in an ensmble and teh idea of reasonable expectation. He asks which is the Primary Concept. He then shows that the relations of probability as Reasonable Expectation are consistent with Symbolic Logic},
  file = {/home/wouter/Zotero/storage/SJREDRTK/Cox - 1946 - Probability, Frequency and Reasonable Expectation.pdf}
}

@book{craggs1973,
  title = {Applied {{Mathematical Sciences}}},
  author = {Craggs, J. W.},
  year = {1973},
  journal = {The Mathematical Gazette},
  volume = {57},
  pages = {80},
  doi = {10.2307/3615195},
  abstract = {This is the first of three volumes on partial differential equations. It introduces basic examples of partial differential equations, arising in continuum mechanics, electromagnetism, complex analysis and other areas, and develops a number of tools for their solution, including particularly Fourier analysis, distribution theory, and Sobolev spaces. These tools are applied to the treatment of basic problems in linear PDE, including the Laplace equation, heat equation, and wave equation, as well as more general elliptic, parabolic, and hyperbolic equations. Volume I prepares the way for studies of more advanced topics in linear PDE, in Volume 2, and for studies of nonlinear PDE, in Volume 3. The book is addressed to graduate students in mathematics and to professional mathematicians, with an interest in partial differential equations, mathematical physics, differential geometry, harmonic analysis, and complex analysis.},
  isbn = {978-1-4614-4941-6},
  file = {/home/wouter/Zotero/storage/8G446XQK/Craggs - 1973 - Applied Mathematical Sciences.pdf}
}

@book{cressie1993,
  title = {Statistics for {{Spatial Data}}},
  author = {Cressie, Noel},
  year = {1993},
  edition = {2},
  publisher = {John Wiley {\textbackslash}\& Sons},
  address = {Nashville, TN},
  isbn = {978-0-471-00255-0}
}

@article{crumpton1995,
  title = {Implicit Time Accurate Solutions on Unstructured Dynamic Grids},
  author = {Crumpton, P. I. and Giles, M. B.},
  year = {1995},
  journal = {12th Computational Fluid Dynamics Conference},
  number = {95},
  pages = {284--294},
  doi = {10.2514/6.1995-1671},
  abstract = {In this paper an unstructured multigrid algorithm is used as an iterative solution procedure for the discrete equations arising from an implicit time discretisation of the unsteady Euler equations on tetrahedral grids. To calculate unsteady flows due to oscillating boundaries, a novel grid movement algorithm is introduced, in which an elliptic equation with a nonlinear diffusion coefficient is used to define the displacement of interior grid nodes. This allows large grid displacements to be calculated in a single step. The multigrid technique uses a edge- collapsing algorithm to generate a sequence of grids, and a pseudo-timestepping smoother. On the coarser grids, no grid motion is used. Instead, surface normals are rotated consistently and transfer/interpolation weights are based on the time-averaged grid coordinates. A 2D NACA0012 test case is used to validate the program. 3D results are presented for the M6 wing and a full aircraft configuration.},
  file = {/home/wouter/Zotero/storage/ZHY39EAP/Crumpton, Giles - 1995 - Implicit time accurate solutions on unstructured dynamic grids.pdf}
}

@book{czumaj2018,
  title = {Proceedings of the {{Twenty-Ninth Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}}},
  editor = {Czumaj, Artur},
  year = {2018},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {Philadelphia, PA},
  doi = {10.1137/1.9781611975031},
  urldate = {2024-09-18},
  isbn = {978-1-61197-503-1},
  langid = {english},
  file = {/home/wouter/Zotero/storage/SM6BK2NR/3174304.3175466.pdf;/home/wouter/Zotero/storage/ZWCBQPPG/Czumaj - 2018 - Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms.pdf}
}

@article{dalcin2011,
  title = {Parallel Distributed Computing Using {{Python}}},
  author = {Dalcin, Lisandro D. and Paz, Rodrigo R. and Kler, Pablo A. and Cosimo, Alejandro},
  year = {2011},
  month = sep,
  journal = {Advances in Water Resources},
  volume = {34},
  number = {9},
  pages = {1124--1139},
  doi = {10.1016/j.advwatres.2011.04.013}
}

@article{dalembert1747,
  title = {Recherches Sur La Courbe Que {{Forme}} Une Corde},
  author = {{d'Alembert}, Jean le Rond},
  year = {1747},
  journal = {Histoire de l'Acad{\'e}mie royale des sciences et belles lettres de Berlin},
  series = {Memoires de l'{{Academie}} Royale Des Sciences et Belles Lettres. {{Classe}} de Mathematique.},
  pages = {214--219}
}

@article{dalsanto2019,
  title = {Multi Space Reduced Basis Preconditioners for Parametrized Partial Differential Equations},
  author = {Dal Santo, N. and Deparis, S. and Manzoni, A. and Quarteroni, A.},
  year = {2019},
  journal = {Computers and Mathematics with Applications},
  volume = {77},
  number = {6},
  pages = {1583--1604},
  doi = {10.1016/j.camwa.2018.09.036},
  abstract = {We introduce a two-level preconditioner for the efficient solution of large scale saddle-point linear systems arising from the finite element (FE) discretization of parametrized Stokes equations. This preconditioner extends the Multi Space Reduced Basis (MSRB) preconditioning method proposed in Dal Santo et al. (2018); it combines an approximated block (fine grid) preconditioner with a reduced basis (RB) solver which plays the role of coarse component. A sequence of RB spaces, constructed either with an enriched velocity formulation or a Petrov--Galerkin projection, is built. Each RB coarse component is defined to perform a single iteration of the iterative method at hand. The flexible GMRES (FGMRES) algorithm is employed to solve the resulting preconditioned system and targets small tolerances with a very small iteration count and in a very short time. Numerical test cases for Stokes flows in three dimensional parameter-dependent geometries are considered to assess the numerical properties of the proposed technique in different large scale computational settings.},
  keywords = {Computational fluid dynamics,Finite element method,Parametrized Stokes equations,Preconditioning techniques,Reduced basis method},
  file = {/home/wouter/Zotero/storage/ZV3NZWYH/Dal Santo et al. - 2019 - Multi space reduced basis preconditioners for parametrized partial differential equations.pdf}
}

@article{dambrine2016,
  title = {Numerical {{Solution}} of the {{Poisson Equation}} on {{Domains}} with a {{Thin Layer}} of {{Random Thickness}}},
  author = {Dambrine, Marc and Greff, Isabelle and Harbrecht, Helmut and Puig, B{\'e}n{\'e}dicte},
  year = {2016},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {54},
  number = {2},
  pages = {921--941},
  doi = {10.1137/140998652},
  file = {/home/wouter/Zotero/storage/QH2JP3CE/Dambrine et al. - 2016 - Numerical Solution of the Poisson Equation on Domains with a Thin Layer of Random Thickness.pdf;/home/wouter/Zotero/storage/YYMV9DAC/Dambrine et al. - 2016 - Numerical Solution of the Poisson Equation on Domains with a Thin Layer of Random Thickness.pdf}
}

@article{daneshzand2009,
  title = {Multifacility Location Problem},
  author = {Daneshzand, Farzaneh and Shoeleh, Razieh},
  year = {2009},
  journal = {Contributions to Management Science},
  number = {July 2009},
  pages = {69--92},
  issn = {9783790821512},
  doi = {10.1007/978-3-7908-2151-2_4},
  abstract = {In the previous chapter, we studied the case of a single new facility to be located relative to a number of existing facilities. In this chapter we consider the problem of optimally locating more than one new facilities with respect to locations of a number of existing facilities (demand points), the locations of which are known. While the problems are natural extension of those of single facility location, there are two important conditions: 1. At least two facilities are to be located 2. Each new facility is linked to at least one other new facility If the first condition contracted, this problem is considered as a single facility location problem (SFLP) and if the second condition contracted, we can consider the problem as some of independent single facility location problems. Thus the SFLP can be considered as a spatial case of the multifacility location problem (MFLP).},
  keywords = {Demand point,Dual problem,Facility location,Location problem,Objective function},
  file = {/home/wouter/Zotero/storage/JS2FRKEQ/Daneshzand, Shoeleh - 2009 - Multifacility location problem.pdf}
}

@article{dassios2011,
  title = {On the {{Global Relation}} and the {{Dirichlet-to-Neumann Correspondence}}},
  author = {Dassios, G. and Doschoris, M.},
  year = {2011},
  month = jan,
  journal = {Studies in Applied Mathematics},
  volume = {126},
  number = {1},
  pages = {75--102},
  doi = {10.1111/j.1467-9590.2010.00498.x},
  abstract = {The recently developed Fokas method for solving two-dimensional Boundary Value Problems (BVP) via the use of global relations is utilized to solve axisymmetric problems in three dimensions. In particular, novel integral representations for the interior and exterior Dirichlet and Neumann problems for the sphere are derived, which recover and improve the already known solutions of these problems. The BVPs considered in this paper can be classically solved using either the finite Legendre transform or the Mellin-sine transform (which can be derived from the classical Mellin transform in a way similar to the way that the sine transform can be derived from the Fourier transform). The Legendre transform representation is uniformly convergent at the boundary, but it involves a series that is not useful for many applications. The Mellin-sine transform involves of course an integral but it is not uniformly convergent at the boundary. In this paper: (a) The Legendre transform representation is rederived in a simpler approach using algebraic manipulations instead of solving ODEs. (b) An integral representation, different that the Mellin-sine transform representation is derived which is uniformly convergent at the boundary. Furthermore, the derivation of the Fokas approach involves only algebraic manipulations, instead of solving an ordinary differential equation. {\copyright} 2010 by the Massachusetts Institute of Technology.},
  file = {/home/wouter/Zotero/storage/XKWEUGI4/Dassios, Doschoris - 2011 - On the Global Relation and the Dirichlet-to-Neumann Correspondence.pdf}
}

@article{daubechies1988,
  title = {Orthonormal Bases of Compactly Supported Wavelets},
  author = {Daubechies, Ingrid},
  year = {1988},
  month = oct,
  journal = {Communications on Pure and Applied Mathematics},
  volume = {41},
  number = {7},
  pages = {909--996},
  publisher = {Princeton University Press},
  issn = {9781400827268},
  doi = {10.1002/cpa.3160410705},
  abstract = {We construct orthonormal bases of compactly supported wavelets, with arbitrarily high regularity. The order of regularity increases linearly with the support width. We start by reviewing the concept of multiresolution analysis as well as several algorithms in vision decomposition and reconstruction. The construction then follows from a synthesis of these different approaches.},
  file = {/home/wouter/Zotero/storage/EJVPLFHD/Daubechies - 1988 - Orthonormal bases of compactly supported wavelets.pdf}
}

@book{daubechies1992,
  title = {Ten {{Lectures}} on {{Wavelets}}},
  author = {Daubechies, Ingrid},
  year = {1992},
  month = jan,
  journal = {Philadelphia, PA:Sosiety for Industrial and Applied Mathematics Analysis},
  pages = {1576},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611970104},
  abstract = {Wavelets are a mathematical development that may revolutionize the world of information storage and retrieval according to many experts. They are a fairly simple mathematical tool now being applied to the compression of data---such as fingerprints, weather satellite photographs, and medical x-rays---that were previously thought to be impossible to condense without losing crucial details.{\textbackslash}r{\textbackslash}n{\textbackslash}r{\textbackslash}nThis monograph contains 10 lectures presented by Dr. Daubechies as the principal speaker at the 1990 CBMS-NSF Conference on Wavelets and Applications. The author has worked on several aspects of the wavelet transform and has developed a collection of wavelets that are remarkably efficient.{\textbackslash}r{\textbackslash}n{\textbackslash}r{\textbackslash}nThe opening chapter provides an overview of the main problems presented in the book. Following chapters discuss the theoretical and practical aspects of wavelet theory, including wavelet transforms, orthonormal bases of wavelets, and characterization of functional spaces by means of wavelets. The last chapter presents several topics under active research, as multidimensional wavelets, wavelet packet bases, and a construction of wavelets tailored to decompose functions defined in a finite interval. Because of their interdisciplinary origins, wavelets appeal to scientists and engineers of many different backgrounds.},
  isbn = {978-0-89871-274-2},
  file = {/home/wouter/Zotero/storage/E9GHGPNS/Daubechies - 1992 - Ten Lectures on Wavelets.pdf}
}

@incollection{daubechles1989,
  title = {Orthonormal {{Bases}} of {{Wavelets}} with {{Finite Support}} --- {{Connection}} with {{Discrete Filters}}},
  author = {Daubechles, Ingrid},
  year = {1989},
  pages = {38--66},
  doi = {10.1007/978-3-642-97177-8_3},
  file = {/home/wouter/Zotero/storage/AA7PAPY7/Daubechles - 1989 - Orthonormal Bases of Wavelets with Finite Support — Connection with Discrete Filters.pdf}
}

@article{dauphin2014,
  title = {Identifying and Attacking the Saddle Point Problem in High-Dimensional Non-Convex Optimization},
  author = {Dauphin, Yann N. and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  year = {2014},
  journal = {Advances in Neural Information Processing Systems},
  volume = {4},
  number = {January},
  pages = {2933--2941},
  abstract = {A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima with much higher error than the global minimum. Here we argue, based on results from statistical physics, random matrix theory, neural network theory, and empirical evidence, that a deeper and more profound difficulty originates from the proliferation of saddle points, not local minima, especially in high dimensional problems of practical interest. Such saddle points are surrounded by high error plateaus that can dramatically slow down learning, and give the illusory impression of the existence of a local minimum. Motivated by these arguments, we propose a new approach to second-order optimization, the saddle-free Newton method, that can rapidly escape high dimensional saddle points, unlike gradient descent and quasi-Newton methods. Weapply this algorithm to deep or recurrent neural network training, and provide numerical evidence for its superior optimization performance.},
  file = {/home/wouter/Zotero/storage/8VT56LJA/Dauphin et al. - 2014 - Identifying and attacking the saddle point problem in high-dimensional non-convex optimization.pdf}
}

@article{delange2025,
  title = {Preventing Congestion Management by Modelling Cable Temperatures: A Real-World Case},
  shorttitle = {Preventing Congestion Management by Modelling Cable Temperatures},
  author = {De Lange, Jordi and Rieken, Sander and Scarabosio, Laura and Lord, Gabriel J.},
  year = {2025},
  month = jan,
  journal = {IET Conference Proceedings},
  volume = {2024},
  number = {5},
  pages = {830--835},
  issn = {2732-4494},
  doi = {10.1049/icp.2024.2007},
  urldate = {2025-01-24},
  langid = {english}
}

@book{delaplace1820,
  title = {Th{\'e}orie Analytique Des Probabilit{\'e}s},
  author = {{de Laplace}, Pierre Simon},
  year = {1820},
  volume = {7},
  publisher = {Courcier}
}

@book{delfour2011,
  title = {Shapes and {{Geometries}}},
  author = {Delfour, M. C. and Zol{\'e}sio, J. -P.},
  year = {2011},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898719826},
  isbn = {978-0-89871-936-9},
  file = {/home/wouter/Zotero/storage/3TFWVIV8/Delfour, Zolésio - 2011 - Shapes and Geometries.pdf}
}

@article{desceliers2005,
  title = {Polynomial Chaos Representation of a Stochastic Preconditioner},
  author = {Desceliers, Christophe and Ghanem, Roger and Soize, Christian},
  year = {2005},
  month = oct,
  journal = {International Journal for Numerical Methods in Engineering},
  volume = {64},
  number = {5},
  pages = {618--634},
  issn = {0029-5981, 1097-0207},
  doi = {10.1002/nme.1382},
  urldate = {2025-03-28},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  langid = {english},
  file = {/home/wouter/Zotero/storage/CP8GY9PB/Desceliers et al. - 2005 - Polynomial chaos representation of a stochastic preconditioner.pdf}
}

@article{dettinger1981,
  title = {First Order Analysis of Uncertainty in Numerical Models of Groundwater Flow Part: 1. {{Mathematical}} Development},
  author = {Dettinger, Michael D. and Wilson, John L.},
  year = {1981},
  month = feb,
  journal = {Water Resources Research},
  volume = {17},
  number = {1},
  pages = {149--161},
  doi = {10.1029/WR017i001p00149},
  abstract = {In part 1 of this paper, first and second order analysis of uncertainty is applied to numerical models of groundwater flow. The models are cast in state-space form, with boundary conditions and inputs that are functionally dependent, but statistically independent, of time. Using a compact matrix calculus notation, first and second order Taylor series expansions of the model equations are derived and used to estimate the mean and variance-covariance properties of piezometric head predictions, given corresponding statistics for aquifer parameters: material properties, initial conditions, boundary conditions, and inputs. The mathematical results demonstrate that the prediction uncertainty is a function of the magnitude of the parameter uncertainty, and sensitivity of the predictions to the parameters. Furthermore, the first order estimate of the piezometric head is identical to the deterministic result. Part 2 of this paper, to be presented later, will illustrate these and other results through numerous applications of the methodology. Copyright 1981 by the American Geophysical Union.},
  file = {/home/wouter/Zotero/storage/HE7LXTFM/Dettinger, Wilson - 1981 - First order analysis of uncertainty in numerical models of groundwater flow part 1. Mathematical development.pdf}
}

@article{devore1998,
  title = {Nonlinear Approximation},
  author = {Devore, Ronald},
  year = {1998},
  month = jan,
  journal = {Acta Numerica},
  volume = {7},
  pages = {51--150},
  doi = {10.1017/S0962492900002816},
  abstract = {This is a survey of nonlinear approximation, especially that part of the subject which is important in numerical computation. Nonlinear approximation means that the approximants do not come from linear spaces but rather from nonlinear manifolds. The central question to be studied is what, if any, are the advantages of nonlinear approximation over the simpler, more established, linear methods. This question is answered by studying the rate of approximation which is the decrease in error versus the number of parameters in the approximant. The number of parameters usually correlates well with computational effort. It is shown that in many settings the rate of nonlinear approximation can be characterized by certain smoothness conditions which are significantly weaker than required in the linear theory. Emphasis in the survey will be placed on approximation by piecewise polynomials and wavelets as well as their numerical implementation. Results on highly nonlinear methods such as optimal basis selection and greedy algorithms (adaptive pursuit) are also given. Applications to image processing, statistical estimation, regularity for PDEs, and adaptive algorithms are discussed. {\copyright} 1998, Cambridge University Press. All rights reserved.},
  file = {/home/wouter/Zotero/storage/Y8JZM9JE/Devore - 1998 - Nonlinear approximation.pdf}
}

@article{dick2004,
  title = {Liberating the Weights},
  author = {Dick, Josef and Sloan, Ian H. and Wang, Xiaoqun and Wo{\'z}niakowski, Henryk},
  year = {2004},
  journal = {Journal of Complexity},
  volume = {20},
  number = {5},
  pages = {593--623},
  doi = {10.1016/j.jco.2003.06.002},
  abstract = {A partial answer to why quasi-Monte Carlo (QMC) algorithms work well for multivariate integration was given in Sloan and Wo{\'z}niakowski (J. Complexity 14 (1998) 1-33) by introducing weighted spaces. In these spaces the importance of successive coordinate directions is quantified by a sequence of weights. However, to be able to make use of weighted spaces for a particular application one has to make a choice of the weights. In this work, we take a more general view of the weights by allowing them to depend arbitrarily not only on the coordinates but also on the number of variables. Liberating the weights in this way allows us to give a recommendation for how to choose the weights in practice. This recommendation results from choosing the weights so as to minimize the error bound. We also consider how best to choose the underlying weighted Sobolev space within which to carry out the analysis. We revisit also lower bounds on the worst-case error, which change in many minor ways now, since the weights are allowed to depend on the number of variables, and we do not assume that the weights are uniformly bounded as has been assumed in previous papers. Necessary and sufficient conditions for QMC tractability and strong QMC tractability are obtained for the weighted Sobolev spaces with general weights. {\copyright} 2003 Published by Elsevier Inc.},
  file = {/home/wouter/Zotero/storage/UE6RUMH2/Dick et al. - 2004 - Liberating the weights.pdf}
}

@article{dick2013,
  title = {High-Dimensional Integration: {{The}} Quasi-{{Monte Carlo}} Way},
  author = {Dick, Josef and Kuo, Frances Y. and Sloan, Ian H.},
  year = {2013},
  journal = {Acta Numerica},
  volume = {22},
  number = {2013},
  pages = {133--288},
  doi = {10.1017/S0962492913000044},
  abstract = {This paper is a contemporary review of QMC ('quasi-Monte Carlo') methods, that is, equal-weight rules for the approximate evaluation of high-dimensional integrals over the unit cube [0,1] s , where s may be large, or even infinite. After a general introduction, the paper surveys recent developments in lattice methods, digital nets, and related themes. Among those recent developments are methods of construction of both lattices and digital nets, to yield QMC rules that have a prescribed rate of convergence for sufficiently smooth functions, and ideally also guaranteed slow growth (or no growth) of the worst-case error as s increases. A crucial role is played by parameters called 'weights', since a careful use of the weight parameters is needed to ensure that the worst-case errors in an appropriately weighted function space are bounded, or grow only slowly, as the dimension s increases. Important tools for the analysis are weighted function spaces, reproducing kernel Hilbert spaces, and discrepancy, all of which are discussed with an appropriate level of detail. {\copyright} Cambridge University Press, 2013.},
  file = {/home/wouter/Zotero/storage/68GLR7YU/Dick, Kuo, Sloan - 2013 - High-dimensional integration The quasi-Monte Carlo way.pdf}
}

@article{dick2014,
  title = {Higher Order {{QMC Petrov-Galerkin}} Discretization for Affine Parametric Operator Equations with Random Field Inputs},
  author = {Dick, Josef and Kuo, Frances Y. and Le Gia, Quoc T. and Nuyens, Dirk and Schwab, Christoph},
  year = {2014},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {52},
  number = {6},
  pages = {2676--2702},
  doi = {10.1137/130943984},
  abstract = {We construct quasi-Monte Carlo methods to approximate the expected values of linear functionals of Petrov-Galerkin discretizations of parametric operator equations which depend on a possibly infinite sequence of parameters. Such problems arise in the numerical solution of differential and integral equations with random field inputs. We analyze the regularity of the solutions with respect to the parameters in terms of the rate of decay of the fluctuations of the input field. If p {$\in$} (0, 1] denotes the "summability exponent" corresponding to the fluctuations in affine-parametric families of operators, then we prove that deterministic "interlaced polynomial lattice rules" of order {$\alpha$} = {$\lfloor$}-1/p{$\rfloor$} +1 in s dimensions with N points can be constructed using a fast component-by-component algorithm, in O({$\alpha$} s N log N + {$\alpha$}2 s2 N) operations, to achieve a convergence rate of O(N-/p), with the implied constant independent of s. This dimension-independent convergence rate is superior to the rate O(N-1/p+1/2) for 2/3 {$\leq$} p {$\leq$} 1, which was recently established for randomly shifted lattice rules under comparable assumptions. In our analysis we use a nonstandard Banach space setting and introduce "smoothness-driven product and order dependent" weights for which we develop a new fast component-by-component construction.},
  keywords = {Higher order digital nets,Infinite dimensional quadrature,Interlaced polynomial lattice rules,Parametric operator equations,Petrov-Galerkin discretization,Quasi-Monte Carlo methods},
  file = {/home/wouter/Zotero/storage/G5P5RYI6/Dick et al. - 2014 - Higher order QMC Petrov-Galerkin discretization for affine parametric operator equations with random field inputs.pdf}
}

@article{dick2016,
  title = {Higher Order Quasi--{{Monte Carlo}} Integration for Holomorphic, Parametric Operator Equations},
  author = {Dick, Josef and Le Gia, Quoc T. and Schwab, Christoph},
  year = {2016},
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  volume = {4},
  number = {1},
  pages = {48--79},
  publisher = {SIAM}
}

@misc{dimola2025,
  title = {Neural {{Preconditioning}} via {{Krylov Subspace Geometry}}},
  author = {Dimola, Nunzio and Coclite, Alessandro and Zunino, Paolo},
  year = {2025},
  month = jul,
  number = {arXiv:2507.15452},
  eprint = {2507.15452},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2507.15452},
  urldate = {2025-08-12},
  abstract = {We propose a geometry-aware strategy for training neural preconditioners tailored to parametrized linear systems arising from the discretization of mixed-dimensional partial differential equations (PDEs). These systems are typically ill-conditioned because of the presence of embedded lower-dimensional structures and are solved using Krylov subspace methods. Our approach yields an approximation of the inverse operator employing a learning algorithm consisting of a two-stage training framework: an initial static pre-training phase, based on residual minimization, followed by a dynamic fine-tuning phase that incorporates solver convergence dynamics into training via a novel loss functional. This dynamic loss is defined by the principal angles between the residuals and the Krylov subspaces. It is evaluated using a differentiable implementation of the Flexible GMRES algorithm, which enables backpropagation through both the Arnoldi process and Givens rotations. The resulting neural preconditioner is explicitly optimized to improve early-stage convergence and reduce iteration counts in a family of 3D-1D mixed-dimensional problems with geometric variability of the 1D domain. Numerical experiments show that our solver-aligned approach significantly improves convergence rate, robustness, and generalization.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis},
  file = {/home/wouter/Zotero/storage/DHJJHDHD/Dimola et al. - 2025 - Neural Preconditioning via Krylov Subspace Geometry.pdf;/home/wouter/Zotero/storage/4XU52XEB/2507.html}
}

@article{dolz2018,
  title = {A Fast Isogeometric {{BEM}} for the Three Dimensional {{Laplace-}} and {{Helmholtz}} Problems},
  author = {D{\"o}lz, J{\"u}rgen and Harbrecht, Helmut and Kurz, Stefan and Sch{\"o}ps, Sebastian and Wolf, Felix},
  year = {2018},
  month = mar,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {330},
  pages = {83--101},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.cma.2017.10.020},
  abstract = {We present an indirect higher order boundary element method utilising NURBS mappings for exact geometry representation and an interpolation-based fast multipole method for compression and reduction of computational complexity, to counteract the problems arising due to the dense matrices produced by boundary element methods. By solving Laplace and Helmholtz problems via a single layer approach we show, through a series of numerical examples suitable for easy comparison with other numerical schemes, that one can indeed achieve extremely high rates of convergence of the pointwise potential through the utilisation of higher order B-spline-based ansatz functions.},
  keywords = {B-splines,BEM,FMM,Helmholtz problem,IGA,Laplace problem},
  file = {/home/wouter/Zotero/storage/7QAM752U/Dölz et al. - 2018 - A fast isogeometric BEM for the three dimensional Laplace- and Helmholtz problems.pdf}
}

@article{dolz2022,
  title = {Isogeometric Multilevel Quadrature for Forward and Inverse Random Acoustic Scattering},
  author = {D{\"o}lz, J{\"u}rgen and Harbrecht, Helmut and {Jerez-Hanckes}, Carlos and Multerer, Michael},
  year = {2022},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {388},
  pages = {114242--114242},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.cma.2021.114242},
  abstract = {We study the numerical solution of forward and inverse time-harmonic acoustic scattering problems by randomly shaped obstacles in three-dimensional space using a fast isogeometric boundary element method. Within the isogeometric framework, realizations of the random scatterer can efficiently be computed by simply updating the NURBS mappings which represent the scatterer. This way, we end up with a random deformation field. In particular, we show that it suffices to know the deformation field's expectation and covariance at the scatterer's boundary to model the surface's Karhunen--Lo{\`e}ve expansion. Leveraging on the isogeometric framework, we employ multilevel quadrature methods to approximate quantities of interest such as the scattered wave's expectation and variance. By computing the wave's Cauchy data at an artificial, fixed interface enclosing the random obstacle, we can also directly infer quantities of interest in free space. Adopting the Bayesian paradigm, we finally compute the expected shape and variance of the scatterer from noisy measurements of the scattered wave at the artificial interface. Numerical results for the forward and inverse problems validate the proposed approach.},
  keywords = {Bayesian inversion,Boundary Integral Methods,Helmholtz scattering,Isogeometric Analysis,Multilevel quadrature,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/TIAFFZJQ/Dölz et al. - 2022 - Isogeometric multilevel quadrature for forward and inverse random acoustic scattering.pdf}
}

@article{dolz2023,
  title = {Parametric {{Shape Holomorphy}} of {{Boundary Integral Operators}} with {{Applications}}},
  author = {D{\"o}lz, J{\"u}rgen and Henr{\'i}quez, Fernando},
  year = {2023},
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {56},
  number = {5},
  pages = {6731--6767},
  doi = {10.1137/23M1576451}
}

@article{dolz2023a,
  title = {Solving Acoustic Scattering Problems by the Isogeometric Boundary Element Method},
  author = {D{\"o}lz, J{\"u}rgen and Harbrecht, Helmut and Multerer, Michael},
  year = {2023},
  journal = {arXiv preprint arXiv:2306.11324},
  eprint = {2306.11324},
  archiveprefix = {arXiv}
}

@article{dominguez2022,
  title = {Analysis and Application of an Overlapped {{FEM-BEM}} for Wave Propagation in Unbounded and Heterogeneous Media},
  author = {Dom{\'i}nguez, V. and Ganesh, M.},
  year = {2022},
  journal = {Applied Numerical Mathematics},
  volume = {171},
  pages = {76--105},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.apnum.2021.08.015},
  abstract = {An overlapped continuous model framework, for the Helmholtz wave propagation problem in unbounded regions comprising bounded heterogeneous media, was recently introduced and analyzed by the authors (2020) [10]. The continuous Helmholtz system incorporates a radiation condition (RC) and our equivalent hybrid framework facilitates application of widely used finite element methods (FEM) and boundary element methods (BEM), and the resulting discrete systems retain the RC exactly. The FEM and BEM discretizations, respectively, applied to the designed interior heterogeneous and exterior homogeneous media Helmholtz systems include the FEM and BEM solutions matching in artificial interface domains, and allow for computations of the exact ansatz based far-fields. In this article we present rigorous numerical analysis of a discrete two-dimensional FEM-BEM overlapped coupling implementation of the algorithm. We also demonstrate the efficiency of our discrete FEM-BEM framework and analysis using numerical experiments, including applications to non-convex heterogeneous multiple particle Janus configurations. Simulations of the far-field induced differential scattering cross sections (DSCS) of heterogeneous configurations and orientation-averaged (OA) counterparts are important for several applications, including inverse wave problems. Our robust FEM-BEM framework facilitates computations of such quantities of interest, without boundedness or homogeneity or shape restrictions on the wave propagation model.},
  keywords = {Finite element methods,Helmholtz,Heterogeneous,Integral equations,Janus configurations,Nystrom boundary element methods,Unbounded,Wave propagation},
  file = {/home/wouter/Zotero/storage/FVSUIMEJ/Domínguez, Ganesh - 2022 - Analysis and application of an overlapped FEM-BEM for wave propagation in unbounded and heterogeneous media.pdf}
}

@article{draganescu2008,
  title = {Optimal Order Multilevel Preconditioners for Regularized Ill-Posed Problems},
  author = {Dr{\u a}g{\u a}nescu, Andrei and Dupont, Todd F.},
  year = {2008},
  month = feb,
  journal = {Mathematics of Computation},
  volume = {77},
  number = {264},
  pages = {2001--2038},
  doi = {10.1090/S0025-5718-08-02100-5},
  file = {/home/wouter/Zotero/storage/VFDIEB5C/Drăgănescu, Dupont - 2008 - Optimal order multilevel preconditioners for regularized ill-posed problems.pdf}
}

@article{drezner2009,
  title = {On the Convergence of the Generalized {{Weiszfeld}} Algorithm},
  author = {Drezner, Zvi},
  year = {2009},
  month = mar,
  journal = {Annals of Operations Research},
  volume = {167},
  number = {1},
  pages = {327--336},
  issn = {0254-5330, 1572-9338},
  doi = {10.1007/s10479-008-0336-z},
  urldate = {2024-10-07},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/KP62W2ZN/Drezner - 2009 - On the convergence of the generalized Weiszfeld algorithm.pdf}
}

@article{drezner2016,
  title = {New Local Searches for Solving the Multi-Source {{Weber}} Problem},
  author = {Drezner, Zvi and Brimberg, Jack and Mladenovi{\'c}, Nenad and Salhi, Said},
  year = {2016},
  journal = {Annals of Operations Research},
  volume = {246},
  number = {1-2},
  pages = {181--203},
  doi = {10.1007/s10479-015-1797-5},
  abstract = {This paper presents three new heuristic approaches for the solution of the multi-source Weber problem in the plane: a constructive heuristic that finds a good starting solution, a decomposition approach which uses Delaunay triangulation, and a new efficient neighborhood structure based on the single facility limited distance median problem. A new heuristic incorporating all these approaches provided high quality solutions in reasonable computing time. We conclude that these heuristics successfully compete with the metaheuristic based methods found in the literature improving ten best known solutions. The ideas here may be extended to a variety of other continuous location as well as data mining problems.},
  keywords = {Constructive heuristic,Continuous p-median,Decomposition,Limited distance median,Locate-allocate,Weiszfeld algorithm},
  file = {/home/wouter/Zotero/storage/ZGTZWII8/Drezner et al. - 2016 - New local searches for solving the multi-source Weber problem.pdf}
}

@article{drezner2023,
  title = {A Trajectory Based Heuristic for the Planar P-Median Problem},
  author = {Drezner, Zvi and Brimberg, Jack and Sch{\"o}bel, Anita},
  year = {2023},
  journal = {Computers and Operations Research},
  volume = {158},
  number = {June},
  pages = {106296--106296},
  publisher = {Elsevier Ltd},
  doi = {10.1007/978-1-4419-7572-0},
  abstract = {This paper presents a novel approach for solving the planar p-median problem. A sub-class of the distributed p-median problem (Brimberg et al., 2021) is identified that allows a continuous trajectory of local optima to be constructed as a parameter {$\alpha$} decreases from 1 to 0. The trajectory converges to a local optimum of the planar p-median problem as {$\alpha$} approaches 0. Computational results are very encouraging. For larger instances tested, the proposed trajectory method finds better solutions in a small fraction of the time taken by a conventional multi-start local search. The methodology is readily extended to continuous p-median problems in higher dimensional spaces.},
  keywords = {Heuristics,Multiple facility location,p-median,Starting solutions},
  file = {/home/wouter/Zotero/storage/ZB2KCYC9/Drezner, Brimberg, Schöbel - 2023 - A trajectory based heuristic for the planar p-median problem.pdf}
}

@article{drezner2024,
  title = {Dispersed Starting Solutions in Facility Location: {{The}} Case of the Planar p-Median Problem},
  author = {Drezner, Zvi and Brimberg, Jack and Sch{\"o}bel, Anita},
  year = {2024},
  journal = {Computers and Operations Research},
  volume = {169},
  number = {December 2023},
  pages = {106726--106726},
  publisher = {Elsevier Ltd},
  doi = {10.1016/j.cor.2024.106726},
  abstract = {There are many planar multiple facilities location problems for which the optimal locations tend to be spread out. The most popular of these is the planar p-median problem. With this in mind, we propose several procedures to generate sparse configurations as starting solutions. The proposed procedures are easy to implement, and can be used as modules combined in different sequences within heuristics such as a recent trajectory-based procedure that we tested in this paper. The procedures are tested experimentally on a set of 24 large problem instances with up to 10,000 demand points and 100 facilities. We are able to demonstrate that the sparse starting solutions generated by the new procedures lead to significant improvements of final p-median solutions.},
  keywords = {Heuristics,Multiple facility location,p-median,Starting solutions},
  file = {/home/wouter/Zotero/storage/6GI23HLL/Drezner, Brimberg, Schöbel - 2024 - Dispersed starting solutions in facility location The case of the planar p-median problem.pdf}
}

@book{driscoll,
  title = {Schwarz -- {{Christoffel Mapping}}},
  author = {Driscoll, Tobin A and Trefethen, Lloyd N},
  isbn = {0-521-80726-3},
  file = {/home/wouter/Zotero/storage/L6SWCSLG/Driscoll, Trefethen - Unknown - Schwarz – Christoffel Mapping.pdf}
}

@article{dubrule1983,
  title = {Cross Validation of Kriging in a Unique Neighborhood},
  author = {Dubrule, Olivier},
  year = {1983},
  month = dec,
  journal = {Journal of the International Association for Mathematical Geology},
  volume = {15},
  number = {6},
  pages = {687--699},
  issn = {0020-5958, 1573-8868},
  doi = {10.1007/BF01033232},
  urldate = {2025-01-16},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/CY9PS5Y3/Dubrule - 1983 - Cross validation of kriging in a unique neighborhood.pdf}
}

@article{duda2016,
  title = {Finite Element Method Formulation in Polar Coordinates for Transient Heat Conduction Problems},
  author = {Duda, Piotr},
  year = {2016},
  journal = {Journal of Thermal Science},
  volume = {25},
  number = {2},
  pages = {188--194},
  doi = {10.1007/s11630-016-0850-2},
  abstract = {The aim of this paper is the formulation of the finite element method in polar coordinates to solve transient heat conduction problems. It is hard to find in the literature a formulation of the finite element method (FEM) in polar or cylindrical coordinates for the solution of heat transfer problems. This document shows how to apply the most often used boundary conditions. The global equation system is solved by the Crank-Nicolson method. The proposed algorithm is verified in three numerical tests. In the first example, the obtained transient temperature distribution is compared with the temperature obtained from the presented analytical solution. In the second numerical example, the variable boundary condition is assumed. In the last numerical example the component with the shape different than cylindrical is used. All examples show that the introduction of the polar coordinate system gives better results than in the Cartesian coordinate system. The finite element method formulation in polar coordinates is valuable since it provides a higher accuracy of the calculations without compacting the mesh in cylindrical or similar to tubular components. The proposed method can be applied for circular elements such as boiler drums, outlet headers, flux tubes. This algorithm can be useful during the solution of inverse problems, which do not allow for high density grid. This method can calculate the temperature distribution in the bodies of different properties in the circumferential and the radial direction. The presented algorithm can be developed for other coordinate systems. The examples demonstrate a good accuracy and stability of the proposed method.},
  keywords = {FEM,numerical methods,polar coordinate system,power boilers,transient heat conduction},
  file = {/home/wouter/Zotero/storage/FGSZ5ULK/Duda - 2016 - Finite element method formulation in polar coordinates for transient heat conduction problems.pdf}
}

@book{dung2022,
  title = {Analyticity and Sparsity in Uncertainty Quantification for {{PDEs}} with {{Gaussian}} Random Field Inputs},
  author = {D{\~u}ng, Dinh and Nguyen, Van Kien and Schwab, Christoph and Zech, Jakob},
  year = {2022},
  publisher = {Springer Cham},
  abstract = {We establish sparsity and summability results for coefficient sequences of Wiener-Hermite polynomial chaos expansions of countably-parametric solutions of linear elliptic and parabolic divergence-form partial differential equations with Gaussian random field inputs. The novel proof technique developed here is based on analytic continuation of parametric solutions into the complex domain. It differs from previous works that used bootstrap arguments and induction on the differentiation order of solution derivatives with respect to the parameters. The present holomorphy-based argument allows a unified, ``differentiation-free'' proof of sparsity (expressed in terms of \${\textbackslash}ell{\textasciicircum}p\$-summability or weighted \${\textbackslash}ell{\textasciicircum}2\$-summability) of sequences of Wiener-Hermite coefficients in polynomial chaos expansions in various scales of function spaces. The analysis also implies corresponding analyticity and sparsity results for posterior densities in Bayesian inverse problems subject to Gaussian priors on uncertain inputs from function spaces. Our results furthermore yield dimension-independent convergence rates of various {\textbackslash}emph\{constructive\} high-dimensional deterministic numerical approximation schemes such as single-level and multi-level versions of Hermite-Smolyak anisotropic sparse-grid interpolation and quadrature in both forward and inverse computational uncertainty quantification.},
  isbn = {978-3-031-38383-0},
  file = {/home/wouter/Zotero/storage/M72Q6TCA/Dũng et al. - 2022 - Analyticity and sparsity in uncertainty quantification for PDEs with Gaussian random field inputs.pdf}
}

@inproceedings{duvenaud2011,
  title = {Additive {{Gaussian Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Duvenaud, David and Nickisch, Hannes and Rasmussen, Carl E.},
  year = {2011},
  volume = {24},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-01-09},
  abstract = {We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efficient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/MIJBGI9R/Duvenaud et al. - 2011 - Additive Gaussian Processes.pdf;/home/wouter/Zotero/storage/VQBCVA2X/1112.html}
}

@phdthesis{duvenaud2014,
  title = {Automatic Model Construction with {{Gaussian}} Processes},
  author = {Duvenaud, David},
  year = {2014},
  month = nov,
  doi = {10.17863/CAM.14087},
  urldate = {2024-10-29},
  abstract = {This thesis develops a method for automatically constructing, visualizing and describing a large class of models, useful for forecasting and finding structure in domains such as time series, geological formations, and physical dynamics. These models, based on Gaussian processes, can capture many types of statistical structure, such as periodicity, changepoints, additivity, and symmetries. Such structure can be encoded through kernels, which have historically been hand-chosen by experts. We show how to automate this task, creating a system that explores an open-ended space of models and reports the structures discovered. To automatically construct Gaussian process models, we search over sums and products of kernels, maximizing the approximate marginal likelihood. We show how any model in this class can be automatically decomposed into qualitatively different parts, and how each component can be visualized and described through text. We combine these results into a procedure that, given a dataset, automatically constructs a model along with a detailed report containing plots and generated text that illustrate the structure discovered in the data. The introductory chapters contain a tutorial showing how to express many types of structure through kernels, and how adding and multiplying different kernels combines their properties. Examples also show how symmetric kernels can produce priors over topological manifolds such as cylinders, toruses, and M{\"o}bius strips, as well as their higher-dimensional generalizations. This thesis also explores several extensions to Gaussian process models. First, building on existing work that relates Gaussian processes and neural nets, we analyze natural extensions of these models to deep kernels and deep Gaussian processes. Second, we examine additive Gaussian processes, showing their relation to the regularization method of dropout. Third, we combine Gaussian processes with the Dirichlet process to produce the warped mixture model: a Bayesian clustering model having nonparametric cluster shapes, and a corresponding latent space in which each cluster has an interpretable parametric form.},
  collaborator = {{Apollo-University Of Cambridge Repository} and {University Of Cambridge} and Rasmussen, Carl},
  copyright = {Attribution-ShareAlike 2.0 UK: England \& Wales, open.access},
  langid = {english},
  school = {Apollo - University of Cambridge Repository},
  keywords = {Forecasting,FOS: Mathematics,Gaussian processes,Machine learning,Model building,Statistics,Time series},
  file = {/home/wouter/Zotero/storage/22AQNZXJ/Duvenaud - 2014 - Automatic model construction with Gaussian processes.pdf}
}

@article{dvinsky1991,
  title = {Adaptive Grid Generation from Harmonic Maps on {{Riemannian}} Manifolds},
  author = {Dvinsky, Arkady S},
  year = {1991},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {95},
  number = {2},
  pages = {450--476},
  issn = {00219991},
  doi = {10.1016/0021-9991(91)90285-S},
  urldate = {2025-06-16},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/G4EICBJV/Dvinsky - 1991 - Adaptive grid generation from harmonic maps on Riemannian manifolds.pdf}
}

@article{dwight2009,
  title = {Robust Mesh Deformation Using the Linear Elasticity Equations},
  author = {Dwight, Richard P.},
  year = {2009},
  journal = {Computational Fluid Dynamics 2006 - Proceedings of the Fourth International Conference on Computational Fluid Dynamics, ICCFD 2006},
  pages = {401--406},
  issn = {9783540927785},
  doi = {10.1007/978-3-540-92779-2_62},
  abstract = {A modification is proposed to the equations of linear elasticity as used to deform Euler and Navier-Stokes meshes. In particular it is seen that the equations do not admit rigid body rotations as solutions, and it is shown how these solutions may be recovered by modifying the constitutive law. The result is significantly more robust to general deformations, and combined with incremental application generates valid meshes well beyond the point at which remeshing is required. {\copyright} Springer-Verlag Berlin Heidelberg 2009.},
  file = {/home/wouter/Zotero/storage/NBQUPVQS/Dwight - 2009 - Robust mesh deformation using the linear elasticity equations.pdf}
}

@incollection{eckhardt1975,
  title = {On an Optimization Problem Related to Minimal Surfaces with Obstacles},
  booktitle = {Optimization and {{Optimal Control}}},
  author = {Eckhardt, Ulrich},
  editor = {Dold, A. and Eckmann, B. and Bulirsch, Roland and Oettli, Werner and Stoer, Josef},
  year = {1975},
  volume = {477},
  pages = {95--101},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/BFb0079169},
  urldate = {2024-10-07},
  isbn = {978-3-540-07393-2 978-3-540-37591-3},
  file = {/home/wouter/Zotero/storage/2FWPT22U/Eckhardt - 1975 - On an optimization problem related to minimal surfaces with obstacles.pdf}
}

@article{eckhardt1980,
  title = {Weber's Problem and Weiszfeld's Algorithm in General Spaces},
  author = {Eckhardt, Ulrich},
  year = {1980},
  journal = {Mathematical Programming},
  volume = {18},
  number = {1},
  pages = {186--196},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/BF01588313},
  urldate = {2024-10-02},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/3YLC4EQS/Eckhardt - 1980 - Weber's problem and weiszfeld's algorithm in general spaces.pdf}
}

@article{efendiev2006,
  title = {Preconditioning {{Markov Chain Monte Carlo Simulations Using Coarse-Scale Models}}},
  author = {Efendiev, Y. and Hou, T. and Luo, W.},
  year = {2006},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {28},
  number = {2},
  pages = {776--803},
  doi = {10.1137/050628568},
  abstract = {We study the preconditioning of Markov chain Monte Carlo (MCMC) methods using coarse-scale models with applications to subsurface characterization. The purpose of preconditioning is to reduce the fine-scale computational cost and increase the acceptance rate in the MCMC sampling. This goal is achieved by generating Markov chains based on two-stage computations. In the first stage, a new proposal is first tested by the coarse-scale model based on multiscale finite volume methods. The full fine-scale computation will be conducted only if the proposal passes the coarse-scale screening. For more efficient simulations, an approximation of the full fine-scale computation using precomputed multiscale basis functions can also be used. Comparing with the regular MCMC method, the preconditioned MCMC method generates a modified Markov chain by incorporating the coarse-scale information of the problem. The conditions under which the modified Markov chain will converge to the correct posterior distribution are stated in the paper. The validity of these assumptions for our application and the conditions which would guarantee a high acceptance rate are also discussed. We would like to note that coarse-scale models used in the simulations need to be inexpensive but not necessarily very accurate, as our analysis and numerical simulations demonstrate. We present numerical examples for sampling permeability fields using two-point geostatistics. The Karhurien-Lo{\`e}ve expansion is used to represent the realizations of the permeability field conditioned to the dynamic data, such as production data, as well as some static data. Our numerical examples show that the acceptance rate can be increased by more than 10 times if MCMC simulations are preconditioned using coarse-scale models. {\copyright} 2006 Society for Industrial and Applied Mathematics.},
  keywords = {Markov chain Monte Carlo,Multiscale,Porous media,Preconditioning},
  file = {/home/wouter/Zotero/storage/GM8HZDUJ/Efendiev, Hou, Luo - 2006 - Preconditioning Markov Chain Monte Carlo Simulations Using Coarse-Scale Models.pdf}
}

@article{eiermann2007,
  title = {Computational Aspects of the Stochastic Finite Element Method},
  author = {Eiermann, Michael and Ernst, Oliver G. and Ullmann, Elisabeth},
  year = {2007},
  month = feb,
  journal = {Computing and Visualization in Science},
  volume = {10},
  number = {1},
  pages = {3--15},
  issn = {1432-9360, 1433-0369},
  doi = {10.1007/s00791-006-0047-4},
  urldate = {2025-02-24},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/YIQGCY6W/Eiermann et al. - 2007 - Computational aspects of the stochastic finite element method.pdf}
}

@article{eigel2020,
  title = {An {{Adaptive Stochastic Galerkin Tensor Train Discretization}} for {{Randomly Perturbed Domains}}},
  author = {Eigel, Martin and Marschall, Manuel and Multerer, Michael},
  year = {2020},
  month = jan,
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  volume = {8},
  number = {3},
  pages = {1189--1214},
  doi = {10.1137/19M1246080},
  abstract = {A linear PDE problem for randomly perturbed domains is considered in an adaptive Galerkin framework. The perturbation of the domain's boundary is described by a vector valued random field depending on a countable number of random variables in an affine way. The corresponding Karhunen-Lo{\textbackslash}`eve expansion is approximated by the pivoted Cholesky decomposition based on a prescribed covariance function. The examined high dimensional Galerkin system follows from the domain mapping approach, transferring the randomness from the domain to the diffusion coefficient and the forcing. In order to make this computationally feasible, the representation makes use of the modern tensor train format for the implicit compression of the problem. Moreover, an a posteriori error estimator is presented, which allows for the problem-dependent iterative refinement of all discretization parameters and the assessment of the achieved error reduction. The proposed approach is demonstrated in numerical benchmark problems.},
  keywords = {Adaptive methods,Low-rank,Partial differential equations with random coeffic,Random domain,Tensor train,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/2C5XCNXL/Eigel, Marschall, Multerer - 2020 - An Adaptive Stochastic Galerkin Tensor Train Discretization for Randomly Perturbed Domains.pdf}
}

@phdthesis{elman1982,
  title = {Iterative  {{Methods}} for {{Large}}, {{Sparse}}, {{Nonsymmetric Systems}} of {{Linear Equations}}},
  author = {Elman, Howard C.},
  year = {1982},
  month = apr,
  school = {Yale University},
  file = {/home/wouter/Zotero/storage/BWEH9LXD/_.pdf}
}

@article{elman2015,
  title = {Preconditioning {{Techniques}} for {{Reduced Basis Methods}} for {{Parameterized Elliptic Partial Differential Equations}}},
  author = {Elman, Howard C. and Forstall, Virginia},
  year = {2015},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {37},
  number = {5},
  pages = {S177-S194},
  doi = {10.1137/140970859},
  keywords = {1,10,1137,140997907,65f08,65f10,65n55,65y05,ams subject classifications,doi,domain decomposition,feti-dp,introduction,nonlinear,parallel computing,partial differential equations leads,the discretization of elliptic},
  file = {/home/wouter/Zotero/storage/CYR36946/Elman, Forstall - 2015 - Preconditioning Techniques for Reduced Basis Methods for Parameterized Elliptic Partial Differential Equations.pdf}
}

@article{embree1999,
  title = {How Descriptive Are {{GMRES}} Convergence Bounds?},
  author = {Embree, Mark},
  year = {1999},
  journal = {NA Report 99},
  volume = {8},
  number = {June},
  abstract = {Eigenvalues with the eigenvector condition number, the eld of values, and pseu-dospectra have all been suggested as the basis for convergence bounds for minimum residual Krylov subspace methods applied to non-normal coeecient matrices. This paper analyzes and compares these bounds, illustrating with six examples the success and failure of each one. Reened bounds based on eigenvalues and the eld of values are suggested to handle low-dimensional non-normality. It is observed that pseudospectral bounds can capture multiple convergence stages. Unfortunately, computation of pseudospectra can be rather expensive. This motivates an adaptive technique for estimating GMRES convergence based on approximate pseudospectra taken from the Arnoldi process that is the basis for GMRES.},
  keywords = {()},
  file = {/home/wouter/Zotero/storage/8LZGIBXV/Embree - 1999 - How descriptive are GMRES convergence bounds.pdf}
}

@article{engquist2011,
  title = {Sweeping Preconditioner for the {{Helmholtz}} Equation: {{Hierarchical}} Matrix Representation},
  author = {Engquist, Bj{\"o}rn and Ying, Lexing},
  year = {2011},
  month = may,
  journal = {Communications on Pure and Applied Mathematics},
  volume = {64},
  number = {5},
  pages = {697--735},
  doi = {10.1002/cpa.20358},
  abstract = {The paper introduces the sweeping preconditioner, which is highly efficient for iterative solutions of the variable-coefficient Helmholtz equation including very-high-frequency problems. The first central idea of this novel approach is to construct an approximate factorization of the discretized Helmholtz equation by sweeping the domain layer by layer, starting from an absorbing layer or boundary condition. Given this specific order of factorization, the second central idea is to represent the intermediate matrices in the hierarchical matrix framework. In two dimensions, both the construction and the application of the preconditioners are of linear complexity. The generalized minimal residual method (GMRES) solver with the resulting preconditioner converges in an amazingly small number of iterations, which is essentially independent of the number of unknowns. This approach is also extended to the three-dimensional case with some success. Numerical results are provided in both two and three dimensions to demonstrate the efficiency of this new approach. {\copyright} 2011 Wiley Periodicals, Inc.},
  file = {/home/wouter/Zotero/storage/CNC4CCCU/Engquist, Ying - 2011 - Sweeping preconditioner for the Helmholtz equation Hierarchical matrix representation.pdf}
}

@article{engquist2011a,
  title = {Sweeping {{Preconditioner}} for the {{Helmholtz Equation}}: {{Moving Perfectly Matched Layers}}},
  author = {Engquist, Bj{\"o}rn and Ying, Lexing},
  year = {2011},
  month = apr,
  journal = {Multiscale Modeling \& Simulation},
  volume = {9},
  number = {2},
  pages = {686--710},
  doi = {10.1137/100804644},
  keywords = {10,100804644,1137,65f08,65n22,65n80,ams subject classifications,doi,factorization,green,helmholtz equation,high frequency waves,ldl t,multifrontal methods,optimal ordering,perfectly matched layers,preconditioners,s function},
  file = {/home/wouter/Zotero/storage/9327JG6D/Engquist, Ying - 2011 - Sweeping Preconditioner for the Helmholtz Equation Moving Perfectly Matched Layers.pdf}
}

@article{erlangga2004,
  title = {On a Class of Preconditioners for Solving the {{Helmholtz}} Equation},
  author = {Erlangga, Yogi A. and Vuik, Kees and Oosterlee, Kees},
  year = {2004},
  journal = {Applied Numerical Mathematics},
  volume = {50},
  number = {3-4},
  pages = {409--425},
  doi = {10.1016/j.apnum.2004.01.009},
  abstract = {In 1983, a preconditioner was proposed [J. Comput. Phys. 49 (1983) 443] based on the Laplace operator for solving the discrete Helmholtz equation efficiently with CGNR. The preconditioner is especially effective for low wavenumber cases where the linear system is slightly indefinite. Laird [Preconditioned iterative solution of the 2D Helmholtz equation, First Year's Report, St. Hugh's College, Oxford, 2001] proposed a preconditioner where an extra term is added to the Laplace operator. This term is similar to the zeroth order term in the Helmholtz equation but with reversed sign. In this paper, both approaches are further generalized to a new class of preconditioners, the so-called "shifted Laplace" preconditioners of the form {$\Delta\varphi$}-{$\alpha$}k2{$\varphi$} with {$\alpha\in\mathbb{C}$}. Numerical experiments for various wavenumbers indicate the effectiveness of the preconditioner. The preconditioner is evaluated in combination with GMRES, Bi-CGSTAB, and CGNR. {\copyright} 2004 IMACS. Published by Elsevier B.V. All rights reserved.},
  keywords = {Helmholtz equation,Krylov subspace,Preconditioner},
  file = {/home/wouter/Zotero/storage/7AMTUDLK/Erlangga, Vuik, Oosterlee - 2004 - On a class of preconditioners for solving the Helmholtz equation.pdf}
}

@article{erlangga2006,
  title = {A {{Novel Multigrid Based Preconditioner For Heterogeneous Helmholtz Problems}}},
  author = {Erlangga, Y. A. and Oosterlee, C. W. and Vuik, C.},
  year = {2006},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {27},
  number = {4},
  pages = {1471--1492},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/040615195},
  urldate = {2025-07-02},
  langid = {english},
  file = {/home/wouter/Zotero/storage/75UL2IX8/Erlangga et al. - 2006 - A Novel Multigrid Based Preconditioner For Heterogeneous Helmholtz Problems.pdf;/home/wouter/Zotero/storage/C2X3A6IA/Erl06OV.pdf}
}

@book{ern2004,
  title = {Theory and {{Practice}} of {{Finite Elements}}},
  author = {Ern, Alexandre and Guermond, Jean-Luc},
  year = {2004},
  journal = {Suparyanto dan Rosad (2015},
  series = {Applied {{Mathematical Sciences}}},
  volume = {159},
  pages = {253},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4757-4355-5},
  abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein-protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-{$\alpha$}-helical peptides and systematically improve pose prediction accuracy bynhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD {$\leq$} 2.0 {\AA} for the interface backbone atoms) increased from 21\% with default Glide SP settings to 58\% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63\% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40\% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
  isbn = {978-1-4419-1918-2},
  keywords = {brand image,consumer decision to buy,corporate social responsibility,price},
  file = {/home/wouter/Zotero/storage/WCWJ9GTK/Ern, Guermond - 2004 - Theory and Practice of Finite Elements.pdf}
}

@article{ernst2009,
  title = {Efficient {{Solvers}} for a {{Linear Stochastic Galerkin Mixed Formulation}} of {{Diffusion Problems}} with {{Random Data}}},
  author = {Ernst, Oliver G. and Powell, Catherine E. and Silvester, David J. and Ullmann, Elisabeth},
  year = {2009},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {31},
  number = {2},
  pages = {1424--1447},
  doi = {10.1137/070705817},
  keywords = {finite elements,mixed approximation,preconditioning,stochastic galerkin method},
  file = {/home/wouter/Zotero/storage/XYDY5X5W/Ernst et al. - 2009 - Efficient Solvers for a Linear Stochastic Galerkin Mixed Formulation of Diffusion Problems with Random Data.pdf}
}

@article{ernst2015,
  title = {Analysis of the Ensemble and Polynomial Chaos Kalman Filters in {{Bayesian}} Inverse Problems},
  author = {Ernst, Oliver G. and Sprungk, Bj{\"o}rn and Starkloff, Hans J{\"o}rg},
  year = {2015},
  journal = {SIAM-ASA Journal on Uncertainty Quantification},
  volume = {3},
  number = {1},
  pages = {823--851},
  doi = {10.1137/140981319},
  abstract = {We analyze the ensemble and polynomial chaos Kalman filters applied to nonlinear stationary Bayesian inverse problems. In a sequential data assimilation setting, such stationary problems arise in each step of either filter. We give a new interpretation of the approximations produced by these two popular filters in the Bayesian context and prove that, in the limit of large ensemble or high polynomial degree, both methods yield approximations which converge to a well-defined random variable termed the analysis random variable. We then show that this analysis variable is more closely related to a specific linear Bayes estimator than to the solution of the associated Bayesian inverse problem given by the posterior measure. This suggests limited or at least guarded use of these generalized Kalman filter methods for the purpose of uncertainty quantification.},
  keywords = {Bayes estimator,Bayesian inverse problem,Conditional distribution,Ensemble Kalman filter,Inverse problems,Kalman filter,Polynomial chaos},
  file = {/home/wouter/Zotero/storage/FHRWUBYE/Ernst, Sprungk, Starkloff - 2015 - Analysis of the ensemble and polynomial chaos kalman filters in Bayesian inverse problems.pdf}
}

@article{ernst2018,
  title = {Convergence of Sparse Collocation for Functions of Countably Many {{Gaussian}} Random Variables (with Application to Elliptic {{PDEs}})},
  author = {Ernst, Oliver G. and Sprungk, Bj{\"o}rn and Tamellini, Lorenzo},
  year = {2018},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {56},
  number = {2},
  pages = {877--905},
  publisher = {SIAM},
  file = {/home/wouter/Zotero/storage/MMKIZ3MY/Ernst, Sprungk, Tamellini - 2018 - Convergence of sparse collocation for functions of countably many Gaussian random variables (with app.pdf}
}

@incollection{ernst2021,
  title = {On {{Expansions}} and {{Nodes}} for {{Sparse Grid Collocation}} of {{Lognormal Elliptic PDEs}}},
  booktitle = {Lecture {{Notes}} in {{Computational Science}} and {{Engineering}}},
  author = {Ernst, Oliver G. and Sprungk, Bj{\"o}rn and Tamellini, Lorenzo},
  year = {2021},
  volume = {144},
  pages = {1--31},
  publisher = {Springer},
  doi = {10.1007/978-3-030-81362-8_1},
  abstract = {This work is a follow-up to our previous contribution (``Convergence of sparse collocation for functions of countably many Gaussian random variables (with application to elliptic PDEs)'', SIAM J. Numer. Anal., 2018), and contains further insights on some aspects of the solution of elliptic PDEs with lognormal diffusion coefficients using sparse grids. Specifically, we first focus on the choice of univariate interpolation rules, advocating the use of Gaussian Leja points as introduced by Narayan and Jakeman (``Adaptive Leja sparse grid constructions for stochastic collocation and high-dimensional approximation'', SIAM J. Sci. Comput., 2014) and then discuss the possible computational advantages of replacing the standard Karhunen-Lo{\`e}ve expansion of the diffusion coefficient with the L{\'e}vy-Ciesielski expansion, motivated by theoretical work of Bachmayr, Cohen, DeVore, and Migliorati (``Sparse polynomial approximation of parametric elliptic PDEs. part II: lognormal coefficients'', ESAIM: M2AN, 2016). Our numerical results indicate that, for the problem under consideration, Gaussian Leja collocation points outperform Gauss--Hermite and Genz--Keister nodes for the sparse grid approximation and that the Karhunen--Lo{\`e}ve expansion of the log diffusion coefficient is more appropriate than its L{\'e}vy--Ciesielski expansion for purpose of sparse grid collocation.},
  isbn = {978-3-030-81361-1},
  file = {/home/wouter/Zotero/storage/FBGD3WL8/Ernst, Sprungk, Tamellini - 2021 - On Expansions and Nodes for Sparse Grid Collocation of Lognormal Elliptic PDEs.pdf}
}

@misc{ernst2025,
  title = {Learning to {{Integrate}}},
  author = {Ernst, Oliver G. and Gottschalk, Hanno and Kowalewitz, Toni and Kr{\"u}ger, Patrick},
  year = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2506.11801},
  urldate = {2025-06-19},
  abstract = {This work deals with uncertainty quantification for a generic input distribution to some resource-intensive simulation, e.g., requiring the solution of a partial differential equation. While efficient numerical methods exist to compute integrals for high-dimensional Gaussian and other separable distributions based on sparse grids (SG), input data arising in practice often does not fall into this class. We therefore employ transport maps to transform complex distributions to multivatiate standard normals. In generative learning, a number of neural network architectures have been introduced that accomplish this task approximately. Examples are affine coupling flows (ACF) and ordinary differential equation-based networks such as conditional flow matching (CFM). To compute the expectation of a quantity of interest, we numerically integrate the composition of the inverse of the learned transport map with the simulation code output. As this map is integrated over a multivariate Gaussian distribution, SG techniques can be applied. Viewing the images of the SG quadrature nodes as learned quadrature nodes for a given complex distribution motivates our title. We demonstrate our method for monomials of total degrees for which the unmapped SG rules are exact. We also apply our approach to the stationary diffusion equation with coefficients modeled by exponentiated L{\'e}vy random fields, using a Karhunen-Lo{\`e}ve-like modal expansions with 9 and 25 modes. In a series of numerical experiments, we investigate errors due to learning accuracy, quadrature, statistical estimation, truncation of the modal series of the input random field, and training data size for three normalizing flows (ACF, conditional Flow Matching and Optimal transport Flow Matching) We discuss the mathematical assumptions on which our approach is based and demonstrate its shortcomings when these are violated.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {65C30 (Primary) 65D40 68T07 (Secondary),FOS: Mathematics,Numerical Analysis (math.NA),Probability (math.PR)},
  file = {/home/wouter/Zotero/storage/KZ2DBKLH/Ernst et al. - 2025 - Learning to Integrate.pdf}
}

@article{euler1766,
  title = {Suppl{\'e}ment Aux Recherches Sur La Propagation Du Son},
  author = {Euler, Leonhard},
  year = {1766},
  journal = {M{\'e}moires de l'acad{\'e}mie des sciences de Berlin},
  volume = {15},
  pages = {452--483}
}

@article{evans1929,
  title = {Discontinuous {{Boundary Value Problems}} of the {{First Kind}} for {{Poisson}} ' s {{Equation}}},
  author = {Evans, {\relax Griffith}. C.},
  year = {1929},
  journal = {American Journal of Mathematics},
  volume = {51},
  number = {1},
  pages = {1--18},
  file = {/home/wouter/Zotero/storage/6S45ZFFY/Evans - 1929 - Discontinuous Boundary Value Problems of the First Kind for Poisson ' s Equation.pdf}
}

@article{evans1932,
  title = {{{NOTE ON THE GRADIENT OF THE GREEN}}'{{S FUNCTION}}},
  author = {Evans, {\relax Griffith}. C.},
  year = {1932},
  volume = {51},
  number = {M},
  file = {/home/wouter/Zotero/storage/WFXXYVBR/Evans - 1932 - NOTE ON THE GRADIENT OF THE GREEN'S FUNCTION.pdf}
}

@book{evans2010,
  title = {Partial {{Differential Equations}}},
  author = {Evans, Lawrence C.},
  year = {2010},
  edition = {2nd},
  publisher = {American Mathematical Society},
  abstract = {Many of the partial differential equations that describe physical systems involve derivatives with respect to space variables (x,y,z) or with respect to space and time variables (x,y,z,t).},
  isbn = {978-082184974},
  file = {/home/wouter/Zotero/storage/RACF2KSV/Lawrence - 2010 - Partial Differential Equations Second Edition.pdf}
}

@article{evensen2003,
  title = {The {{Ensemble Kalman Filter}}: {{Theoretical}} Formulation and Practical Implementation},
  author = {Evensen, Geir},
  year = {2003},
  journal = {Ocean Dynamics},
  volume = {53},
  number = {4},
  pages = {343--367},
  doi = {10.1007/s10236-003-0036-9},
  abstract = {The purpose of this paper is to provide a comprehensive presentation and interpretation of the Ensemble Kalman Filter (EnKF) and its numerical implementation. The EnKF has a large user group, and numerous publications have discussed applications and theoretical aspects of it. This paper reviews the important results from these studies and also presents new ideas and alternative interpretations which further explain the success of the EnKF. In addition to providing the theoretical framework needed for using the EnKF, there is also a focus on the algorithmic formulation and optimal numerical implementation. A program listing is given for some of the key subroutines. The paper also touches upon specific issues such as the use of nonlinear measurements, in situ profiles of temperature and salinity, and data which are available with high frequency in time. An ensemble based optimal interpolation (EnOI) scheme is presented as a cost-effective approach which may serve as an alternative to the EnKF in some applications. A fairly extensive discussion is devoted to the use of time correlated model errors and the estimation of model bias. {\copyright} Springer-Verlag 2003.},
  keywords = {Data assimilation,Ensemble Kalman Filter},
  file = {/home/wouter/Zotero/storage/JJVDLXPS/Evensen - 2003 - The Ensemble Kalman Filter Theoretical formulation and practical implementation.pdf}
}

@article{fang2018,
  title = {A Hybrid Approach to Solve the High-Frequency {{Helmholtz}} Equation with Source Singularity in Smooth Heterogeneous Media},
  author = {Fang, Jun and Qian, Jianliang and {Zepeda-N{\'u}{\~n}ez}, Leonardo and Zhao, Hongkai},
  year = {2018},
  journal = {Journal of Computational Physics},
  volume = {371},
  pages = {261--279},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jcp.2018.03.011},
  abstract = {We propose a hybrid approach to solve the high-frequency Helmholtz equation with point source terms in smooth heterogeneous media. The method is based on the ray-based finite element method (ray-FEM) [29], whose original version can not handle the singularity close to point sources accurately. This pitfall is addressed by combining the ray-FEM, which is used to compute the smooth far-field of the solution accurately, with a high-order asymptotic expansion close to the point source, which is used to properly capture the singularity of the solution in the near-field. The method requires a fixed number of grid points per wavelength to accurately represent the wave field with an asymptotic convergence rate of O({$\omega-$}1/2), where {$\omega$} is the frequency parameter in the Helmholtz equation. In addition, a fast sweeping-type preconditioner is used to solve the resulting linear system. We present numerical examples in 2D to show both accuracy and efficiency of our method as the frequency increases. In particular, we provide numerical evidence of the convergence rate, and we show empirically that the overall complexity is O({$\omega$}2) up to a poly-logarithmic factor.},
  keywords = {Babich's expansion,Helmholtz equation,NMLA,Ray-FEM},
  file = {/home/wouter/Zotero/storage/PB9HJTNZ/Fang et al. - 2018 - A hybrid approach to solve the high-frequency Helmholtz equation with source singularity in smooth heterogeneous me.pdf}
}

@article{fel2021,
  title = {Preconditioning of {{Domain Decomposition Methods}} for {{Joao Fel{\'i}cio Dos Reis To}} Cite This Version : {{HAL Id}} : Tel-03498777 {{Preconditioning}} of {{Domain Decomposition Methods}} for {{Stochastic Elliptic Equations}}},
  author = {Fel, Joao and Reis, Dos},
  year = {2021},
  file = {/home/wouter/Zotero/storage/42LTYJ43/Fel, Reis - 2021 - Preconditioning of Domain Decomposition Methods for Joao Felício Dos Reis To cite this version HAL Id tel-03498777.pdf}
}

@article{feng2011,
  title = {ℎ?-{{Discontinuous Galerkin}} Methods for the {{Helmholtz}} Equation with Large Wave Number},
  author = {Feng, Xiaobing and Wu, Haijun},
  year = {2011},
  journal = {Mathematics of Computation},
  volume = {80},
  number = {276},
  pages = {1997--2024},
  doi = {10.1090/s0025-5718-2011-02475-0},
  abstract = {In this paper we develop and analyze some interior penalty     h p  hp    -discontinuous Galerkin (     h p  hp    -DG) methods for the Helmholtz equation with first order absorbing boundary condition in two and three dimensions. The proposed     h p  hp    -DG methods are defined using a sesquilinear form which is not only mesh-dependent (or    h h    -dependent) but also degree-dependent (or    p p    -dependent). In addition, the sesquilinear form contains penalty terms which not only penalize the jumps of the function values across the element edges but also the jumps of the first order tangential derivatives as well as jumps of all normal derivatives up to order    p p    . Furthermore, to ensure the stability, the penalty parameters are taken as complex numbers with positive imaginary parts, so essentially and practically no constraint is imposed on the penalty parameters. It is proved that the proposed     h p  hp    -discontinuous Galerkin methods are stable (hence, well-posed) without any mesh constraint. For each fixed wave number    k k    , sub-optimal order (with respect to    h h    and    p p    ) error estimates in the broken     H 1  H{\textasciicircum}1    -norm and the     L 2  L{\textasciicircum}2    -norm are derived without any mesh constraint. The error estimates as well as the stability estimates are improved to optimal order under the mesh condition      k 3   h 2   p   -   2    {$\leq$}    C 0   k{\textasciicircum}3h{\textasciicircum}2p{\textasciicircum}\{-2\}{\textbackslash}le C\_0    by utilizing these stability and error estimates and using a stability-error iterative procedure, where     C 0  C\_0    is some constant independent of    k k    ,    h h    ,    p p    , and the penalty parameters. To overcome the difficulty caused by strong indefiniteness (and non-Hermitian nature) of the Helmholtz problems in the stability analysis for numerical solutions, our main ideas for stability analysis are to make use of a local version of the Rellich identity (for the Laplacian) and to mimic the stability analysis for the PDE solutions given in [19, 20, 33], which enable us to derive stability estimates and error bounds with explicit dependence on the mesh size    h h    , the polynomial degree    p p    , the wave number    k k    , as well as all the penalty parameters for the numerical solutions.},
  file = {/home/wouter/Zotero/storage/7T6NTTFY/Feng, Wu - 2011 - ℎ-Discontinuous Galerkin methods for the Helmholtz equation with large wave number.pdf}
}

@article{fischer1998,
  title = {Projection Techniques for Iterative Solution of {{Ax}} = b with Successive Right-Hand Sides},
  author = {Fischer, Paul F.},
  year = {1998},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {163},
  number = {1-4},
  pages = {193--204},
  doi = {10.1016/S0045-7825(98)00012-7},
  abstract = {Projection techniques are developed for computing approximate solutions to linear systems of the form Axn = bn, for a sequence n = 1, 2,..., e.g. arising from time discretization of a partial differential equation. The approximate solutions are based upon previous solutions, and can be used as initial guesses for iterative solution of the system, resulting in significantly reduced computational expense. Examples of two-and three-dimensional incompressible Navier-Stokes calculations are presented in which xn represents the pressure at time level tn, and A is a consistent discrete Poisson operator. In flows containing significant dynamic activity, these projection techniques lead to as much as a two-fold reduction in solution time. {\copyright} 1998 Elsevier Science S.A. All rights reserved.},
  file = {/home/wouter/Zotero/storage/LGTTZI2V/Fischer - 1998 - Projection techniques for iterative solution of Ax = b with successive right-hand sides.pdf}
}

@article{fokas1997,
  title = {A Unified Transform Method for Solving Linear and Certain Nonlinear {{PDEs}}},
  author = {Fokas, A. S.},
  year = {1997},
  month = jul,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {453},
  number = {1962},
  pages = {1411--1443},
  doi = {10.1098/rspa.1997.0077},
  abstract = {A new transform method for solving initial boundary value problems for linear and for integrable nonlinear PDEs in two independent variables is introduced. This unified method is based on the fact that linear and integrable nonlinear equations have the distinguished property that they possess a Lax pair formulation. The implementation of this method involves performing a simultaneous spectral analysis of both parts of the Lax pair and solving a Riemann-Hilbert problem. In addition to a unification in the method of solution, there also exists a unification in the representation of the solution. The sine-Gordon equation in light-cone coordinates, the nonlinear Schr{\"o}dinger equation and their linearized versions are used as illustrative examples. It is also shown that appropriate deformations of the Lax pairs of linear equations can be used to construct Lax pairs for integrable nonlinear equations. As an example, a new Lax pair of the nonlinear Schr{\"o}dinger equation is derived. {\copyright} 1997 The Royal Society.},
  file = {/home/wouter/Zotero/storage/K2VWTKVQ/Fokas - 1997 - A unified transform method for solving linear and certain nonlinear PDEs.pdf}
}

@article{fokas2001,
  title = {Two--Dimensional Linear Partial Differential Equations in a Convex Polygon},
  author = {Fokas, A.S},
  year = {2001},
  month = feb,
  journal = {Proceedings of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences},
  volume = {457},
  number = {2006},
  pages = {371--393},
  doi = {10.1098/rspa.2000.0671},
  abstract = {A method is introduced for solving boundary-value problems for linear partial differential equations (PDEs) in convex polygons. It consists of three algorithmic steps. (1) Given a PDE, construct two compatible eigenvalue equations. (2) Given a polygon, perform the simultaneous spectral analysis of these two equations. This yields an integral representation in the complex k-plane of the solution q(x1, x2) in terms of a function {\^q}(k), and an integral representation in the (x1, x2)-plane of {\^q}(k) in terms of the values of q and of its derivatives on the boundary of the polygon. These boundary values are in general related, thus only some of them can be prescribed. (3) Given appropriate boundary conditions, express the part of {\^q}(k) involving the unknown boundary values in terms of the boundary conditions. This is based on the existence of a simple global relation formulated in the complex k-plane, and on the invariant properties of this relation. As an illustration, the following integral representations are obtained: (a) q(x, t) for a general dispersive evolution equation of order n in a domain bounded by a linearly moving boundary; (b) q(x, y) for the Laplace, modified Helmholtz and Helmholtz equations in a convex polygon. These general formulae and the analysis of the associated global relations are used to discuss typical boundary-value problems for evolution equations and for elliptic equations.},
  keywords = {Boundary-value problems,Riemann-Hilbert problem,Wiener-Hopf factorization},
  file = {/home/wouter/Zotero/storage/4J5BIB7W/Fokas - 2001 - Two–dimensional linear partial differential equations in a convex polygon.pdf}
}

@book{fokas2008,
  title = {A {{Unified Approach}} to {{Boundary Value Problems}}},
  author = {Fokas, Athanassios S.},
  year = {2008},
  month = jan,
  journal = {CBMS-NSF Regional Conference Series in Applied Mathematics},
  number = {78},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898717068},
  isbn = {978-0-89871-651-1},
  file = {/home/wouter/Zotero/storage/JCIV7IYU/Fokas - 2008 - A Unified Approach to Boundary Value Problems.pdf}
}

@book{fornaess2024,
  title = {Backtracking {{New Q-Newton}}'s {{Method}}, {{Newton}}'s {{Flow}}, {{Voronoi}}'s {{Diagram}} and {{Stochastic Root Finding}}},
  author = {Forn{\ae}ss, John Erik and Hu, Mi and Truong, Tuyen Trung and Watanabe, Takayuki},
  year = {2024},
  journal = {Complex Analysis and Operator Theory},
  volume = {18},
  doi = {10.1007/s11785-024-01558-6},
  abstract = {A new variant of Newton's method - named Backtracking New Q-Newton's method (BNQN) - which has strong theoretical guarantee, is easy to implement, and has good experimental performance, was recently introduced by the third author. Experiments performed previously showed some remarkable properties of the basins of attractions for finding roots of polynomials and meromorphic functions, with BNQN. In general, they look more smooth than that of Newton's method. In this paper, we continue to experimentally explore in depth this remarkable phenomenon, and connect BNQN to Newton's flow and Voronoi's diagram. This link poses a couple of challenging puzzles to be explained. Experiments also indicate that BNQN is more robust against random perturbations than Newton's method and Random Relaxed Newton's method.},
  isbn = {0-12-345678-9},
  file = {/home/wouter/Zotero/storage/EJ75FIIS/Fornæss et al. - 2024 - Backtracking New Q-Newton’s Method, Newton’s Flow, Voronoi’s Diagram and Stochastic Root Finding.pdf}
}

@article{foster2019,
  title = {Variational {{Bayesian}} Optimal Experimental Design},
  author = {Foster, Adam and Jankowiak, Martin and Bingham, Eli and Horsfall, Paul and Teh, Yee Whye and Rainforth, Tom and Goodman, Noah},
  year = {2019},
  journal = {Advances in Neural Information Processing Systems},
  volume = {32},
  number = {NeurIPS},
  abstract = {Bayesian optimal experimental design (BOED) is a principled framework for making efficient use of limited experimental resources. Unfortunately, its applicability is hampered by the difficulty of obtaining accurate estimates of the expected information gain (EIG) of an experiment. To address this, we introduce several classes of fast EIG estimators by building on ideas from amortized variational inference. We show theoretically and empirically that these estimators can provide significant gains in speed and accuracy over previous approaches. We further demonstrate the practicality of our approach on a number of end-to-end experiments.},
  file = {/home/wouter/Zotero/storage/A7LRW8HW/Foster et al. - 2019 - Variational Bayesian optimal experimental design.pdf}
}

@article{freitag2015,
  title = {Tuned Preconditioners for Inexact Two-Sided Inverse and {{Rayleigh}} Quotient Iteration},
  author = {Freitag, Melina A. and K{\"u}rschner, Patrick},
  year = {2015},
  journal = {Numerical Linear Algebra with Applications},
  volume = {22},
  number = {1},
  pages = {175--196},
  doi = {10.1002/nla.1945},
  abstract = {Convergence results are provided for inexact two-sided inverse and Rayleigh quotient iteration, which extend the previously established results to the generalized non-Hermitian eigenproblem and inexact solves with a decreasing solve tolerance. Moreover, the simultaneous solution of the forward and adjoint problem arising in two-sided methods is considered, and the successful tuning strategy for preconditioners is extended to two-sided methods, creating a novel way of preconditioning two-sided algorithms. Furthermore, it is shown that inexact two-sided Rayleigh quotient iteration and the inexact two-sided Jacobi-Davidson method (without subspace expansion) applied to the generalized preconditioned eigenvalue problem are equivalent when a certain number of steps of a Petrov-Galerkin-Krylov method is used and when this specific tuning strategy is applied.},
  keywords = {Bi-conjugated gradients,Convergence rate,Inexact inverse iteration,Krylov subspace methods,Preconditioning,Two-sided (in)exact Rayleigh quotient iteration,Two-sided Jacobi-Davidson method},
  file = {/home/wouter/Zotero/storage/U3KNAWIR/Freitag, Kürschner - 2015 - Tuned preconditioners for inexact two-sided inverse and Rayleigh quotient iteration.pdf}
}

@article{freitag2018,
  title = {{{GMRES Convergence Bounds}} for {{Eigenvalue Problems}}},
  author = {Freitag, Melina A. and K{\"u}rschner, Patrick and Pestana, Jennifer},
  year = {2018},
  journal = {Computational Methods in Applied Mathematics},
  volume = {18},
  number = {2},
  pages = {203--222},
  doi = {10.1515/cmam-2017-0017},
  abstract = {The convergence of GMRES for solving linear systems can be influenced heavily by the structure of the right-hand side. Within the solution of eigenvalue problems via inverse iteration or subspace iteration, the right-hand side is generally related to an approximate invariant subspace of the linear system. We give detailed and new bounds on (block) GMRES that take the special behavior of the right-hand side into account and explain the initial sharp decrease of the GMRES residual. The bounds motivate the use of specific preconditioners for these eigenvalue problems, e.g., tuned and polynomial preconditioners, as we describe. The numerical results show that the new (block) GMRES bounds are much sharper than conventional bounds and that preconditioned subspace iteration with either a tuned or polynomial preconditioner should be used in practice.},
  keywords = {Block Krylov Methods,Convergence Analysis,GMRES,Inexact Inverse Iteration,Inexact Subspace Iteration,Krylov Subspace Methods,Preconditioning},
  file = {/home/wouter/Zotero/storage/VKJ3S282/Freitag, Kürschner, Pestana - 2018 - GMRES Convergence Bounds for Eigenvalue Problems.pdf}
}

@article{fuhrmann2021,
  title = {On the {{Gaussian Approximation}} to {{Bayesian Posterior Distributions}}},
  author = {Fuhrmann, Christoph and Harney, Hanns-Ludwig and Harney, Klaus and Muller, Andreas},
  year = {2021},
  month = jul,
  journal = {Mathematics and Statistics},
  volume = {9},
  number = {4},
  pages = {535--551},
  issn = {2332-2071, 2332-2144},
  doi = {10.13189/ms.2021.090413},
  urldate = {2025-01-13},
  langid = {english},
  file = {/home/wouter/Zotero/storage/3UD6AA3F/Fuhrmann et al. - 2021 - On the Gaussian Approximation to Bayesian Posterior Distributions.pdf}
}

@article{gagnon2015,
  title = {Lorenz-{{Mie}} Theory for {{2D}} Scattering and Resonance Calculations},
  author = {Gagnon, Denis and Dub{\'e}, Louis J.},
  year = {2015},
  journal = {Journal of Optics (United Kingdom)},
  volume = {17},
  number = {10},
  publisher = {IOP Publishing},
  doi = {10.1088/2040-8978/17/10/103501},
  abstract = {This PhD tutorial is concerned with a description of the two-dimensional generalized Lorenz-Mie theory (2D-GLMT), a well-established numerical method used to compute the interaction of light with arrays of cylindrical scatterers. This theory is based on the method of separation of variables and the application of an addition theorem for cylindrical functions. The purpose of this tutorial is to assemble the practical tools necessary to implement the 2D-GLMT method for the computation of scattering by passive scatterers or of resonances in optically active media. The first part contains a derivation of the vector and scalar Helmholtz equations for 2D geometries, starting from Maxwell's equations. Optically active media are included in 2D-GLMT using a recent stationary formulation of the Maxwell-Bloch equations called steady-state ab initio laser theory (SALT), which introduces new classes of solutions useful for resonance computations. Following these preliminaries, a detailed description of 2D-GLMT is presented. The emphasis is placed on the derivation of beam-shape coefficients for scattering computations, as well as the computation of resonant modes using a combination of 2D-GLMT and SALT. The final section contains several numerical examples illustrating the full potential of 2D-GLMT for scattering and resonance computations. These examples, drawn from the literature, include the design of integrated polarization filters and the computation of optical modes of photonic crystal cavities and random lasers.},
  keywords = {cavities,integrated optics,modeling,photonics,random lasers,scattering},
  file = {/home/wouter/Zotero/storage/2L5ALIFJ/Gagnon, Dubé - 2015 - Lorenz-Mie theory for 2D scattering and resonance calculations.pdf}
}

@article{galkowski2020,
  title = {Optimal Constants in Nontrapping Resolvent Estimates and Applications in Numerical Analysis},
  author = {Galkowski, Jeffrey and Spence, Euan A. and Wunsch, Jared},
  year = {2020},
  month = jan,
  journal = {Pure and Applied Analysis},
  volume = {2},
  number = {1},
  pages = {157--202},
  issn = {2578-5885, 2578-5893},
  doi = {10.2140/paa.2020.2.157},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/PN9R3J54/Galkowski et al. - 2020 - Optimal constants in nontrapping resolvent estimates and applications in numerical analysis.pdf}
}

@article{galkowski2023,
  title = {Does the {{Helmholtz Boundary Element Method Suffer}} from the {{Pollution Effect}}?},
  author = {Galkowski, J. and Spence, E. A.},
  year = {2023},
  month = aug,
  journal = {SIAM Review},
  volume = {65},
  number = {3},
  pages = {806--828},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/22M1474199},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/99NG6BK6/Galkowski and Spence - 2023 - Does the Helmholtz Boundary Element Method Suffer from the Pollution Effect.pdf}
}

@article{galy-fajou2021,
  title = {Flexible and Efficient Inference with Particles for the Variational Gaussian Approximation},
  author = {{Galy-Fajou}, Th{\'e}o and Perrone, Valerio and Opper, Manfred},
  year = {2021},
  journal = {Entropy},
  volume = {23},
  number = {8},
  pages = {1--34},
  doi = {10.3390/e23080990},
  abstract = {Variational inference is a powerful framework, used to approximate intractable posteriors through variational distributions. The de facto standard is to rely on Gaussian variational families, which come with numerous advantages: they are easy to sample from, simple to parametrize, and many expectations are known in closed-form or readily computed by quadrature. In this paper, we view the Gaussian variational approximation problem through the lens of gradient flows. We introduce a flexible and efficient algorithm based on a linear flow leading to a particle-based approximation. We prove that, with a sufficient number of particles, our algorithm converges linearly to the exact solution for Gaussian targets, and a low-rank approximation otherwise. In addition to the theoretical analysis, we show, on a set of synthetic and real-world high-dimensional problems, that our algorithm outperforms existing methods with Gaussian targets while performing on a par with non-Gaussian targets.},
  keywords = {Gaussian,Particle flow,Variable flow,Variational inference},
  file = {/home/wouter/Zotero/storage/I8EJSWC3/Galy-Fajou, Perrone, Opper - 2021 - Flexible and efficient inference with particles for the variational gaussian approximation.pdf}
}

@article{gander2015,
  title = {Applying {{GMRES}} to the {{Helmholtz}} Equation with Shifted {{Laplacian}} Preconditioning: What Is the Largest Shift for Which Wavenumber-Independent Convergence Is Guaranteed?},
  author = {Gander, M. J. and Graham, I. G. and Spence, E. A.},
  year = {2015},
  journal = {Numerische Mathematik},
  volume = {131},
  number = {3},
  pages = {567--614},
  doi = {10.1007/s00211-015-0700-2},
  abstract = {There has been much recent research on preconditioning discretisations of the Helmholtz operator {$\Delta$} + k2 (subject to suitable boundary conditions) using a discrete version of the so-called ``shifted Laplacian'' {$\Delta$} + (k2+i{$\varepsilon$}) for some {$\varepsilon$} {$>$} 0. This is motivated by the fact that, as {$\varepsilon$} increases, the shifted problem becomes easier to solve iteratively. Despite many numerical investigations, there has been no rigorous analysis of how to chose the shift. In this paper, we focus on the question of how large {$\varepsilon$} can be so that the shifted problem provides a preconditioner that leads to k-independent convergence of GMRES, and our main result is a sufficient condition on {$\varepsilon$} for this property to hold. This result holds for finite element discretisations of both the interior impedance problem and the sound-soft scattering problem (with the radiation condition in the latter problem imposed as a far-field impedance boundary condition). Note that we do not address the important question of how large {$\varepsilon$} should be so that the preconditioner can easily be inverted by standard iterative methods.},
  keywords = {35J05,65F08,65F10,65N30,78A45},
  file = {/home/wouter/Zotero/storage/C687TM4C/Gander, Graham, Spence - 2015 - Applying GMRES to the Helmholtz equation with shifted Laplacian preconditioning what is the largest shif.pdf}
}

@article{gander2019,
  title = {A {{Class}} of {{Iterative Solvers}} for the {{Helmholtz Equation}}: {{Factorizations}}, {{Sweeping Preconditioners}}, {{Source Transfer}}, {{Single Layer Potentials}}, {{Polarized Traces}}, and {{Optimized Schwarz Methods}}},
  author = {Gander, Martin J. and Zhang, Hui},
  year = {2019},
  month = jan,
  journal = {SIAM Review},
  volume = {61},
  number = {1},
  pages = {3--76},
  doi = {10.1137/16M109781X},
  abstract = {Solving time-harmonic wave propagation problems by iterative methods is a difficult task, and over the last two decades an important research effort has gone into developing preconditioners for the simplest representative of such wave propagation problems, the Helmholtz equation. A specific class of these new preconditioners is considered here. They were developed by researchers with various backgrounds using formulations and notations that are very different, and all are among the most promising preconditioners for the Helmholtz equation. The goal of the present article is to show that this class of preconditioners is based on a common mathematical principle, and that they can all be formulated in the context of domain decomposition methods known as optimized Schwarz methods. This common formulation allows us to explain in detail how and why all these methods work. The domain decomposition formulation also allows us to avoid technicalities in the implementation description we give of these recent methods. The equivalence of these methods with optimized Schwarz methods translates at the discrete level into equivalence with approximate block LU decomposition preconditioners, and in each case we give the algebraic version, including a detailed description of the approximations used. While we choose to use the Helmholtz equation for which these methods were developed, our notation is completely general and the algorithms we give are written for an arbitrary second-order elliptic operator. The algebraic versions are even more general, assuming only a connectivity pattern in the discretization matrix. All the new methods studied here are based on sequential decomposition of the problem in space into a sequence of subproblems, and they have in their optimal form the property to lead to nilpotent iterations, like an exact block LU factorization. Using our domain decomposition formulation, we finally present an algorithm for two-dimensional decompositions, i.e., decompositions that contain cross points, which is still nilpotent in its optimal form. Its approximation is currently an active area of research, and it would have been difficult to discover such an algorithm without the domain decomposition framework.},
  keywords = {Factorization,Helmholtz,Iterative,Preconditioner,Schwarz,Sweeping},
  file = {/home/wouter/Zotero/storage/AMIK36M7/Gander, Zhang - 2019 - A Class of Iterative Solvers for the Helmholtz Equation Factorizations, Sweeping Preconditioners, Source Transfer.pdf}
}

@book{gantner2017,
  title = {Computational {{Higher-Order Quasi-Monte Carlo}} for {{Random Partial Differential Equations}}},
  author = {Gantner, Robert Nicholas},
  year = {2017},
  number = {24529},
  doi = {10.3929/ethz-b-000182695},
  isbn = {978-3-906327-96-9},
  keywords = {High,Monte Carlo,Performance Computing,Quasi,Uncertainty Quantification},
  file = {/home/wouter/Zotero/storage/GD3LCJXB/Gantner - 2017 - Computational Higher-Order Quasi-Monte Carlo for Random Partial Differential Equations.pdf}
}

@article{gantner2018,
  title = {Higher-{{Order Quasi-Monte Carlo}} for {{Bayesian Shape Inversion}}},
  author = {Gantner, R N and Peters, M D},
  year = {2018},
  month = jan,
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  volume = {6},
  number = {2},
  pages = {707--736},
  doi = {10.1137/16M1096116},
  abstract = {In this article, we consider a Bayesian approach towards data assimilation and uncertainty quantification in diffusion problems on random domains. We provide a rigorous analysis of parametric regularity of the posterior distribution given that the data exhibit only limited smoothness. Moreover, we present a dimension truncation analysis for the forward problem, which is formulated in terms of the domain mapping method. Having these novel results at hand, we shall consider as a practical example electrical impedance tomography in the regime of constant conductivities. We are interested in computing moments, in particular, expectation and variance, of the contour of an unknown inclusion, given perturbed surface measurements. By casting the forward problem into the framework of elliptic diffusion problems on random domains, we can directly apply the presented analysis. This straightforwardly yields parametric regularity results for the system response and for the posterior measure, facilitating the application of higher-order quadrature methods for the approximation of moments of quantities of interest. As an example of such a quadrature method, we consider here recently developed higher-order quasi-Monte Carlo methods. To solve the forward problem numerically, we employ a fast boundary integral solver. Numerical examples are provided to illustrate the presented approach and validate the theoretical findings.},
  keywords = {Electrical impedance tomography,Error estimates,High-dimensional quadrature,Quasi-Monte Carlo methods,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/6VJWS9ZY/Gantner, Peters - 2018 - Higher-Order Quasi-Monte Carlo for Bayesian Shape Inversion.pdf}
}

@book{garcke2016,
  title = {Sparse Grids and Applications --- {{Stuttgart}} 2014},
  author = {Garcke, Jochen and Pfl{\"u}ger, Dirk},
  year = {2016},
  journal = {Lecture Notes in Computational Science and Engineering},
  volume = {109},
  isbn = {978-3-319-28260-2},
  file = {/home/wouter/Zotero/storage/7KS5FFZL/Garcke, Pflüger - 2016 - Sparse grids and applications — Stuttgart 2014.pdf}
}

@article{gatto2015,
  title = {Numerical {{Approximation}} of the {{Fractional Laplacian}} via \$\$hp\$\$ h p -Finite {{Elements}}, with an {{Application}} to {{Image Denoising}}},
  author = {Gatto, Paolo and Hesthaven, Jan S.},
  year = {2015},
  month = oct,
  journal = {Journal of Scientific Computing},
  volume = {65},
  number = {1},
  pages = {249--270},
  publisher = {Springer US},
  issn = {1091501499591},
  doi = {10.1007/s10915-014-9959-1},
  abstract = {The fractional Laplacian operator (-{$\Delta$})s on a bounded domain {\textohm} can be realized as a Dirichlet-to-Neumann map for a degenerate elliptic equation posed in the semi-infinite cylinder {\textohm}{\texttimes}(0,{$\infty$}). In fact, the Neumann trace on {\textohm} involves a Muckenhoupt weight that, according to the fractional exponent s, either vanishes (s{$<$}1/2) or blows up (s{$>$}1/2). On the other hand, the normal trace of the solution has the reverse behavior, thus making the Neumann trace analytically well-defined. Nevertheless, the solution develops an increasingly sharp boundary layer in the vicinity of {\textohm} as s decreases. In this work, we extend the technology of automatic hp-adaptivity, originally developed for standard elliptic equations, to the energy setting of a Sobolev space with a Muckenhoupt weight, in order to accommodate for the problem of interest. The numerical evidence confirms that the method maintain exponential convergence. Finally, we discuss image denoising via the fractional Laplacian. In the image processing community, the standard way to apply the fractional Laplacian to a corrupted image is as a filter in Fourier space. This construction is inherently affected by the Gibbs phenomenon, which prevents the direct application to ``spliced'' images. Since our numerical approximation relies instead on the extension problem, it allows for processing different portions of a noisy image independently and combine them, without complications induced by the Gibbs phenomenon.},
  keywords = {Automatic adaptivity,Fractional Laplacian,hp-finite elements,Image denoising},
  file = {/home/wouter/Zotero/storage/BLLWJWM9/Gatto, Hesthaven - 2015 - Numerical Approximation of the Fractional Laplacian via $$hp$$ h p -finite Elements, with an Application to Im.pdf}
}

@article{geist2021,
  title = {Numerical {{Solution}} of the {{Parametric Diffusion Equation}} by {{Deep Neural Networks}}},
  author = {Geist, Moritz and Petersen, Philipp and Raslan, Mones and Schneider, Reinhold and Kutyniok, Gitta},
  year = {2021},
  journal = {Journal of Scientific Computing},
  volume = {88},
  number = {1},
  pages = {1--37},
  publisher = {Springer US},
  doi = {10.1007/s10915-021-01532-w},
  abstract = {We perform a comprehensive numerical study of the effect of approximation-theoretical results for neural networks on practical learning problems in the context of numerical analysis. As the underlying model, we study the machine-learning-based solution of parametric partial differential equations. Here, approximation theory for fully-connected neural networks predicts that the performance of the model should depend only very mildly on the dimension of the parameter space and is determined by the intrinsic dimension of the solution manifold of the parametric partial differential equation. We use various methods to establish comparability between test-cases by minimizing the effect of the choice of test-cases on the optimization and sampling aspects of the learning problem. We find strong support for the hypothesis that approximation-theoretical effects heavily influence the practical behavior of learning problems in numerical analysis. Turning to practically more successful and modern architectures, at the end of this study we derive improved error bounds by focusing on convolutional neural networks.},
  keywords = {Neural network capacity,Neural networks,Numerical approximation,Parametric diffusion equation},
  file = {/home/wouter/Zotero/storage/AAGKZKQX/Geist et al. - 2021 - Numerical Solution of the Parametric Diffusion Equation by Deep Neural Networks.pdf}
}

@article{geman1984,
  title = {Stochastic Relaxation, {{Gibbs}} Distributions, and the {{Bayesian}} Restoration of Images},
  author = {Geman, Stuart and Geman, Donald},
  year = {1984},
  journal = {IEEE Transactions on pattern analysis and machine intelligence},
  number = {6},
  pages = {721--741},
  publisher = {IEEE}
}

@misc{geroch1997,
  title = {Suggestions {{For Giving Talks}}},
  author = {Geroch, Robert},
  year = {1997},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.GR-QC/9703019},
  urldate = {2025-01-13},
  abstract = {This is a latex'd version of Robert Geroch's 1973 notes entitled 'Suggestions For Giving Talks'.},
  copyright = {Assumed arXiv.org perpetual, non-exclusive license to distribute this article for submissions made before January 2004},
  keywords = {FOS: Physical sciences,General Relativity and Quantum Cosmology (gr-qc)},
  file = {/home/wouter/Zotero/storage/5UZ8F723/Geroch - 1997 - Suggestions For Giving Talks.pdf}
}

@article{gerstner2003,
  title = {Dimension-{{Adaptive Tensor-Product Quadrature}}},
  author = {Gerstner, T. and Griebel, M.},
  year = {2003},
  journal = {Computing (Vienna/New York)},
  volume = {71},
  number = {1},
  pages = {65--87},
  doi = {10.1007/s00607-003-0015-5},
  abstract = {We consider the numerical integration of multivariate functions defined over the unit hypercube. Here, we especially address the high-dimensional case, where in general the curse of dimension is encountered. Due to the concentration of measure phenomenon, such functions can often be well approximated by sums of lower-dimensional terms. The problem, however, is to find a good expansion given little knowledge of the integrand itself. The dimension-adaptive quadrature method which is developed and presented in this paper aims to find such an expansion automatically. It is based on the sparse grid method which has been shown to give good results for low- and moderate-dimensional problems. The dimension-adaptive quadrature method tries to find important dimensions and adaptively refines in this respect guided by suitable error estimators. This leads to an approach which is based on generalized sparse grid index sets. We propose efficient data structures for the storage and traversal of the index sets and discuss an efficient implementation of the algorithm. The performance of the method is illustrated by several numerical examples from computational physics and finance where dimension reduction is obtained from the Brownian bridge discretization of the underlying stochastic process.},
  keywords = {Adaptivity,Curse of dimension,Multivariate numerical integration},
  file = {/home/wouter/Zotero/storage/4YCDBIPH/Gerstner, Griebel - 2003 - Dimension-Adaptive Tensor-Product Quadrature.pdf}
}

@article{gerstner2010,
  title = {Sparse {{Grids}}},
  author = {Gerstner, Thomas and Griebel, Michael},
  year = {2010},
  journal = {Encyclopedia of Quantitative Finance},
  doi = {10.1002/9780470061602.eqf12011},
  abstract = {One coordinate direction at the boundary. The accuracy obtained with piece- wise linear basis functions, for example, is O(N2 (logN)d1) with respect to the L2-and L-norm, if the solution has bounded second mixed derivatives. This way, the curse of dimensionality, i.e., the exponential dependence O(Nd) of conventional approaches, is overcome to some extent. For the energy norm, only O(N) degrees of freedom are needed to give an accuracy of O(N1). That is why sparse grids are especially well-suited for problems of very high dimensionality. The sparse grid approach can be extended to nonsmooth solutions by adaptive refinement methods. Furthermore, it can be generalized from piecewise linear to higher-order polynomials. Also, more sophisticated basis functions like interpolets, prewavelets, or wavelets can be used in a straightforward way. We describe the basic features of sparse grids and report the results of various numerical experiments for the solution of elliptic PDEs as well as for other selected problems such as numerical quadrature and data mining.},
  file = {/home/wouter/Zotero/storage/AZBSZX3J/Gerstner, Griebel - 2010 - Sparse Grids.pdf}
}

@article{geuzaine2009,
  title = {Gmsh: {{A}} 3-{{D}} Finite Element Mesh Generator with Built-in Pre- and Post-Processing Facilities},
  author = {Geuzaine, Christophe and Remacle, Jean-Fran{\c c}ois},
  year = {2009},
  month = sep,
  journal = {International Journal for Numerical Methods in Engineering},
  volume = {79},
  number = {11},
  pages = {1309--1331},
  doi = {10.1002/nme.2579},
  file = {/home/wouter/Zotero/storage/D23EY7VW/Geuzaine, Remacle - 2009 - Gmsh A 3-D finite element mesh generator with built-in pre- and post-processing facilities.pdf}
}

@article{geweke1989,
  title = {Bayesian Inference in Econometric Models Using {{Monte Carlo}} Integration},
  author = {Geweke, John},
  year = {1989},
  journal = {Econometrica: Journal of the Econometric Society},
  pages = {1317--1339},
  publisher = {JSTOR}
}

@article{ghanem1996,
  title = {Numerical Solution of Spectral Stochastic Finite Element Systems},
  author = {Ghanem, Roger G. and Kruger, Robert M.},
  year = {1996},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {129},
  number = {3},
  pages = {289--303},
  doi = {10.1016/0045-7825(95)00909-4},
  abstract = {This paper addresses the issues involved in solving systems of linear equations which arise in the context of the spectral stochastic finite element (SSFEM) formulation. Two efficient solution procedures are presented that dramatically reduce the amount of computations involved in numerically solving these problems. A brief review is first provided of the underlying spectral approach which highlights the peculiar structure of the matrices generated and how their properties are related to both the level of approximation involved as well as to the convergence behavior of the proposed solution procedure. The differences between these matrices from their deterministic finite element counterparts are illustrated. An iterative solution scheme is proposed, which utilizes their specific properties for efficient memory management and enhanced convergence behavior. Results from numerical tests are presented. Comparisons with standard algorithms illustrate the efficiency of the proposed algorithm. The second solution procedure presented in this paper is based on hierarchical basis concepts. Results from numerical tests are again provided, and the limitations of this approach are assessed. The performance of both proposed algorithms indicates that the linear algebraic systems from the underlying SSFEM formulation can be solved with considerably less effort in memory and computation time than their size suggests. Furthermore, the data structures and the hierarchical concept introduced in this study are found to have great potential for the future development of adaptive procedures in stochastic FEM.},
  file = {/home/wouter/Zotero/storage/SRVZBYK6/Ghanem, Kruger - 1996 - Numerical solution of spectral stochastic finite element systems.pdf}
}

@article{ghanem1998,
  title = {Stochastic {{Finite Element Analysis}} for {{Multiphase Flow}} in {{Heterogeneous Porous Media}}},
  author = {Ghanem, R. and Dham, S.},
  year = {1998},
  journal = {Transport in Porous Media},
  volume = {32},
  number = {3},
  pages = {239--262},
  issn = {01693913},
  doi = {10.1023/A:1006514109327},
  urldate = {2025-02-13},
  file = {/home/wouter/Zotero/storage/B465V3ES/Ghanem and Dham - 1998 - [No title found].pdf}
}

@book{ghanem2003,
  title = {Stochastic Finite Elements: A Spectral Approach},
  author = {Ghanem, Roger G and Spanos, Pol D},
  year = {2003},
  publisher = {Courier Corporation}
}

@book{gilbarg1997,
  title = {Elliptic {{Partial Differential Equations}} of {{Second Order}}},
  author = {Gilbarg, David and Trudinger, Neil S},
  year = {1997},
  publisher = {Springer},
  abstract = {his revision of the 1983 second edition of "Elliptic Partial Differential Equations of Second Order" corresponds to the Russian edition, published in 1989, in which we essentially updated the previous version to 1984. The additional text relates to the boundary Holder derivative estimates of Nikolai Krylov, which provided a fundamental component of the further development of the classical theory of elliptic (and parabolic), fully nonlinear equations in higher dimensions. In our presentation we adapted a simplification of Krylov's approach due to Luis Caffarelli. The theory of nonlinear second order elliptic equations has continued to flourish during the last fifteen years and, in a brief epilogue to this volume, we signal some of the major advances. Although a proper treatment would necessi- tate at least another monograph, it is our hope that this book, most of whose text is now more than twenty years old, can continue to serve as background for these and future developments. Since our first edition we have become indebted to numerous colleagues, all over the globe. It was particularly pleasant in recent years to make and renew friendships with our Russian colleagues, Olga Ladyzhenskaya, Nina Ural'tseva, Nina Ivochkina, Nikolai Krylov and Mikhail Safonov, who have contributed so much to this area. Sadly, we mourn the passing away in 1996 of Ennico De Giorgi, whose brilliant discovery forty years ago opened the door to the higher-dimen- sional nonlinear theory.},
  isbn = {978-3-540-41160-4},
  file = {/home/wouter/Zotero/storage/Q6PKB7F8/Gilbarg, Trudinger - 1997 - Elliptic Partial Differential Equations of Second Order.pdf}
}

@article{giles2008,
  title = {Multilevel {{Monte Carlo}} Path Simulation},
  author = {Giles, Michael B.},
  year = {2008},
  journal = {Operations Research},
  volume = {56},
  number = {3},
  pages = {607--617},
  doi = {10.1287/opre.1070.0496},
  abstract = {We show that multigrid ideas can be used to reduce the computational complexity of estimating an expected value arising from a stochastic differential equation using Monte Carlo path simulations. In the simplest case of a Lipschitz payoff and a Euler discretisation, the computational cost to achieve an accuracy of O({$\varepsilon$}) is reduced from O({$\varepsilon$}-3) to O({$\varepsilon$}-2(log{$\varepsilon$})2). The analysis is supported, by numerical results showing significant computational savings. {\copyright} 2008 INFORMS.},
  keywords = {Analysis of algorithms: Computational complexity,Finance,Simulation: Efficiency. Area of review : Financial},
  file = {/home/wouter/Zotero/storage/HW2BWREN/Giles - 2008 - Multilevel Monte Carlo path simulation.pdf}
}

@article{giles2015,
  title = {Multilevel {{Monte Carlo}} Methods},
  author = {Giles, Michael B.},
  year = {2015},
  journal = {Acta Numerica},
  volume = {24},
  pages = {259--328},
  doi = {10.1017/S096249291500001X},
  abstract = {Monte Carlo methods are a very general and useful approach for the estimation of expectations arising from stochastic simulation. However, they can be computationally expensive, particularly when the cost of generating individual stochastic samples is very high, as in the case of stochastic PDEs. Multilevel Monte Carlo is a recently developed approach which greatly reduces the computational cost by performing most simulations with low accuracy at a correspondingly low cost, with relatively few simulations being performed at high accuracy and a high cost. In this article, we review the ideas behind the multilevel Monte Carlo method, and various recent generalizations and extensions, and discuss a number of applications which illustrate the flexibility and generality of the approach and the challenges in developing more efficient implementations with a faster rate of convergence of the multilevel correction variance.},
  file = {/home/wouter/Zotero/storage/W8JC7GQ4/Giles - 2015 - Multilevel Monte Carlo methods.pdf}
}

@article{gilks2001,
  title = {Following a Moving Target - {{Monte Carlo}} Inference for Dynamic {{Bayesian}} Models},
  author = {Gilks, Walter R. and Berzuini, Carlo},
  year = {2001},
  journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  volume = {63},
  number = {1},
  pages = {127--146},
  doi = {10.1111/1467-9868.00280},
  abstract = {Markov chain Monte Carlo (MCMC) sampling is a numerically intensive simulation technique which has greatly improved the practicality of Bayesian inference and prediction. However, MCMC sampling is too slow to be of practical use in problems involving a large number of posterior (target) distributions, as in dynamic modelling and predictive model selection. Alternative simulation techniques for tracking moving target distributions, known as particle filters, which combine importance sampling, importance resampling and MCMC sampling, tend to suffer from a progressive degeneration as the target sequence evolves. We propose a new technique, based on these same simulation methodologies, which does not suffer from this progressive degeneration.},
  keywords = {Bayesian inference,Dynamic model,Hidden Markov model,Importance resampling,Importance sampling,Markov chain Monte Carlo methods,Particle filter,Predictive model selection,Sequential imputation,Simulation,Tracking},
  file = {/home/wouter/Zotero/storage/N9NNI72H/Gilks, Berzuini - 2001 - Following a moving target - Monte Carlo inference for dynamic Bayesian models.pdf}
}

@incollection{ginsbourger2010,
  title = {Kriging {{Is Well-Suited}} to {{Parallelize Optimization}}},
  booktitle = {Computational {{Intelligence}} in {{Expensive Optimization Problems}}},
  author = {Ginsbourger, David and Le Riche, Rodolphe and Carraro, Laurent},
  editor = {Hiot, Lim Meng and Ong, Yew Soon and Tenne, Yoel and Goh, Chi-Keong},
  year = {2010},
  volume = {2},
  pages = {131--162},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-10701-6_6},
  urldate = {2024-10-02},
  isbn = {978-3-642-10700-9 978-3-642-10701-6}
}

@article{ginsbourger2012,
  title = {Argumentwise Invariant Kernels for the Approximation of Invariant Functions},
  author = {Ginsbourger, David and Bay, Xavier and Roustant, Olivier and Carraro, Laurent},
  year = {2012},
  month = oct,
  journal = {Annales de la Facult{\'e} des sciences de Toulouse : Math{\'e}matiques},
  volume = {21},
  number = {3},
  pages = {501--527},
  issn = {2258-7519},
  doi = {10.5802/afst.1343},
  urldate = {2024-10-29},
  langid = {english},
  file = {/home/wouter/Zotero/storage/RU79682U/Ginsbourger et al. - 2012 - Argumentwise invariant kernels for the approximation of invariant functions.pdf}
}

@article{ginsbourger2016,
  title = {On Degeneracy and Invariances of Random Fields Paths with Applications in {{Gaussian}} Process Modelling},
  author = {Ginsbourger, David and Roustant, Olivier and Durrande, Nicolas},
  year = {2016},
  month = mar,
  journal = {Journal of Statistical Planning and Inference},
  volume = {170},
  pages = {117--128},
  issn = {03783758},
  doi = {10.1016/j.jspi.2015.10.002},
  urldate = {2024-11-01},
  langid = {english},
  file = {/home/wouter/Zotero/storage/PPG56D5M/Ginsbourger et al. - 2016 - On degeneracy and invariances of random fields paths with applications in Gaussian process modelling.pdf}
}

@article{girouard2022,
  title = {The {{Dirichlet-to-Neumann}} Map, the Boundary {{Laplacian}}, and {{H{\"o}rmander}}'s Rediscovered Manuscript},
  author = {Girouard, Alexandre and Karpukhin, Mikhail and Levitin, Michael and Polterovich, Iosif},
  year = {2022},
  month = mar,
  journal = {Journal of Spectral Theory},
  volume = {12},
  number = {1},
  pages = {195--225},
  doi = {10.4171/JST/399},
  abstract = {How close is the Dirichlet-to-Neumann (DtN) map to the square root of the corresponding boundary Laplacian? This question has been actively investigated in recent years. Somewhat surprisingly, a lot of techniques involved can be traced back to a newly rediscovered manuscript of H{\"o}rmander from the 1950s. We present H{\"o}rmander's approach and its applications, with an emphasis on eigenvalue estimates and spectral asymptotics. In particular, we obtain results for the DtN maps on non-smooth boundaries in the Riemannian setting, the DtN operators for the Helmholtz equation and the DtN operators on differential forms.},
  keywords = {Dirichlet eigenvalues,Dirichlet-to-Neumann map,eigenvalue asymptotics,Laplace-Beltrami operator,Robin eigenvalues},
  file = {/home/wouter/Zotero/storage/ZC62EQT8/Girouard et al. - 2022 - The Dirichlet-to-Neumann map, the boundary Laplacian, and Hörmander’s rediscovered manuscript.pdf}
}

@article{gittelson2013,
  title = {An Adaptive Stochastic {{Galerkin}} Method for Random Elliptic Operators},
  author = {Gittelson, Claude Jeffrey},
  year = {2013},
  volume = {82},
  number = {283},
  pages = {1515--1541},
  file = {/home/wouter/Zotero/storage/J8G9YGPM/Gittelson - 2013 - An adaptive stochastic Galerkin method for random elliptic operators.pdf}
}

@article{gittelson2014,
  title = {Adaptive Wavelet Methods for Elliptic Partial Differential Equations with Random Operators},
  author = {Gittelson, Claude Jeffrey},
  year = {2014},
  journal = {Numerische Mathematik},
  volume = {126},
  number = {3},
  pages = {471--513},
  doi = {10.1007/s00211-013-0572-2},
  abstract = {We apply adaptive wavelet methods to boundary value problems with random coefficients, discretized by wavelets in the spatial domain and tensorized polynomials in the parameter domain. Greedy algorithms control the approximate application of the fully discretized random operator, and the construction of sparse approximations to this operator. We suggest a power iteration for estimating errors induced by sparse approximations of linear operators. {\copyright} 2013 Springer-Verlag Berlin Heidelberg.},
  file = {/home/wouter/Zotero/storage/PTNDHXDC/Gittelson - 2014 - Adaptive wavelet methods for elliptic partial differential equations with random operators.pdf}
}

@article{givoli1989,
  title = {A Finite Element Method for Large Domains},
  author = {Givoli, Dan and Keller, Joseph B.},
  year = {1989},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {76},
  number = {1},
  pages = {41--66},
  doi = {10.1016/0045-7825(89)90140-0},
  abstract = {A combined analytical and numerical method is devised to solve elliptic boundary value problems in large or infinite domains. First the domain is divided by an artificial boundary B into a small computational domain {\textohm} and a large or infinite residual domain D. In D the problem is solved analytically, and from the solution an exact nonlocal relation between the solution and its derivatives on B is deduced. This relation is used as a boundary condition to complete the formulation of a problem in {\textohm} which has exactly the same solution there as the original problem. Then a finite element formulation of this new problem in {\textohm} is presented. The exact nonlocal boundary condition is given explicitly for Laplace's equation, for the equations of plane stress and plane strain in linear elastostatics, and for certain equations governing beams and axisymmetric cylindrical shells. The artificial boundary is chosen to be a sphere or a circle. The properties and computational implications of the boundary condition are discussed. Some numerical examples are presented, and the results are compared with those obtained by the standard finite element method using different approximate local boundary conditions on the artificial boundary. {\copyright} 1989.},
  file = {/home/wouter/Zotero/storage/SGKGHFYW/Givoli, Keller - 1989 - A finite element method for large domains.pdf}
}

@article{goda2015,
  title = {Good Interlaced Polynomial Lattice Rules for Numerical Integration in Weighted {{Walsh}} Spaces},
  author = {Goda, Takashi},
  year = {2015},
  journal = {Journal of Computational and Applied Mathematics},
  volume = {285},
  pages = {279--294},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.cam.2015.02.041},
  abstract = {Quadrature rules using higher order digital nets and sequences are known to exploit the smoothness of a function for numerical integration and to achieve an improved rate of convergence as compared to classical digital nets and sequences for smooth functions. A construction principle of higher order digital nets and sequences based on a digit interlacing function was introduced in Dick (2007), which interlaces classical digital nets or sequences whose number of components is a multiple of the dimension. In this paper, we study the use of polynomial lattice point sets for interlaced components. We call quadrature rules using such point sets interlaced polynomial lattice rules. We consider weighted Walsh spaces containing smooth functions and derive two upper bounds on the worst-case error for interlaced polynomial lattice rules, both of which can be employed as a quality criterion for the construction of interlaced polynomial lattice rules. We investigate the component-by-component construction and the Korobov construction as a means of explicit constructions of good interlaced polynomial lattice rules that achieve the optimal rate of the worst-case error. Through this approach we are able to obtain a good dependence of the worst-case error bounds on the dimension under certain conditions on the weights, while significantly reducing the construction cost as compared to higher order polynomial lattice rules.},
  keywords = {Carlo,Higher order digital nets,Interlaced polynomial lattice rules,Numerical integration,Quasi-Monte},
  file = {/home/wouter/Zotero/storage/LU7FEVYK/Goda - 2015 - Good interlaced polynomial lattice rules for numerical integration in weighted Walsh spaces.pdf}
}

@article{gogoladze2022,
  title = {On the Absolute Convergence of Orthogonal Series},
  author = {Gogoladze, Larry},
  year = {2022},
  month = aug,
  journal = {Georgian Mathematical Journal},
  volume = {29},
  number = {4},
  pages = {527--532},
  doi = {10.1515/gmj-2022-2151},
  abstract = {We obtain sufficient conditions for the absolute convergence of Fourier series for functions of L{\textasciitilde}r depending on the properties of the function being expanded and the rate of growth of the sums {\textasciitilde},k=tr of the system of functions \{q{\textasciitilde}k(t)\} orthonormalized in [a, b] with re- spect 1;o de(t). We show that if at some point x{\textasciitilde} [a, b] the function r has a discontinuity, at that point the Fourier series of any function f(t) E L2r converges absolutely. i.},
  file = {/home/wouter/Zotero/storage/RD8VEEMQ/Gogoladze - 2022 - On the absolute convergence of orthogonal series.pdf}
}

@article{goloviznin1983,
  title = {A Method of Constructing Computational Meshes in Domains with Curvilinear Boundaries},
  author = {Goloviznin, V.M. and Simacheva, O.G.},
  year = {1983},
  journal = {USSR Computational Mathematics and Mathematical Physics},
  volume = {23},
  number = {5},
  pages = {144--147},
  publisher = {Pergamon Press Ltd.},
  doi = {10.1016/s0041-5553(83)80173-6},
  file = {/home/wouter/Zotero/storage/FXKYK5BB/Goloviznin, Simacheva - 1983 - A method of constructing computational meshes in domains with curvilinear boundaries.pdf}
}

@book{golub2007,
  title = {Matrix Computations},
  author = {Golub, Gene H. and Van Loan, Charles F.},
  year = {2007},
  series = {Johns {{Hopkins}} Studies in the Mathematical Sciences},
  edition = {3. Aufl., [Nachdr.]},
  publisher = {Johns Hopkins Univ. Press},
  address = {Baltimore},
  isbn = {978-0-8018-5414-9 978-0-8018-5413-2},
  langid = {english}
}

@article{gong2021,
  title = {Domain Decomposition Preconditioners for High-Order Discretizations of the Heterogeneous {{Helmholtz}} Equation},
  author = {Gong, Shihua and Graham, Ivan G. and Spence, Euan A.},
  year = {2021},
  journal = {IMA Journal of Numerical Analysis},
  volume = {41},
  number = {3},
  pages = {2139--2185},
  doi = {10.1093/imanum/draa080},
  abstract = {We consider one-level additive Schwarz domain decomposition preconditioners for the Helmholtz equation with variable coefficients (modelling wave propagation in heterogeneous media), subject to boundary conditions that include wave scattering problems. Absorption is included as a parameter in the problem. This problem is discretized using H1-conforming nodal finite elements of fixed local degree p on meshes with diameter h = h(k), chosen so that the error remains bounded with increasing k. The action of the one-level preconditioner consists of the parallel solution of problems on subdomains (which can be of general geometry), each equipped with an impedance boundary condition. We prove rigorous estimates on the norm and field of values of the left- or right-preconditioned matrix that show explicitly how the absorption, the heterogeneity in the coefficients and the dependence on the degree enter the estimates. These estimates prove rigorously that, with enough absorption and for k large enough, GMRES is guaranteed to converge in a number of iterations that is independent of k, p and the coefficients. The theoretical threshold for k to be large enough depends on p and on the local variation of coefficients in subdomains (and not globally). Extensive numerical experiments are given for both the absorptive and the propagative cases; in the latter case, we investigate examples both when the coefficients are nontrapping and when they are trapping. These experiments support (i) our theory in terms of dependence on polynomial degree and the coefficients; and (ii) the sharpness of our field of values estimates in terms of the level of absorption required.},
  keywords = {Domain decomposition,Helmholtz equation,High frequency,High-order elements,Preconditioning,Variable coefficients},
  file = {/home/wouter/Zotero/storage/49RKYYU3/Gong, Graham, Spence - 2021 - Domain decomposition preconditioners for high-order discretizations of the heterogeneous Helmholtz equatio.pdf}
}

@article{gordon2012,
  title = {On Solving Stochastic Collocation Systems with Algebraic Multigrid},
  author = {Gordon, Andrew D. and Powell, Catherine E.},
  year = {2012},
  journal = {IMA Journal of Numerical Analysis},
  volume = {32},
  number = {3},
  pages = {1051--1070},
  doi = {10.1093/imanum/drr034},
  abstract = {Stochastic collocation methods facilitate the numerical solution of partial differential equations (PDEs) with random data and give rise to long sequences of similar linear systems. When elliptic PDEs with random diffusion coefficients are discretized with mixed finite element methods in the physical domain we obtain saddle point systems. These are trivial to solve when considered individually; the challenge lies in exploiting their similarities to recycle information and minimize the cost of solving the entire sequence. We apply stochastic collocation to a model stochastic elliptic problem and discretize in physical space using Raviart-Thomas elements. We propose an efficient solution strategy for the resulting linear systems that is more robust than any other in the literature. In particular, we show that it is feasible to use finely-tuned algebraic multigrid preconditioning if key set-up information is reused. The proposed solver is robust with respect to variations in the discretization and statistical parameters for stochastically linear and nonlinear data. {\copyright} 2010 The author. Published by Oxford University Press on behalf of the Institute of Mathematics and its Applications. All rights reserved.},
  keywords = {algebraic multigrid,mixed finite elements,preconditioning,sparse grids,stochastic collocation},
  file = {/home/wouter/Zotero/storage/3UG8XJP2/Gordon, Powell - 2012 - On solving stochastic collocation systems with algebraic multigrid.pdf}
}

@article{gorner2016,
  title = {On {{Newton}}'s {{Method}} for the {{Fermat}}--{{Weber Location Problem}}},
  author = {G{\"o}rner, Simone and Kanzow, Christian},
  year = {2016},
  journal = {Journal of Optimization Theory and Applications},
  volume = {170},
  number = {1},
  pages = {107--118},
  doi = {10.1007/s10957-016-0946-6},
  abstract = {This paper considers the Fermat--Weber location problem. It is shown that, after a suitable initialization, the standard Newton method can be applied to the Fermat--Weber problem, and is globally and locally quadratically convergent. A numerical comparison with the popular Weiszfeld algorithm shows that Newton's method is significantly more efficient than the Weiszfeld scheme.},
  keywords = {Fermat-Weber location problem,Global convergence,Local quadratic convergence,Newton method,Weiszfeld method},
  file = {/home/wouter/Zotero/storage/3XHI26P2/Görner, Kanzow - 2016 - On Newton’s Method for the Fermat–Weber Location Problem.pdf}
}

@article{graham2019,
  title = {The {{Helmholtz}} Equation in Heterogeneous Media: {{A}} Priori Bounds, Well-Posedness, and Resonances},
  author = {Graham, Ivan G. and Pembery, Owen R. and Spence, Euan A.},
  year = {2019},
  journal = {Journal of Differential Equations},
  volume = {266},
  number = {6},
  pages = {2869--2923},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jde.2018.08.048},
  abstract = {We consider the exterior Dirichlet problem for the heterogeneous Helmholtz equation, i.e. the equation ∇{$\cdot$}(A∇u)+k2nu=-f where both A and n are functions of position. We prove new a priori bounds on the solution under conditions on A, n, and the domain that ensure nontrapping of rays; the novelty is that these bounds are explicit in k, A, n, and geometric parameters of the domain. We then show that these a priori bounds hold when A and n are L{$\infty$} and satisfy certain monotonicity conditions, and thereby obtain new results both about the well-posedness of such problems and about the resonances of acoustic transmission problems (i.e. A and n discontinuous) where the transmission interfaces are only assumed to be C0 and star-shaped; the novelty of this latter result is that until recently the only known results about resonances of acoustic transmission problems were for C{$\infty$} convex interfaces with strictly positive curvature.},
  keywords = {Helmholtz equation,Heterogeneous,High frequency,Nontrapping,Resolvent,Resonance,Semiclassical,Transmission problem,Uniqueness,Variable wave speed},
  file = {/home/wouter/Zotero/storage/F8HHYRP8/Graham, Pembery, Spence - 2019 - The Helmholtz equation in heterogeneous media A priori bounds, well-posedness, and resonances(2).pdf;/home/wouter/Zotero/storage/P26AYLLX/Graham, Pembery, Spence - 2019 - The Helmholtz equation in heterogeneous media A priori bounds, well-posedness, and resonances.pdf}
}

@article{graham2020,
  title = {Domain {{Decomposition}} with {{Local Impedance Conditions}} for the {{Helmholtz Equation}} with {{Absorption}}},
  author = {Graham, Ivan G. and Spence, Euan A. and Zou, Jun},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {58},
  number = {5},
  pages = {2515--2543},
  doi = {10.1137/19M1272512},
  abstract = {We consider one-level additive Schwarz preconditioners for a family of Helmholtz problems with increasing wavenumber k. These problems are discretized using the Galerkin method with nodal conforming finite elements of any (fixed) order on meshes with diameter h = h(k), chosen to maintain accuracy as k increases. The action of the preconditioner requires the solution of independent (parallel) subproblems (with impedance boundary conditions) on overlapping subdomains of diameter H and overlap {$\delta$} {$\leq$} H. The solutions of these subproblems are linked together using prolongation/restriction operators defined using a partition of unity; this formulation was previously proposed in [J.-H. Kimn and M. Sarkis, Comput. Methods Appl. Mech. Engrg., 196 (2007), pp. 1507-1514]. In numerical experiments (with {$\delta$} {$\sim$} H) for a model interior impedance problem, we observe robust (i.e., k-independent) GMRES convergence as k increases, with H {$\sim$} k - {$\alpha$} and {$\alpha$}∊ [0, 0.4] as k increases. This provides a highly parallel, k-robust one-level domain decomposition method. We provide a supporting theory by studying the preconditioner applied to a range of absorptive problems, k2 {$\rightarrow$} k2 + i∊, with absorption parameter ∊. Working in the Helmholtz "energy" inner product, and using the underlying theory of Helmholtz boundary-value problems, we prove a k-independent upper bound on the norm of the preconditioned matrix, valid for all {\textbar} ∊ {\textbar} {$\lessequivlnt$} k2. We also prove a strictly positive lower bound on the distance of the field of values of the preconditioned matrix from the origin which holds when ∊ /k is constant or growing arbitrarily slowly with k. These results imply robustness of the preconditioner for the corresponding absorptive problem as k increases (given an appropriate choice of H). Since it is known that the absorptive problem provides a good preconditioner for the pure Helmholtz problem when ∊ {$\sim$} k, our results provide some theoretical support for the observed robustness of the preconditioner for the pure Helmholtz problem. Since the subdomains used in our preconditioner shrink only slowly (relative to the fine grid size) as k increases, cheaper approximate (two- or multilevel) versions of the preconditioner analyzed here are important in practice and are reviewed here.},
  keywords = {Domain decomposition,GMRES,Helmholtz equation,High frequency,Preconditioning,Robustness,Subproblems with impedance conditions},
  file = {/home/wouter/Zotero/storage/XFUXSYMF/Graham, Spence, Zou - 2020 - Domain Decomposition with Local Impedance Conditions for the Helmholtz Equation with Absorption.pdf}
}

@article{graham2021,
  title = {Analysis of a {{Helmholtz}} Preconditioning Problem Motivated by Uncertainty Quantification},
  author = {Graham, Ivan G. and Pembery, Owen R. and Spence, Euan A.},
  year = {2021},
  journal = {Advances in Computational Mathematics},
  volume = {47},
  number = {5},
  pages = {1--39},
  publisher = {Advances in Computational Mathematics},
  doi = {10.1007/s10444-021-09889-0},
  abstract = {This paper analyses the following question: let Aj, j = 1,2, be the Galerkin matrices corresponding to finite-element discretisations of the exterior Dirichlet problem for the heterogeneous Helmholtz equations ∇{$\cdot$} (Aj∇uj) + k2njuj = -f. How small must {$\parallel$}A1-A2{$\parallel$}Lq and {$\parallel$}n1-n2{$\parallel$}Lq be (in terms of k-dependence) for GMRES applied to either (A1)-1A2 or A2(A1)- 1 to converge in a k-independent number of iterations for arbitrarily large k? (In other words, for A1 to be a good left or right preconditioner for A2?) We prove results answering this question, give theoretical evidence for their sharpness, and give numerical experiments supporting the estimates. Our motivation for tackling this question comes from calculating quantities of interest for the Helmholtz equation with random coefficients A and n. Such a calculation may require the solution of many deterministic Helmholtz problems, each with different A and n, and the answer to the question above dictates to what extent a previously calculated inverse of one of the Galerkin matrices can be used as a preconditioner for other Galerkin matrices.},
  keywords = {Helmholtz equation,Heterogeneous,High frequency,Preconditioning,Uncertainty quantification,Variable wave speed},
  file = {/home/wouter/Zotero/storage/H4YYKED8/Graham, Pembery, Spence - 2021 - Analysis of a Helmholtz preconditioning problem motivated by uncertainty quantification.pdf}
}

@book{griffiths2018,
  title = {Introduction to {{Quantum Mechanics}}},
  author = {Griffiths, David J. and Schroeter, Darrell F.},
  year = {2018},
  month = aug,
  edition = {3},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781316995433},
  urldate = {2025-05-01},
  abstract = {Changes and additions to the new edition of this classic textbook include a new chapter on symmetries, new problems and examples, improved explanations, more numerical problems to be worked on a computer, new applications to solid state physics, and consolidated treatment of time-dependent potentials.},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-316-99543-3 978-1-107-18963-8}
}

@article{grim-mcnally2016,
  title = {Preconditioning {{Parametrized Linear Systems}}},
  author = {{Grim-McNally}, Arielle and {de Sturler}, Eric and Gugercin, Serkan},
  year = {2016},
  abstract = {Preconditioners are generally essential for fast convergence in the iterative solution of linear systems of equations. However, the computation of a good preconditioner can be expensive. So, while solving a sequence of many linear systems, it is advantageous to recycle preconditioners, that is, update a previous preconditioner and reuse the updated version. In this paper, we introduce a simple and effective method for doing this. Although our approach can be used for matrices changing slowly in any way, we focus on the important case of sequences of the type \$(s\_k{\textbackslash}textbf\{E\}({\textbackslash}textbf\{p\}) + {\textbackslash}textbf\{A\}({\textbackslash}textbf\{p\})){\textbackslash}textbf\{x\}\_k = {\textbackslash}textbf\{b\}\_k\$, where the right hand side may or may not change. More general changes in matrices will be discussed in a future paper. We update preconditioners by defining a map from a new matrix to a previous matrix, for example the first matrix in the sequence, and combine the preconditioner for this previous matrix with the map to define the new preconditioner. This approach has several advantages. The update is entirely independent from the original preconditioner, so it can be applied to any preconditioner. The possibly high cost of an initial preconditioner can be amortized over many linear solves. The cost of updating the preconditioner is more or less constant and independent of the original preconditioner. There is flexibility in balancing the quality of the map with the computational cost. In the numerical experiments section we demonstrate good results for several applications, in particular when using an algebraic multigrid preconditioner.},
  keywords = {65f10,ams subject classifications,approximate inverse,diffuse optical tomography,irka,krylov subspace methods,model reduction,parametrized systems,preconditioning,raphy,recycling preconditioners,sparse,topology optimization,transient hydraulic tomog-},
  file = {/home/wouter/Zotero/storage/34MKIWPF/Grim-McNally, de Sturler, Gugercin - 2016 - Preconditioning Parametrized Linear Systems.pdf}
}

@article{grippo1986,
  title = {A {{Nonmonotone Line Search Technique}} for {{Newton}}'s {{Method}}},
  author = {Grippo, L. and Lampariello, F. and Lucidi, S.},
  year = {1986},
  month = aug,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {23},
  number = {4},
  pages = {707--716},
  doi = {10.1137/0723046},
  keywords = {line search,newton,nonlinear programming,s method,unconstrained minimization},
  file = {/home/wouter/Zotero/storage/CG6JK7GJ/Grippo, Lampariello, Lucidi - 1986 - A Nonmonotone Line Search Technique for Newton’s Method.pdf}
}

@book{grisvard1985,
  title = {Elliptic {{Problems}} in {{Nonsmooth Domains}}},
  author = {Grisvard, Pierre},
  year = {1985},
  journal = {Elliptic Problems in Nonsmooth Domains},
  pages = {422},
  publisher = {Pitman Advanced Publishing Program},
  doi = {10.1137/1.9781611972030},
  abstract = {This classic text focuses on elliptic boundary value problems in domains with nonsmooth boundaries and on problems with mixed boundary conditions. Its contents are essential for an understanding of the behavior of numerical methods for partial differential equations (PDEs) on two-dimensional domains with corners. Elliptic Problems in Nonsmooth Domains provides a careful and self-contained development of Sobolev spaces on nonsmooth domains, develops a comprehensive theory for second-order elliptic boundary value problems and addresses fourth-order boundary value problems and numerical treatment of singularities. This book is intended for researchers and graduate students in computational science and numerical analysis who work with theoretical and numerical PDEs. Readers need only a background in functional analysis to find the material accessible.},
  isbn = {0-273-08647-2},
  file = {/home/wouter/Zotero/storage/MQL6LQ5U/Grisvard - 1985 - Elliptic Problems in Nonsmooth Domains.djvu}
}

@article{grossi2014,
  title = {On the Location of Two Blowup Points on an Annulus for the Mean Field Equation},
  author = {Grossi, Massimo and Takahashi, Futoshi},
  year = {2014},
  journal = {Comptes Rendus Mathematique},
  volume = {352},
  number = {7-8},
  pages = {615--619},
  publisher = {Elsevier Masson SAS},
  doi = {10.1016/j.crma.2014.04.006},
  abstract = {We consider the mean field equation on two-dimensional annular domains, and prove that if P1 and P2 are two blowup points of a blowing-up solution sequence of the equation, then we must have P1=-P2. {\copyright} 2014 Acad{\'e}mie des sciences.},
  file = {/home/wouter/Zotero/storage/FW8IHZYE/Grossi, Takahashi - 2014 - On the location of two blowup points on an annulus for the mean field equation.pdf}
}

@article{grossmann1984,
  title = {Decomposition of {{Hardy Functions}} into {{Square Integrable Wavelets}} of {{Constant Shape}}},
  author = {Grossmann, Alex and Morlet, Jean},
  year = {1984},
  month = jul,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {15},
  number = {4},
  pages = {723--736},
  publisher = {Princeton University Press},
  issn = {9781400827268},
  doi = {10.1137/0515056},
  abstract = {An arbitrary square integrable real-valued function (or, equivalently, the associated Hardy function) can be conveniently analyzed into a suitable family of square integrable wavelets of constant shape. (i.e. obtained by shifts and dilations from anyone of them.) The resulting integral transform is isometric and self-reciprocal if the wavelets satisfy an "admissibility condition" given here. Explicit expressions are obtained in the case of a particular analyzing family that plays a role analogous to that of coherent states (Gabor wavelets) in the usual L2-theory. They are written in terms of a modified r-function that is introduced and studied. From the point of view of group theory, this paper is concerned with square integrable coefficients of an irreducible representation of the nonunimodular ax + b-group.},
  file = {/home/wouter/Zotero/storage/GSIKIYZE/Grossmann, Morlet - 1984 - Decomposition of Hardy Functions into Square Integrable Wavelets of Constant Shape.pdf}
}

@article{gu2023,
  title = {A {{Fictitious Domain Spectral Method}} for {{Solving}} the {{Helmholtz Equation}} in {{Exterior Domains}}},
  author = {Gu, Yiqi and Shen, Jie},
  year = {2023},
  journal = {Journal of Scientific Computing},
  volume = {94},
  number = {3},
  pages = {1--27},
  publisher = {Springer US},
  issn = {1091502302098},
  doi = {10.1007/s10915-023-02098-5},
  abstract = {We extend the fictitious domain spectral method presented in Gu and Shen (SIAM J Sci Comput 43:A309--A329, 2021) for elliptic PDEs in bounded domains to the Helmhotlz equation in exterior domains. We first reduce the problem in an exterior domain to a bounded domain using the exact Dirichlet-to-Neumann operator. Next, we formulate the reduced problem into an equivalent problem in an annulus by using a fictitious domain approach. Then, we apply the Fourier-spectral method in the radial direction to reduce the problem in an annulus to a sequence of 1-D Bessel-type equations, each with a one-sided open boundary condition that are to be determined by the boundary condition of the original Helmholtz equation. We solve these 1-D Bessel-type equations by the Legendre-spectral method, and determine the open boundary conditions with a least square approach. We derive a wave number explicit error estimate for the special case of a circular obstacle, and provide ample numerical results to show the effectiveness of the proposed method.},
  keywords = {Acoustic scattering,Error estimate,Fictitious domain,Helmholtz equation,Petrov-Galerkin method},
  file = {/home/wouter/Zotero/storage/MLL4D9LL/Gu, Shen - 2023 - A Fictitious Domain Spectral Method for Solving the Helmholtz Equation in Exterior Domains.pdf}
}

@article{guillen2019,
  title = {Min--Max Formulas for Nonlocal Elliptic Operators},
  author = {Guillen, Nestor and Schwab, Russell W.},
  year = {2019},
  journal = {Calculus of Variations and Partial Differential Equations},
  volume = {58},
  number = {6},
  doi = {10.1007/s00526-019-1631-z},
  abstract = {In this work, we give a characterization of Lipschitz operators on spaces of C2(M) functions (also C1 , 1, C1,{$\gamma$}, C1, C{$\gamma$}) that obey the global comparison property---i.e. those that preserve the global ordering of input functions at any points where their graphs may touch, often called ``elliptic'' operators. Here M is a complete Riemannian manifold. In particular, we show that all such operators can be written as a min--max over linear operators that are a combination of drift--diffusion and integro-differential parts. In the linear (and nonlocal) case, these operators had been characterized in the 1960s, and in the local, but nonlinear case---e.g. local Hamilton--Jacobi--Bellman operators---this characterization has also been known and used since approximately since 1960s or 1970s. Our main theorem contains both of these results as special cases. It also shows any nonlinear scalar elliptic equation can be represented as an Isaacs equation for an appropriate differential game. Our approach is to ``project'' the operator to one acting on functions on large finite graphs that approximate the manifold, use non-smooth analysis to derive a min--max formula on this finite dimensional level, and then pass to the limit in order to lift the formula to the original operator.},
  keywords = {and phrases,global comparison principle,integro-differential operators,isaacs equation,whitney},
  file = {/home/wouter/Zotero/storage/YIE2MWGN/Guillen, Schwab - 2019 - Min–max formulas for nonlocal elliptic operators.pdf}
}

@article{guillen2020,
  title = {Estimates for {{Dirichlet-to-Neumann Maps}} as {{Integro-differential Operators}}},
  author = {Guillen, Nestor and Kitagawa, Jun and Schwab, Russell W.},
  year = {2020},
  journal = {Potential Analysis},
  volume = {53},
  number = {2},
  pages = {483--521},
  publisher = {Potential Analysis},
  doi = {10.1007/s11118-019-09776-w},
  abstract = {Some linear integro-differential operators have old and classical representations as the Dirichlet-to-Neumann operators for linear elliptic equations, such as the 1/2-Laplacian or the generator of the boundary process of a reflected diffusion. In this work, we make some extensions of this theory to the case of a nonlinear Dirichlet-to-Neumann mapping that is constructed using a solution to a fully nonlinear elliptic equation in a given domain, mapping Dirichlet data to its normal derivative of the resulting solution. Here we begin the process of giving detailed information about the L{\'e}vy measures that will result from the integro-differential representation of the Dirichlet-to-Neumann mapping. We provide new results about both linear and nonlinear Dirichlet-to-Neumann mappings. Information about the L{\'e}vy measures is important if one hopes to use recent advancements of the integro-differential theory to study problems involving Dirichlet-to-Neumann mappings.},
  keywords = {Boundary operators,Boundary process,Dirichlet-to-Neumann,Elliptic equation,Fully nonlinear,Integro-differential,Levy measures,Nonlocal},
  file = {/home/wouter/Zotero/storage/3HKJVRIJ/Guillen, Kitagawa, Schwab - 2020 - Estimates for Dirichlet-to-Neumann Maps as Integro-differential Operators.pdf}
}

@article{gupta2008,
  title = {Advanced {{Approximation Algorithms}} ({{CMU}} 18-{{854B}}, {{Spring}} 2008) {{Lecture}} 4: {{Uncapacitated Facility Location Jan}} 24, 2008},
  author = {Gupta, Anupam},
  year = {2008},
  journal = {Communications in Computer and Information Science},
  volume = {15},
  pages = {76--83},
  issn = {9783540859291},
  doi = {10.1007/978-3-540-85930-7_11},
  abstract = {In this lecture, as well as the next two lectures, we will study the uncapacitated facility location problem, using it as a vehicle to illustrate several different techniques that are commonly used to devise approximation algorithms for NP-hard problems.},
  keywords = {Approximation algorithm,Complexity,Facility location,K-level},
  file = {/home/wouter/Zotero/storage/BLGIK66U/Gupta - 2008 - Advanced Approximation Algorithms (CMU 18-854B, Spring 2008) Lecture 4 Uncapacitated Facility Location Jan 24, 2008.pdf}
}

@article{gupta2019,
  title = {Maximum {{Vanishing Moment}} of {{Compactly Supported B-spline Wavelets}}},
  author = {Gupta, Kanchan Lata and Kunwar, B. and Singh, V. K.},
  year = {2019},
  journal = {Asian Journal of Probability and Statistics},
  volume = {3},
  number = {3},
  pages = {1--8},
  doi = {10.9734/ajpas/2019/v3i330095},
  abstract = {Spline function is of very great interest in field of wavelets due to its compactness and smoothness property. As splines have specific formulae in both time and frequency domain, it greatly facilitates their manipulation. We have given a simple procedure to generate compactly supported orthogonal scaling function for higher order B-splines in our previous work. Here we determine the maximum vanishing moments of the formed spline wavelet as established by the new refinable function using sum rule order method.},
  keywords = {b-splines,multiresolution analysis,sum rule order,vanishing moments},
  file = {/home/wouter/Zotero/storage/HW4M6LQC/Gupta, Kunwar, Singh - 2019 - Maximum Vanishing Moment of Compactly Supported B-spline Wavelets.pdf}
}

@article{haasdonk2014,
  title = {Reduced {{Basis Methods}} for {{Parametrized PDEs-A Tutorial Introduction}} for {{Stationary}} and {{Instationary Problems}}},
  author = {Haasdonk, B and Haasdonk, Bernard},
  year = {2014},
  number = {2014},
  abstract = {In this part we are concerned with a class of model reduction techniques for paramet-ric partial differential equations, the so-called Reduced Basis (RB) methods. These allow to obtain low-dimensional parametric models for various complex applications, enabling accurate and rapid numerical simulations. Important aspects are basis generation and certification of the simulation results by suitable a posteriori error control. The main terminology, ideas and assumptions will be explained for the case of linear stationary elliptic, as well as parabolic or hyperbolic instationary problems. Re-producable experiments will illustrate the theoretical findings. We close with a discussion of further recent developments. Abstract In this part we are concerned with a class of model reduction techniques for parametric partial differential equations, the so-called Reduced Basis (RB) methods. These allow to obtain low-dimensional parametric models for various complex applications, enabling accurate and rapid numerical simulations. Important aspects are basis generation and certification of the simulation results by suitable a posteriori error control. The main terminology, ideas and assumptions will be explained for the case of linear stationary elliptic, as well as parabolic or hyperbolic instationary problems. Reproducible experiments will illustrate the theoretical findings. We close with a discussion of further recent developments.},
  keywords = {Parametrized Partial Differential Equations,Reduced Basis Methods},
  file = {/home/wouter/Zotero/storage/Y4B9YL5Z/Haasdonk, Haasdonk - 2014 - Reduced Basis Methods for Parametrized PDEs-A Tutorial Introduction for Stationary and Instationary Problems.pdf}
}

@book{hahn1996,
  title = {Hilbert Transforms in Signal Processing},
  author = {Hahn, Stefan L.},
  year = {1996},
  journal = {undefined},
  pages = {442},
  publisher = {Artech House},
  abstract = {Ch. 1. Theory of the One-Dimensional Hilbert Transformation -- Ch. 2. Properties of the Hilbert Transformation Derivations and Applications -- Ch. 3. Distributions in the Theory of the Hilbert Transformation and Complex Signals -- Ch. 4. The Discrete Hilbert Transformation -- Ch. 5. Hilbert Transformers -- Ch. 6. The Hilbert Transform In Modulation Theory -- Ch. 7. The Hilbert Transform in Signal and System Theory -- Ch. 8. Multidimensional Complex Signals and Applications -- Ch. 9. Multidimensional Hilbert and Fourier Transformations -- App. A. Tabulation of Hilbert Pairs -- App. B. The Derivation of the Derivative of the Logarithmic and [theta](t) Distributions -- App. C. Supplement to Chapter 4 -- App. D. Details of the Calculation of the Phase Function of IIR Hilbert Transformers -- App. E. Derivation of the Spectrum of the CSSB Signal for Linear Amplitude -- App. F. Derivation of the Fourier Spectrum of the N-Dimensional Hilbert Transform.},
  isbn = {978-0-89006-886-1},
  file = {/home/wouter/Zotero/storage/ZV5B9G6G/Hahn - 1996 - Hilbert transforms in signal processing.djvu}
}

@article{halton1970,
  title = {A Retrospective and Prospective Survey of the {{Monte Carlo}} Method},
  author = {Halton, John H},
  year = {1970},
  journal = {Siam review},
  volume = {12},
  number = {1},
  pages = {1--63},
  publisher = {SIAM}
}

@article{han2017,
  title = {Weighted {{Gradient-Enhanced Kriging}} for {{High-Dimensional Surrogate Modeling}} and {{Design Optimization}}},
  author = {Han, Zhong-Hua and Zhang, Yu and Song, Chen-Xing and Zhang, Ke-Shi},
  year = {2017},
  month = dec,
  journal = {AIAA Journal},
  volume = {55},
  number = {12},
  pages = {4330--4346},
  issn = {0001-1452, 1533-385X},
  doi = {10.2514/1.J055842},
  urldate = {2024-09-24},
  langid = {english},
  file = {/home/wouter/Zotero/storage/E6X3U678/Han et al. - 2017 - Weighted Gradient-Enhanced Kriging for High-Dimensional Surrogate Modeling and Design Optimization.pdf}
}

@article{harbrecht2008,
  title = {Sparse Second Moment Analysis for Elliptic Problems in Stochastic Domains},
  author = {Harbrecht, Helmut and Schneider, Reinhold and Schwab, Christoph},
  year = {2008},
  month = may,
  journal = {Numerische Mathematik},
  volume = {109},
  number = {3},
  pages = {385--414},
  doi = {10.1007/s00211-008-0147-9},
  abstract = {We consider the numerical solution of elliptic boundary value problems in domains with random boundary perturbations. Assuming normal perturbations with small amplitude and known mean field and two-point correlation function, we derive, using a second order shape calculus, deterministic equations for the mean field and the two-point correlation function of the random solution for a model Dirichlet problem which are 3rd order accurate in the boundary perturbation size. Using a variational boundary integral equation formulation on the unperturbed, "nominal" boundary and a wavelet discretization, we present and analyze an algorithm to approximate the random solution's mean and its two-point correlation function at essentially optimal order in essentially O(N)work and memory, where N denotes the number of unknowns required for consistent discretization of the boundary of the nominal domain. {\copyright} 2008 Springer-Verlag.},
  file = {/home/wouter/Zotero/storage/S4YG3ZCP/Harbrecht, Schneider, Schwab - 2008 - Sparse second moment analysis for elliptic problems in stochastic domains.pdf}
}

@article{harbrecht2013,
  title = {First Order Second Moment Analysis for Stochastic Interface Problems Based on Low-Rank Approximation},
  author = {Harbrecht, Helmut and Li, Jingzhi},
  year = {2013},
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  volume = {47},
  number = {5},
  pages = {1533--1552},
  publisher = {EDP Sciences}
}

@article{harbrecht2016,
  title = {Analysis of the Domain Mapping Method for Elliptic Diffusion Problems on Random Domains},
  author = {Harbrecht, Helmut and Peters, Michael and Siebenmorgen, Markus},
  year = {2016},
  month = dec,
  journal = {Numerische Mathematik},
  volume = {134},
  number = {4},
  pages = {823--856},
  publisher = {Springer Berlin Heidelberg},
  doi = {10.1007/s00211-016-0791-4},
  abstract = {In this article, we provide a rigorous analysis of the solution to elliptic diffusion problems on random domains. In particular, based on the decay of the Karhunen-Lo{\`e}ve expansion of the domain perturbation field, we establish decay rates for the derivatives of the random solution that are independent of the stochastic dimension. For the implementation of a related approximation scheme, like quasi-Monte Carlo quadrature, stochastic collocation, etc., we propose parametric finite elements to compute the solution of the diffusion problem on each individual realization of the domain generated by the perturbation field. This simplifies the implementation and yields a non-intrusive approach. Having this machinery at hand, we can easily transfer it to stochastic interface problems. The theoretical findings are complemented by numerical examples for both, stochastic interface problems and boundary value problems on random domains.},
  keywords = {35R60,60H35,65C30},
  file = {/home/wouter/Zotero/storage/HTB7I7DX/Harbrecht, Peters, Siebenmorgen - 2016 - Analysis of the domain mapping method for elliptic diffusion problems on random domains.pdf}
}

@article{hartmann2016,
  title = {A {{Sparse Grid Discretization}} with {{Variable Coefficient}} in {{High Dimensions}}},
  author = {Hartmann, Rainer and Pflaum, Christoph},
  year = {2016},
  month = mar,
  pages = {1--24},
  abstract = {We present a Ritz-Galerkin discretization on sparse grids using pre-wavelets, which allows to solve elliptic differential equations with variable coefficients for dimension \$d=2,3\$ and higher dimensions \$d{$>$}3\$. The method applies multilinear finite elements. We introduce an efficient algorithm for matrix vector multiplication using a Ritz-Galerkin discretization and semi-orthogonality. This algorithm is based on standard 1-dimensional restrictions and prolongations, a simple pre-wavelet stencil, and the classical operator dependent stencil for multilinear finite elements. Numerical simulation results are presented for a 3-dimensional problem on a curvilinear bounded domain and for a 6-dimensional problem with variable coefficients. Simulation results show a convergence of the discretization according to the approximation properties of the finite element space. The condition number of the stiffness matrix can be bounded below \$10\$ using a standard diagonal preconditioner.},
  file = {/home/wouter/Zotero/storage/KVICTMT8/Hartmann, Pflaum - 2016 - A Sparse Grid Discretization with Variable Coefficient in High Dimensions.pdf}
}

@article{haubner2020,
  title = {A Continuous Perspective on Modeling of Shape Optimal Design Problems},
  author = {Haubner, Johannes and Siebenborn, Martin and Ulbrich, Michael},
  year = {2020},
  journal = {SIAM Journal on Scientific Computing},
  pages = {1--20},
  doi = {10.1137/20m1332050},
  abstract = {In this article we consider shape optimization problems as optimal control problems via the method of mappings. Instead of optimizing over a set of admissible shapes a reference domain is introduced and it is optimized over a set of admissible transformations. The focus is on the choice of the set of transformations, which we motivate from a function space perspective. In order to guarantee local injectivity of the admissible transformations we enrich the optimization problem by a nonlinear constraint. The approach requires no parameter tuning for the extension equation and can naturally be combined with geometric constraints on volume and barycenter of the shape. Numerical results for drag minimization of Stokes flow are presented.},
  keywords = {35r30,49k20,49q10,65k10,ams subject classifications,method of mappings,shape optimization,stokes flow},
  file = {/home/wouter/Zotero/storage/AWN7P8A8/Haubner, Siebenborn, Ulbrich - 2020 - A continuous perspective on modeling of shape optimal design problems.pdf}
}

@article{haubner2021,
  title = {A {{Continuous Perspective}} on {{Shape Optimization}} via {{Domain Transformations}}},
  author = {Haubner, Johannes and Siebenborn, Martin and Ulbrich, Michael},
  year = {2021},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {43},
  number = {3},
  pages = {A1997-A2018},
  publisher = {Springer US},
  doi = {10.1137/20M1332050},
  abstract = {In this article, we propose a shape optimization algorithm which is able to handle large deformations while maintaining a high level of mesh quality. Based on the method of mappings, we introduce a nonlinear extension operator, which links a boundary control to domain deformations, ensuring admissibility of resulting shapes. The major focus is on comparisons between well-established approaches involving linear-elliptic operators for the extension and the effect of additional nonlinear advection on the set of reachable shapes. It is moreover discussed how the computational complexity of the proposed algorithm can be reduced. The benefit of the nonlinearity in the extension operator is substantiated by several numerical test cases of stationary, incompressible Navier--Stokes flows in 2d and 3d.},
  keywords = {Aerodynamic shape optimization,Method of mappings,Nonlinear extensions},
  file = {/home/wouter/Zotero/storage/YTBSKL6W/Haubner, Siebenborn, Ulbrich - 2021 - A Continuous Perspective on Shape Optimization via Domain Transformations.pdf}
}

@book{heil2009,
  title = {Fundamental {{Papers}} in {{Wavelet Theory}}},
  author = {Heil, Christopher and Walnut, David F.},
  year = {2009},
  month = dec,
  pages = {878},
  publisher = {Princeton University Press},
  doi = {10.1515/9781400827268},
  abstract = {This book traces the prehistory and initial development of wavelet theory, a discipline that has had a profound impact on mathematics, physics, and engineering. Interchanges between these fields during the last fifteen years have led to a number of advances in applications such as image compression, turbulence, machine vision, radar, and earthquake prediction. This book contains the seminal papers that presented the ideas from which wavelet theory evolved, as well as those major papers that developed the theory into its current form. These papers originated in a variety of journals from different disciplines, making it difficult for the researcher to obtain a complete view of wavelet theory and its origins. Additionally, some of the most significant papers have heretofore been available only in French or German. Heil and Walnut bring together these documents in a book that allows researchers a complete view of wavelet theory's origins and development.},
  isbn = {978-1-4008-2726-8},
  file = {/home/wouter/Zotero/storage/HHTBAR7P/Heil, Walnut - 2009 - Fundamental Papers in Wavelet Theory.pdf}
}

@article{helin2023,
  title = {Introduction {{To Gaussian Process Regression In Bayesian Inverse Problems}}, {{With New Results On Experimental Design For Weighted Error Measures}}},
  author = {Helin, Tapio and Stuart, Andrew and Teckentrup, Aretha and Zygalakis, Konstantinos},
  year = {2023},
  abstract = {Bayesian posterior distributions arising in modern applications, including inverse problems in partial differential equation models in tomography and subsurface flow, are often computationally intractable due to the large computational cost of evaluating the data likelihood. To alleviate this problem, we consider using Gaussian process regression to build a surrogate model for the likelihood, resulting in an approximate posterior distribution that is amenable to computations in practice. This work serves as an introduction to Gaussian process regression, in particular in the context of building surrogate models for inverse problems, and presents new insights into a suitable choice of training points. We show that the error between the true and approximate posterior distribution can be bounded by the error between the true and approximate likelihood, measured in the \$L{\textasciicircum}2\$-norm weighted by the true posterior, and that efficiently bounding the error between the true and approximate likelihood in this norm suggests choosing the training points in the Gaussian process surrogate model based on the true posterior.},
  file = {/home/wouter/Zotero/storage/H9C7UI7M/Helin et al. - 2023 - Introduction To Gaussian Process Regression In Bayesian Inverse Problems, With New Results On Experimental Design.pdf}
}

@article{henriquez2021,
  title = {Shape {{Holomorphy}} of the {{Calder{\'o}n Projector}} for the {{Laplacian}} in \$\{{\textbackslash}mathbb \{\vphantom{\}\}}{{R}}\vphantom\{\}\vphantom\{\}{\textasciicircum}2\$},
  author = {Henr{\'i}quez, Fernando and Schwab, Christoph},
  year = {2021},
  month = aug,
  journal = {Integral Equations and Operator Theory},
  volume = {93},
  number = {4},
  pages = {43--43},
  doi = {10.1007/s00020-021-02653-5},
  abstract = {We establish the holomorphic dependence of the boundary integral operators (BIOs) comprising the Calder{\'o}n projector for the Laplacian in two dimensions on the boundary shape. More precisely, we show that the Calder{\'o}n projector, as an element of the Banach space of bounded linear operators satisfying suitable mapping properties, depends holomorphically on a set of boundaries given by a collection of C2--regular Jordan curves in R2. In turn, this result implies that the solution of a well-posed first or second kind boundary integral equation (BIE) arising from the boundary reduction of the Laplace problem set on a domain of class C2 in two spatial dimensions depends holomorphically on the shape of the boundary, provided that the corresponding right-hand side does so as well. This property of shape holomorphy is of crucial significance to mathematically justify the construction of sparse parametric shape surrogates of polynomial chaos type, and to prove dimension-independent convergence rates for the approximation of parametric solution families of BIEs in forward and inverse computational shape uncertainty quantification.},
  keywords = {Boundary integral equations,Boundary integral operators,Shape holomorphy,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/4XG8QW6Y/Henríquez, Schwab - 2021 - Shape Holomorphy of the Calderón Projector for the Laplacian in $ mathbb R 2$.pdf}
}

@article{herrmann2022,
  title = {Constructive {{Deep ReLU Neural Network Approximation}}},
  author = {Herrmann, Lukas and Opschoor, Joost A.A. and Schwab, Christoph},
  year = {2022},
  journal = {Journal of Scientific Computing},
  volume = {90},
  number = {2},
  pages = {1--37},
  publisher = {Springer US},
  doi = {10.1007/s10915-021-01718-2},
  abstract = {We propose an efficient, deterministic algorithm for constructing exponentially convergent deep neural network (DNN) approximations of multivariate, analytic maps f: [- 1 , 1] K{$\rightarrow$} R. We address in particular networks with the rectified linear unit (ReLU) activation function. Similar results and proofs apply for many other popular activation functions. The algorithm is based on collocating f in deterministic families of grid points with small Lebesgue constants, and by a-priori (i.e., ``offline'') emulation of a spectral basis with DNNs to prescribed fidelity. Assuming availability of N function values of a possibly corrupted, numerical approximation f{\textasciibreve} of f in [- 1 , 1] K and a bound on {\textbardbl}f-f{\textasciibreve}{\textbardbl}L{$\infty$}([-1,1]K), we provide an explicit, computational construction of a ReLU DNN which attains accuracy {$\varepsilon$} (depending on N and {\textbardbl}f-f{\textasciibreve}{\textbardbl}L{$\infty$}([-1,1]K)) uniformly, with respect to the inputs. For analytic maps f: [- 1 , 1] K{$\rightarrow$} R, we prove exponential convergence of expression and generalization errors of the constructed ReLU DNNs. Specifically, for every target accuracy {$\varepsilon\in$} (0 , 1) , there exists N depending also on f such that the error of the construction algorithm with N evaluations of f{\textasciibreve} as input in the norm L{$\infty$}([- 1 , 1] K; R) is smaller than {$\varepsilon$} up to an additive data-corruption bound {\textbardbl}f-f{\textasciibreve}{\textbardbl}L{$\infty$}([-1,1]K) multiplied with a factor growing slowly with 1 / {$\varepsilon$} and the number of non-zero DNN weights grows polylogarithmically with respect to 1 / {$\varepsilon$}. The algorithmic construction of the ReLU DNNs which will realize the approximations, is explicit and deterministic in terms of the function values of f{\textasciibreve} in tensorized Clenshaw--Curtis grids in [- 1 , 1] K. We illustrate the proposed methodology by a constructive algorithm for (offline) computations of posterior expectations in Bayesian PDE inversion.},
  keywords = {Deep ReLU neural networks,Exponential convergence,Generalization error,Neural network construction},
  file = {/home/wouter/Zotero/storage/82NP6ZQ7/Herrmann, Opschoor, Schwab - 2022 - Constructive Deep ReLU Neural Network Approximation.pdf}
}

@article{hicks1978,
  title = {Wing {{Design}} by {{Numerical Optimization}}},
  author = {Hicks, Raymond M. and Henne, Preston A.},
  year = {1978},
  journal = {Journal of Aircraft},
  volume = {15},
  pages = {407--412}
}

@article{hiptmair2015,
  title = {Shape {{Optimization}} by {{Pursuing Diffeomorphisms}}},
  author = {Hiptmair, Ralf and Paganini, Alberto},
  year = {2015},
  month = jul,
  journal = {Computational Methods in Applied Mathematics},
  volume = {15},
  number = {3},
  pages = {291--305},
  doi = {10.1515/cmam-2015-0013},
  abstract = {We consider PDE constrained shape optimization in the framework of finite element discretization of the underlying boundary value problem. We present an algorithm tailored to preserve and exploit the approximation properties of the finite element method, and that allows for arbitrarily high resolution of shapes. It employs (i) B-spline based representations of the deformation diffeomorphism, and (ii) superconvergent domain integral expressions for the shape gradient. We provide numerical evidence of the performance of this method both on prototypical well-posed and ill-posed shape optimization problems.},
  keywords = {finite element method,pde constraint,shape optimization},
  file = {/home/wouter/Zotero/storage/EN7PIHFX/Hiptmair, Paganini - 2015 - Shape Optimization by Pursuing Diffeomorphisms.pdf}
}

@article{hiptmair2018,
  title = {Large Deformation Shape Uncertainty Quantification in Acoustic Scattering},
  author = {Hiptmair, Ralf and Scarabosio, Laura and Schillings, Claudia and Schwab, Christoph},
  year = {2018},
  journal = {Advances in Computational Mathematics},
  volume = {44},
  number = {5},
  pages = {1475--1518},
  doi = {10.1007/s10444-018-9594-8},
  abstract = {We address shape uncertainty quantification for the two-dimensional Helmholtz transmission problem, where the shape of the scatterer is the only source of uncertainty. In the framework of the so-called deterministic approach, we provide a high-dimensional parametrization for the interface. Each domain configuration is mapped to a nominal configuration, obtaining a problem on a fixed domain with stochastic coefficients. To compute surrogate models and statistics of quantities of interest, we apply an adaptive, anisotropic Smolyak algorithm, which allows to attain high convergence rates that are independent of the number of dimensions activated in the parameter space. We also develop a regularity theory with respect to the spatial variable, with norm bounds that are independent of the parametric dimension. The techniques and theory presented in this paper can be easily generalized to any elliptic problem on a stochastic domain.},
  keywords = {Dimension-adaptive Smolyak quadrature,Helmholtz equation,High-dimensional approximation,Random interface,Stochastic parametrization,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/9A7Q5W2F/Hiptmair et al. - 2018 - Large deformation shape uncertainty quantification in acoustic scattering(2).pdf}
}

@misc{hiptmair2024,
  title = {Frequency-{{Explicit Shape Holomorphy}} in {{Uncertainty Quantification}} for {{Acoustic Scattering}}},
  author = {Hiptmair, Ralf and Schwab, Christoph and Spence, Euan A.},
  year = {2024},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2408.01194},
  urldate = {2025-03-06},
  abstract = {We consider frequency-domain acoustic scattering at a homogeneous star-shaped penetrable obstacle, whose shape is uncertain and modelled via a radial spectral parameterization with random coefficients. Using recent results on the stability of Helmholtz transmission problems with piecewise constant coefficients from [A. Moiola and E. A. Spence, Acoustic transmission problems: wavenumber-explicit bounds and resonance-free regions, Mathematical Models and Methods in Applied Sciences, 29 (2019), pp. 317-354] we obtain frequency-explicit statements on the holomorphic dependence of the scattered field and the far-field pattern on the stochastic shape parameters. This paves the way for applying general results on the efficient construction of high-dimensional surrogate models. We also take into account the effect of domain truncation by means of perfectly matched layers (PML). In addition, spatial regularity estimates which are explicit in terms of the wavenumber \$k\$ permit us to quantify the impact of finite-element Galerkin discretization using high-order Lagrangian finite-element spaces.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Mathematics,Numerical Analysis (math.NA)}
}

@article{hoang2014,
  title = {N-Term {{Wiener}} Chaos Approximation Rates for Elliptic {{PDEs}} with Lognormal {{Gaussian}} Random Inputs},
  author = {Hoang, Viet Ha and Schwab, Christoph},
  year = {2014},
  journal = {Mathematical Models and Methods in Applied Sciences},
  volume = {24},
  number = {04},
  pages = {797--826},
  publisher = {World Scientific}
}

@article{hoang2020,
  title = {Deep {{ReLU}} Neural Network Expression for Elliptic Multiscale Problems},
  author = {Hoang, Viet Ha and Schwab, Christoph},
  year = {2020},
  file = {/home/wouter/Zotero/storage/C435A3UB/Hoang, Schwab - 2020 - Deep ReLU neural network expression for elliptic multiscale problems.pdf}
}

@article{holschneider1990,
  title = {Wavelet Analysis on the Circle},
  author = {Holschneider, Matthias},
  year = {1990},
  journal = {Journal of Mathematical Physics},
  volume = {31},
  number = {1},
  pages = {39--44},
  doi = {10.1063/1.528825},
  abstract = {The construction of a wavelet analysis over the circle is presented. The spaces of infinitely times differentiable functions, tempered distributions, and square integrable functions over the circle are analyzed by means of the wavelet transform. {\copyright} 1989 American Institute of Physics.},
  file = {/home/wouter/Zotero/storage/HY57BD77/Holschneider - 1990 - Wavelet analysis on the circle.pdf}
}

@article{horgan2016,
  title = {Some Applications of Maximum Principles in Linear and Nonlinear Elasticity},
  author = {Horgan, Cornelius},
  year = {2016},
  number = {January 1988},
  file = {/home/wouter/Zotero/storage/AW4XYPHS/Horgan - 2016 - Some applications of maximum principles in linear and nonlinear elasticity.pdf}
}

@book{horn1985,
  title = {Matrix {{Analysis}}},
  author = {Horn, Roger A. and Johnson, Charles R.},
  year = {1985},
  month = dec,
  journal = {Matrix Analysis},
  publisher = {Cambridge University Press},
  doi = {10.1017/CBO9780511810817},
  abstract = {Linear algebra and matrix theory have long been fundamental tools in mathematical disciplines as well as fertile fields for research. In this book the authors present classical and recent results of matrix analysis that have proved to be important to applied mathematics. Facts about matrices, beyond those found in an elementary linear algebra course, are needed to understand virtually any area of mathematical science, but the necessary material has appeared only sporadically in the literature and in university curricula. As interest in applied mathematics has grown, the need for a text and reference offering a broad selection of topics in matrix theory has become apparent, and this book meets that need. This volume reflects two concurrent views of matrix analysis. First, it encompasses topics in linear algebra that have arisen out of the needs of mathematical analysis. Second, it is an approach to real and complex linear algebraic problems that does not hesitate to use notions from analysis. Review and miscellanea -- Eigenvalues, eigenvectors, and similarity.},
  isbn = {978-0-521-38632-6},
  file = {/home/wouter/Zotero/storage/TAXKLZB7/Horn, Johnson - 1985 - Matrix Analysis.pdf}
}

@book{horn1991,
  title = {Topics in {{Matrix Analysis}}},
  author = {Horn, Roger A. and Johnson, Charles R.},
  year = {1991},
  month = apr,
  journal = {Topics in Matrix Analysis},
  publisher = {Cambridge University Press},
  doi = {10.1017/cbo9780511840371},
  abstract = {Building on the foundations of its predecessor volume, Matrix Analysis, this book treats in detail several topics with important applications and of special mathematical interest in matrix theory not included in the previous text. These topics include the field of values, stable matrices and inertia, singular values, matrix equations and Kronecker products, Hadamard products, and matrices and functions. The authors assume a background in elementary linear algebra and knowledge of rudimentary analytical concepts. The book should be welcomed by graduate students and researchers in a variety of mathematical fields both as an advanced text and as a modern reference work.},
  isbn = {978-0-521-30587-7},
  file = {/home/wouter/Zotero/storage/75PX4ADX/Horn, Johnson - 1991 - Topics in Matrix Analysis.pdf}
}

@article{howell2009,
  title = {Lifting the Curse of Dimensionality: {{A}} Europeanist's Perspective},
  author = {Howell, Chris},
  year = {2009},
  journal = {Labor History},
  volume = {50},
  number = {3},
  pages = {347--350},
  doi = {10.1080/00236560903020930},
  file = {/home/wouter/Zotero/storage/RNNPTX7C/Howell - 2009 - Lifting the curse of dimensionality A europeanist's perspective.pdf}
}

@article{hsu1986,
  title = {On {{Excursions}} of {{Reflecting Brownian Motion}}},
  author = {Hsu, Pei},
  year = {1986},
  journal = {Transactions of the American Mathematical Society},
  volume = {296},
  number = {1},
  pages = {239--239},
  doi = {10.2307/2000572},
  file = {/home/wouter/Zotero/storage/KW3VYI4D/Hsu - 1986 - On Excursions of Reflecting Brownian Motion.pdf}
}

@article{hsu2004,
  title = {A Simplified Mesh Deformation Method Using Commercial Structural Analysis Software},
  author = {Hsu, Su Yuen and Chang, Chau Lyan and Samareh, Jamshid},
  year = {2004},
  journal = {Collection of Technical Papers - 10th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference},
  volume = {2},
  pages = {1197--1218},
  issn = {1563477165},
  doi = {10.2514/6.2004-4409},
  abstract = {Mesh deformation in response to redefined or moving aerodynamic surface geometries is a frequently encountered task in many applications. Most existing methods are either mathematically too complex or computationally too expensive for usage in practical design and optimization. We propose a simplified mesh deformation method based on linear elastic finite element analyses that can be easily implemented by using commercially available structural analysis software. Using a prescribed displacement at the mesh boundaries, a simple structural analysis is constructed based on a spatially varying Young's modulus to move the entire mesh in accordance with the surface geometry redefinitions. A variety of surface movements, such as translation, rotation, or incremental surface reshaping that often takes place in an optimization procedure, may be handled by the present method. We describe the numerical formulation and implementation using the NASTRAN software in this paper. The use of commercial software bypasses tedious reimplementation and takes advantage of the computational efficiency offered by the vendor. A two-dimensional airfoil mesh and a three-dimensional aircraft mesh were used as test cases to demonstrate the effectiveness of the proposed method. Euler and Navier-Stokes calculations were performed for the deformed two-dimensional meshes.},
  file = {/home/wouter/Zotero/storage/G7A8Z3ZI/Hsu, Chang, Samareh - 2004 - A simplified mesh deformation method using commercial structural analysis software.pdf}
}

@article{huang2022,
  title = {Efficient Derivative-Free {{Bayesian}} Inference for Large-Scale Inverse Problems},
  author = {Huang, Daniel Zhengyu and Huang, Jiaoyang and Reich, Sebastian and Stuart, Andrew M.},
  year = {2022},
  journal = {Inverse Problems},
  volume = {38},
  number = {12},
  publisher = {IOP Publishing},
  doi = {10.1088/1361-6420/ac99fa},
  abstract = {We consider Bayesian inference for large-scale inverse problems, where computational challenges arise from the need for repeated evaluations of an expensive forward model. This renders most Markov chain Monte Carlo approaches infeasible, since they typically require O ( 1 0 4 ) model runs, or more. Moreover, the forward model is often given as a black box or is impractical to differentiate. Therefore derivative-free algorithms are highly desirable. We propose a framework, which is built on Kalman methodology, to efficiently perform Bayesian inference in such inverse problems. The basic method is based on an approximation of the filtering distribution of a novel mean-field dynamical system, into which the inverse problem is embedded as an observation operator. Theoretical properties are established for linear inverse problems, demonstrating that the desired Bayesian posterior is given by the steady state of the law of the filtering distribution of the mean-field dynamical system, and proving exponential convergence to it. This suggests that, for nonlinear problems which are close to Gaussian, sequentially computing this law provides the basis for efficient iterative methods to approximate the Bayesian posterior. Ensemble methods are applied to obtain interacting particle system approximations of the filtering distribution of the mean-field model; and practical strategies to further reduce the computational and memory cost of the methodology are presented, including low-rank approximation and a bi-fidelity approach. The effectiveness of the framework is demonstrated in several numerical experiments, including proof-of-concept linear/nonlinear examples and two large-scale applications: learning of permeability parameters in subsurface flow; and learning subgrid-scale parameters in a global climate model. Moreover, the stochastic ensemble Kalman filter and various ensemble square-root Kalman filters are all employed and are compared numerically. The results demonstrate that the proposed method, based on exponential convergence to the filtering distribution of a mean-field dynamical system, is competitive with pre-existing Kalman-based methods for inverse problems.},
  keywords = {Bayesian inference,derivative-free optimization,ensemble Kalman filter,interacting particle system,inverse problem,mean-field dynamical system,uncertainty quantification},
  file = {/home/wouter/Zotero/storage/NGSFQP23/Huang et al. - 2022 - Efficient derivative-free Bayesian inference for large-scale inverse problems.pdf}
}

@inproceedings{hvarfner2024,
  title = {Vanilla {{Bayesian Optimization Performs Great}} in {{High Dimensions}}},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Hvarfner, Carl and Hellsten, Erik O. and Nardi, Luigi},
  year = {2024},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {235},
  pages = {20793--20817},
  publisher = {PMLR},
  doi = {10.48550/ARXIV.2402.02229},
  urldate = {2024-09-30},
  abstract = {High-dimensional problems have long been considered the Achilles' heel of Bayesian optimization algorithms. Spurred by the curse of dimensionality, a large collection of algorithms aim to make it more performant in this setting, commonly by imposing various simplifying assumptions on the objective. In this paper, we identify the degeneracies that make vanilla Bayesian optimization poorly suited to high-dimensional tasks, and further show how existing algorithms address these degeneracies through the lens of lowering the model complexity. Moreover, we propose an enhancement to the prior assumptions that are typical to vanilla Bayesian optimization algorithms, which reduces the complexity to manageable levels without imposing structural restrictions on the objective. Our modification - a simple scaling of the Gaussian process lengthscale prior with the dimensionality - reveals that standard Bayesian optimization works drastically better than previously thought in high dimensions, clearly outperforming existing state-of-the-art algorithms on multiple commonly considered real-world high-dimensional tasks.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/home/wouter/Zotero/storage/9AWV5BHI/Hvarfner et al. - 2024 - Vanilla Bayesian Optimization Performs Great in High Dimensions.pdf}
}

@article{ibrahimoglu2016,
  title = {Lebesgue Functions and {{Lebesgue}} Constants in Polynomial Interpolation},
  author = {Ibrahimoglu, Bayram Ali},
  year = {2016},
  journal = {Journal of Inequalities and Applications},
  volume = {2016},
  number = {1},
  publisher = {Ibrahimoglu},
  issn = {1366001610303},
  doi = {10.1186/s13660-016-1030-3},
  abstract = {The Lebesgue constant is a valuable numerical instrument for linear interpolation because it provides a measure of how close the interpolant of a function is to the best polynomial approximant of the function. Moreover, if the interpolant is computed by using the Lagrange basis, then the Lebesgue constant also expresses the conditioning of the interpolation problem. In addition, many publications have been devoted to the search for optimal interpolation points in the sense that these points lead to a minimal Lebesgue constant for the interpolation problems on the interval (Formula presented.). In Section~1 we introduce the univariate polynomial interpolation problem, for which we give two useful error formulas. The conditioning of polynomial interpolation is discussed in Section~2. A review of some results for the Lebesgue constants and the behavior of the Lebesgue functions in view of the optimal interpolation points is given in Section~3.},
  keywords = {Lebesgue constant,Lebesgue function,polynomial interpolation},
  file = {/home/wouter/Zotero/storage/R4MW78Q5/Ibrahimoglu - 2016 - Lebesgue functions and Lebesgue constants in polynomial interpolation.pdf}
}

@book{ihlenburg1998,
  title = {Finite Element Analysis of Acoustic Scattering},
  author = {Ihlenburg, Frank},
  year = {1998},
  series = {Applied Mathematical Sciences},
  number = {v. 132},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-98319-6},
  lccn = {QA1 QC174.26.W28 .A647 vol. 132},
  keywords = {Boundary value problems,Finite element method,Helmholtz equation,Mathematical models,Numerical solutions,Scattering (Physics),Wave equation},
  file = {/home/wouter/Zotero/storage/IH2P2S3F/Ihlenburg - 1998 - Finite element analysis of acoustic scattering.pdf}
}

@article{imaizumi2020,
  title = {Deep Neural Networks Learn Non-Smooth Functions Effectively},
  author = {Imaizumi, Masaaki and Fukumizu, Kenji},
  year = {2020},
  journal = {AISTATS 2019 - 22nd International Conference on Artificial Intelligence and Statistics},
  volume = {89},
  abstract = {We elucidate a theoretical reason that deep neural networks (DNNs) perform better than other models in some cases from the viewpoint of their statistical properties for non-smooth functions. While DNNs have empirically shown higher performance than other standard methods, understanding its mechanism is still a challenging problem. From an aspect of the statistical theory, it is known many standard methods attain the optimal rate of generalization errors for smooth functions in large sample asymptotics, and thus it has not been straightforward to find theoretical advantages of DNNs. This paper fills this gap by considering learning of a certain class of non-smooth functions, which was not covered by the previous theory. We derive the generalization error of estimators by DNNs with a ReLU activation, and show that convergence rates of the generalization by DNNs are almost optimal to estimate the non-smooth functions, while some of the popular models do not attain the optimal rate. In addition, our theoretical result provides guidelines for selecting an appropriate number of layers and edges of DNNs. We provide numerical experiments to support the theoretical results.},
  file = {/home/wouter/Zotero/storage/QEGKJEG7/Imaizumi, Fukumizu - 2020 - Deep neural networks learn non-smooth functions effectively.pdf}
}

@article{ipsen1998,
  title = {The {{Idea Behind Krylov Methods}}},
  author = {Ipsen, Ilse C. F. and Meyer, Carl D.},
  year = {1998},
  month = dec,
  journal = {The American Mathematical Monthly},
  volume = {105},
  number = {10},
  pages = {889--899},
  issn = {0002-9890, 1930-0972},
  doi = {10.1080/00029890.1998.12004985},
  urldate = {2025-02-18},
  langid = {english},
  file = {/home/wouter/Zotero/storage/VXLQL5Q3/Ipsen and Meyer - 1998 - The Idea Behind Krylov Methods.pdf}
}

@article{iyigun2010,
  title = {A Generalized {{Weiszfeld}} Method for the Multi-Facility Location Problem},
  author = {Iyigun, Cem and {Ben-Israel}, Adi},
  year = {2010},
  month = may,
  journal = {Operations Research Letters},
  volume = {38},
  number = {3},
  pages = {207--214},
  issn = {01676377},
  doi = {10.1016/j.orl.2009.11.005},
  urldate = {2024-10-07},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/JDULZHC9/Iyigun and Ben-Israel - 2010 - A generalized Weiszfeld method for the multi-facility location problem.pdf}
}

@article{jacob2020,
  title = {Unbiased {{Markov}} Chain {{Monte Carlo}} Methods with Couplings},
  author = {Jacob, Pierre E. and O'Leary, John and Atchad{\'e}, Yves F.},
  year = {2020},
  journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  volume = {82},
  number = {3},
  pages = {543--600},
  doi = {10.1111/rssb.12336},
  abstract = {Markov chain Monte Carlo (MCMC) methods provide consistent approximations of integrals as the number of iterations goes to {$\infty$}. MCMC estimators are generally biased after any fixed number of iterations. We propose to remove this bias by using couplings of Markov chains together with a telescopic sum argument of Glynn and Rhee. The resulting unbiased estimators can be computed independently in parallel. We discuss practical couplings for popular MCMC algorithms. We establish the theoretical validity of the estimators proposed and study their efficiency relative to the underlying MCMC algorithms. Finally, we illustrate the performance and limitations of the method on toy examples, on an Ising model around its critical temperature, on a high dimensional variable-selection problem, and on an approximation of the cut distribution arising in Bayesian inference for models made of multiple modules.},
  keywords = {Coupling,Markov chain Monte Carlo methods,Parallel computing,Unbiased estimation},
  file = {/home/wouter/Zotero/storage/U6HN5GJG/Jacob, O’Leary, Atchadé - 2020 - Unbiased Markov chain Monte Carlo methods with couplings.pdf}
}

@article{jahangiri1999,
  title = {Harmonic Functions Starlike in the Unit Disk},
  author = {Jahangiri, Jay M.},
  year = {1999},
  journal = {Journal of Mathematical Analysis and Applications},
  volume = {235},
  number = {2},
  pages = {470--477},
  doi = {10.1006/jmaa.1999.6377},
  abstract = {Complex-valued harmonic functions that are univalent and sense-preserving in the unit disk {$\Delta$} can be written in the form f=h+{\=g}, where h and g are analytic in {$\Delta$}. We give univalence criteria and sufficient coefficient conditions for normalized harmonic functions that are starlike of order {$\alpha$}, 0{$\leq\alpha<$}1. These coefficient conditions are also shown to be necessary when h has negative and g has positive coefficients. These lead to extreme points and distortion bounds. {\copyright} 1999 Academic Press.},
  keywords = {Harmonic,sense-preserving,starlike,univalent},
  file = {/home/wouter/Zotero/storage/J5JJ9495/Jahangiri - 1999 - Harmonic functions starlike in the unit disk.pdf}
}

@article{james1961,
  title = {Pointwise Bounds in Parabolic and Elliptic Partial Differential Equations .},
  author = {James, Fred},
  year = {1961},
  file = {/home/wouter/Zotero/storage/P9QNBDWF/James - 1961 - Pointwise bounds in parabolic and elliptic partial differential equations .pdf}
}

@article{jean-pierre1994,
  title = {A Perfectly Matched Layer for the Absorption of Electromagnetic Waves},
  author = {{Jean-Pierre}, Berenger},
  year = {1994},
  journal = {Journal of Computational Physics},
  volume = {114},
  number = {2},
  pages = {185--200},
  abstract = {A new technique of free-space simulation has been developed for solving unbounded electromagnetic problems with the finite-difference time-domain method. Referred to as PML, the new technique is based on the use of an absorbing layer especially designed to absorb without reflection the electromagnetic waves. The first part of the paper presents the theory of the PML technique. The second part is devoted to numerical experiments and to numerical comparisons with the previously used techniques of free-space simulation. These comparisons show that the PML technique works better than the others in all cases; using it allows us to obtain a higher accuracy in some problems and a release of computational requirements in some others.},
  keywords = {Berenger perfectly matched layer absorbing boundar},
  file = {/home/wouter/Zotero/storage/LSE98EHW/Jean-Pierre - 1994 - A perfectly matched layer for the absorption of electromagnetic waves.pdf}
}

@article{jerez-hanckes2017,
  title = {Electromagnetic Wave Scattering by Random Surfaces: {{Shape}} Holomorphy},
  author = {{Jerez-Hanckes}, Carlos and Schwab, Christoph and Zech, Jakob},
  year = {2017},
  month = nov,
  journal = {Mathematical Models and Methods in Applied Sciences},
  volume = {27},
  number = {12},
  pages = {2229--2259},
  doi = {10.1142/S0218202517500439},
  abstract = {For time-harmonic electromagnetic waves scattered by either perfectly conducting or dielectric bounded obstacles, we show that the fields depend holomorphically on the shape of the scatterer. In the presence of random geometrical perturbations, our results imply strong measurability of the fields, in weighted spaces in the exterior of the scatterer. These findings are key to prove dimension-independent convergence rates of sparse approximation techniques of polynomial chaos type for forward and inverse computational uncertainty quantification. Also, our shape-holomorphy results imply parsimonious approximate representations of the corresponding parametric solution families, which are produced, for example, by greedy strategies such as model order reduction or reduced basis approximations. Finally, the presently proved shape holomorphy results imply convergence of shape Taylor expansions of far-field patterns for fixed amplitude domain perturbations in a vicinity of the nominal domain, thereby extending the widely used asymptotic linearizations employed in first-order, second moment domain uncertainty quantification.},
  keywords = {Electromagnetic scattering,shape calculus,Smolyak quadrature,uncertainty quantification},
  file = {/home/wouter/Zotero/storage/5QSTRA3J/Jerez-Hanckes, Schwab, Zech - 2017 - Electromagnetic wave scattering by random surfaces Shape holomorphy.pdf}
}

@article{jiang2012,
  title = {Lipschitz {{Continuity}} of {{Solutions}} of {{Poisson Equations}} in {{Metric Measure Spaces}}},
  author = {Jiang, Renjin},
  year = {2012},
  journal = {Potential Analysis},
  volume = {37},
  number = {3},
  pages = {281--301},
  doi = {10.1007/s11118-011-9256-7},
  abstract = {Let (X, d) be a pathwise connected metric space equipped with an Ahlfors Q-regular measure {$\mu$}, Q {$\in$} [1, {$\infty$}). Suppose that (X, d, {$\mu$}) supports a 2-Poincar{\'e} inequality and a Sobolev-Poincar{\'e} type inequality for the corresponding "Gaussian measure". The author uses the heat equation to study the Lipschitz regularity of solutions of the Poisson equation {$\Delta$}u = f, where f {$\in$} L ploc. When p {$>$} Q, the local Lipschitz continuity of u is established. {\copyright} 2011 Springer Science+Business Media B.V.},
  keywords = {Heat kernel,Lipschitz regularity,Newtonian space,Poincare inequality,Poisson equation},
  file = {/home/wouter/Zotero/storage/4P4XC58Y/Jiang - 2012 - Lipschitz Continuity of Solutions of Poisson Equations in Metric Measure Spaces.pdf}
}

@article{jin2009,
  title = {A Preconditioned Recycling {{GMRES}} Solver for Stochastic Helmholtz Problems},
  author = {Jin, Chao and Cai, Xiao C.},
  year = {2009},
  journal = {Communications in Computational Physics},
  volume = {6},
  number = {2},
  pages = {342--353},
  doi = {10.4208/cicp.2009.v6.p342},
  abstract = {We present a parallel Schwarz type domain decomposition preconditioned recycling Krylov subspace method for the numerical solution of stochastic indefinite elliptic equations with two random coefficients. Karhunen-Loeve expansions are used to represent the stochastic variables and the stochastic Galerkin method with double orthogonal polynomials is used to derive a sequence of uncoupled deterministic equations. We show numerically that the Schwarz preconditioned recycling GMRES method is an effective technique for solving the entire family of linear systems and, in particular, the use of recycled Krylov subspaces is the key element of this successful approach.},
  keywords = {Additive Schwarz preconditioner,Domain decomposition,Recycling GMRES,Stochastic helmholtz equation},
  file = {/home/wouter/Zotero/storage/9BB5BS8V/Jin, Cai - 2009 - A preconditioned recycling GMRES solver for stochastic helmholtz problems.pdf}
}

@article{johansen2010,
  title = {Monte Carlo Methods},
  author = {Johansen, Adam M and Evers, Ludger and Whiteley, N},
  year = {2010},
  journal = {Lecture notes},
  volume = {200}
}

@article{johnson2011,
  title = {A Finite-Dimensional Approach to Wavelet Systems on the Circle},
  author = {Johnson, Brody Dylan},
  year = {2011},
  journal = {Glasnik Matematicki},
  volume = {46},
  number = {2},
  pages = {415--431},
  doi = {10.3336/gm.46.2.11},
  abstract = {Motivated by recent developments in the study of finite-dimensional frames, this work develops an independent theory of finite-dimensional wavelet systems on the circle. Using natural translation and dilation operators, trigonometric polynomial, orthonormal scaling functions are constructed which give rise to finite-dimensional multiresolution analyses and, consequently, orthonormal wavelet systems. It is shown that the finite-dimensional systems so constructed can lead to arbitrarily close approximation of square-integrable functions on the circle. Departures from the existing theory of periodic wavelets are encountered, e.g., the finite-dimensional equivalent of the Smith-Barnwell equation describes both a necessary and sufficient condition on a candidate low-pass filter for the existence of an orthonormal scaling function. Moreover, this finite-dimensional framework allows for a natural analog to the Shannon wavelet, in contrast to the classical periodic wavelets.},
  keywords = {Circle,Multiresolution analysis,Periodic wavelet,Wavelet},
  file = {/home/wouter/Zotero/storage/EQQEPW29/Johnson - 2011 - A finite-dimensional approach to wavelet systems on the circle.pdf}
}

@article{jones1998,
  title = {Efficient {{Global Optimization}} of {{Expensive}}  {{Black-Box Functions}}},
  author = {Jones, Donald R. and Schonlau, Matthias and Welch, William J.},
  year = {1998},
  journal = {Journal of Global Optimization},
  volume = {13},
  number = {4},
  pages = {455--492},
  issn = {09255001},
  doi = {10.1023/A:1008306431147},
  urldate = {2024-09-24},
  file = {/home/wouter/Zotero/storage/W2IRMYMK/Jones et al. - 1998 - [No title found].pdf}
}

@article{jornet2022,
  title = {Theory and Methods for Random Differential Equations: A Survey},
  author = {Jornet, Marc},
  year = {2022},
  month = oct,
  journal = {SeMA Journal},
  publisher = {Springer International Publishing},
  doi = {10.1007/s40324-022-00314-0},
  abstract = {In this survey, we present an overview of random differential equations, focusing on strong solutions and methods for estimation of statistics and densities. We combine classical and recent literature on the subject, making special emphasis on topics for which review works are still lacking.},
  keywords = {Differential equation with random input parameters,Mathematical modeling,Moment and density estimation,Stochastic solution,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/PSYQTVMJ/Jornet - 2022 - Theory and methods for random differential equations a survey.pdf}
}

@book{kaipo2004,
  title = {Statistical and {{Computational Inverse Problems}}},
  author = {Kaipo, Erkki, Jari; Somersalo},
  year = {2004},
  journal = {Applied Mathematical Sciences},
  volume = {160},
  isbn = {0-387-22073-9},
  file = {/home/wouter/Zotero/storage/822V2MRZ/Kaipo, Jari Somersalo - 2004 - Statistical and Computational Inverse Problems.pdf}
}

@article{kalaj2012,
  title = {Optimal Estimates for Harmonic Functions in the Unit Ball},
  author = {Kalaj, David and Markovi{\'c}, Marijan},
  year = {2012},
  month = dec,
  journal = {Positivity},
  volume = {16},
  number = {4},
  pages = {771--782},
  doi = {10.1007/s11117-011-0145-5},
  abstract = {We find the sharp constants Cp and the sharp functions Cp = Cp(x) in the inequality, in terms of Gauss hypergeometric and Euler functions. This extends and improves some results of Axler et al. (Harmonic function theory, New York, 1992), where they obtained similar results which are sharp only in the cases p = 2 and p = 1. {\copyright} 2011 Springer Basel AG.},
  keywords = {Hardy spaces,Harmonic functions},
  file = {/home/wouter/Zotero/storage/SETZIAPA/Kalaj, Marković - 2012 - Optimal estimates for harmonic functions in the unit ball.pdf}
}

@article{kalczynski2024,
  title = {Further {{Analysis}} of the {{Weber Problem}}},
  author = {Kalczynski, Pawel and Drezner, Zvi},
  year = {2024},
  journal = {Networks and Spatial Economics},
  publisher = {Springer US},
  issn = {1106702409},
  doi = {10.1007/s11067-024-09627-1},
  abstract = {The most basic location problem is the Weber problem, that is a basis to many advanced location models. It is finding the location of a facility which minimizes the sum of weighted distances to a set of demand points. Solution approaches have convergence issues when the optimal solution is at a demand point because the derivatives of the objective function do not exist on a demand point and are discontinuous near it. In this paper we investigate the probability that the optimal location is on a demand point, create example problems that may take millions of iterations to converge to the optimal location, and suggest a simple improvement to the Weiszfeld solution algorithm. One would expect that if the number of demand points increases to infinity, the probability that the optimal location is on a demand point converges to 1 because there is no ``space" left to locate the facility not on a demand point. Consequently, we may experience convergence issues for relatively large problems. However, it was shown that for randomly generated points in a circle the probability converges to zero, which is counter intuitive. In this paper we further investigate this probability. Another interesting result of our experiments is that FORTRAN is much faster than Python for such simulations. Researchers are advised to apply old fashioned programming languages rather than newer software for simulations of this type.},
  file = {/home/wouter/Zotero/storage/5NWEJPIV/Kalczynski, Drezner - 2024 - Further Analysis of the Weber Problem.pdf}
}

@article{kantas2009,
  title = {An Overview of {{Sequential Monte Carlo}} Methods for Parameter Estimation in General State-Space Models},
  author = {Kantas, N. and Doucet, A. and Singh, S. S. and MacIejowski, J. M.},
  year = {2009},
  journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
  volume = {15},
  number = {PART 1},
  pages = {774--785},
  issn = {9783902661470},
  doi = {10.3182/20090706-3-FR-2004.0297},
  abstract = {Nonlinear non-Gaussian state-space models arise in numerous applications in control and signal processing. Sequential Monte Carlo (SMC) methods, also known as Particle Filters, provide very good numerical approximations to the associated optimal state estimation problems. However, in many scenarios, the state-space model of interest also depends on unknown static parameters that need to be estimated from the data. In this context, standard SMC methods fail and it is necessary to rely on more sophisticated algorithms. The aim of this paper is to present a comprehensive overview of SMC methods that have been proposed to perform static parameter estimation in general state-space models. We discuss the advantages and limitations of these methods. {\copyright} 2009 IFAC.},
  keywords = {General state-space models,Hidden Markov models,Parameter estimation,Sequential Monte Carlo},
  file = {/home/wouter/Zotero/storage/PUY4RXZU/Kantas et al. - 2009 - An overview of Sequential Monte Carlo methods for parameter estimation in general state-space models.pdf}
}

@article{kantas2014,
  title = {Sequential {{Monte Carlo}} Methods for High-Dimensional Inverse Problems: {{A}} Case Study for the {{Navier}}--{{Stokes}} Equations},
  author = {Kantas, Nikolas and Beskos, Alexandros and Jasra, Ajay},
  year = {2014},
  journal = {SIAM-ASA Journal on Uncertainty Quantification},
  volume = {2},
  number = {1},
  pages = {464--489},
  doi = {10.1137/130930364},
  abstract = {We consider the inverse problem of estimating the initial condition of a partial differential equation, which is observed only through noisy measurements at discrete time intervals. In particular, we focus on the case where Eulerian measurements are obtained from the time and space evolving vector field, whose evolution obeys the two-dimensional Navier--Stokes equations defined on a torus. This context is particularly relevant to the area of numerical weather forecasting and data assimilation. We will adopt a Bayesian formulation resulting from a particular regularization that ensures the problem is well posed. In the context of Monte Carlo--based inference, it is a challenging task to obtain samples from the resulting high-dimensional posterior on the initial condition. In real data assimilation applications it is common for computational methods to invoke the use of heuristics and Gaussian approximations. As a result, the resulting inferences are biased and not well justified in the presence of nonlinear dynamics and observations. On the other hand, Monte Carlo methods can be used to assimilate data in a principled manner, but they are often perceived as inefficient in this context due to the high dimensionality of the problem. In this work we will propose a generic sequential Monte Carlo (SMC) sampling approach for high-dimensional inverse problems that overcomes these difficulties. The method builds upon ``state of the art'' Markov chain Monte Carlo (MCMC) techniques, which are currently considered as benchmarks for evaluating data assimilation algorithms used in practice. SMC samplers can improve in terms of efficiency, as they possess greater flexibility and one can include steps like sequential tempering, adaptation, and parallelization with a relatively low number of extra computations. We will illustrate this using numerical examples, where our proposed SMC approach can achieve the same accuracy as MCMC but in a much more efficient manner.},
  keywords = {Bayesian inverse problems,Data assimilation,Navier-Stokes equations,Sequential Monte Carlo},
  file = {/home/wouter/Zotero/storage/ZCMXQNLE/Kantas, Beskos, Jasra - 2014 - Sequential Monte Carlo methods for high-dimensional inverse problems A case study for the Navier–Stokes.pdf}
}

@article{kaplan2020,
  title = {Dynamic {{Planar Voronoi Diagrams}} for {{General Distance Functions}} and {{Their Algorithmic Applications}}},
  author = {Kaplan, Haim and Mulzer, Wolfgang and Roditty, Liam and Seiferth, Paul and Sharir, Micha},
  year = {2020},
  journal = {Discrete and Computational Geometry},
  volume = {64},
  number = {3},
  pages = {838--904},
  doi = {10.1007/s00454-020-00243-7},
  abstract = {We describe a new data structure for dynamic nearest neighbor queries in the plane with respect to a general family of distance functions. These include Lp-norms and additively weighted Euclidean distances. Our data structure supports general (convex, pairwise disjoint) sites that have constant description complexity (e.g., points, line segments, disks, etc.). Our structure uses O(nlog 3n) storage, and requires polylogarithmic update and query time, improving an earlier data structure of Agarwal, Efrat, and Sharir which required O(n{$\varepsilon$}) time for an update and O(log n) time for a query [SICOMP 1999]. Our data structure has numerous applications. In all of them, it gives faster algorithms, typically reducing an O(n{$\varepsilon$}) factor in the previous bounds to polylogarithmic. In addition, we give here two new applications: an efficient construction of a spanner in a disk intersection graph, and a data structure for efficient connectivity queries in a dynamic disk graph. To obtain this data structure, we combine and extend various techniques from the literature. Along the way, we obtain several side results that are of independent interest. Our data structure depends on the existence and an efficient construction of ``vertical'' shallow cuttings in arrangements of bivariate algebraic functions. We prove that an appropriate level in an arrangement of a random sample of a suitable size provides such a cutting. To compute it efficiently, we develop a randomized incremental construction algorithm for computing the lowest k levels in an arrangement of bivariate algebraic functions (we mostly consider here collections of functions whose lower envelope has linear complexity, as is the case in the dynamic nearest-neighbor context, under both types of norm). To analyze this algorithm, we also improve a longstanding bound on the combinatorial complexity of the vertical decomposition of these levels. Finally, to obtain our structure, we combine our vertical shallow cutting construction with Chan's algorithm for efficiently maintaining the lower envelope of a dynamic set of planes in R3. Along the way, we also revisit Chan's technique and present a variant that uses a single binary counter, with a simpler analysis and improved amortized deletion time (by a logarithmic factor; the insertion and query costs remain asymptotically the same).},
  keywords = {Dynamic structure,General distance functions,Voronoi diagram},
  file = {/home/wouter/Zotero/storage/IJL7M4E9/Kaplan et al. - 2020 - Dynamic Planar Voronoi Diagrams for General Distance Functions and Their Algorithmic Applications.pdf}
}

@techreport{karlova,
  title = {Krepela+{{Embeddings}} in the {{Spaces}} of {{H{\"o}lder Functions}}.Pdf},
  author = {Karlova, Univerzita and {Matematicko-fyzik}, Praze},
  file = {/home/wouter/Zotero/storage/NR6I5NWV/Karlova, Matematicko-fyzik - Unknown - KrepelaEmbeddings in the Spaces of Hölder Functions.pdf.pdf}
}

@article{katsevich2023,
  title = {On the {{Approximation Accuracy}} of {{Gaussian Variational Inference}}},
  author = {Katsevich, Anya and Rigollet, Philippe},
  year = {2023},
  pages = {1--39},
  abstract = {The main quantities of interest in Bayesian inference are arguably the first two moments of the posterior distribution. In the past decades, variational inference (VI) has emerged as a tractable approach to approximate these summary statistics, and a viable alternative to the more established paradigm of Markov Chain Monte Carlo. However, little is known about the approximation accuracy of VI. In this work, we bound the mean and covariance approximation error of Gaussian VI in terms of dimension and sample size. Our results indicate that Gaussian VI outperforms significantly the classical Gaussian approximation obtained from the ubiquitous Laplace method. Our error analysis relies on a Hermite series expansion of the log posterior whose first terms are precisely cancelled out by the first order optimality conditions associated to the Gaussian VI optimization problem.},
  file = {/home/wouter/Zotero/storage/N96XZ7VW/Katsevich, Rigollet - 2023 - On the Approximation Accuracy of Gaussian Variational Inference.pdf}
}

@book{katznelson1968,
  title = {Katznelson.Pdf},
  author = {Katznelson, Yitshak},
  year = {1968},
  file = {/home/wouter/Zotero/storage/R9HMRRTN/Katznelson - 1968 - Katznelson.pdf.pdf}
}

@article{katzourakis2017,
  title = {A Remark on Global {{W1}},p Bounds for Harmonic Functions with Lipschitz Boundary Values},
  author = {Katzourakis, Nikos},
  year = {2017},
  journal = {Glasnik Matematicki},
  volume = {52},
  number = {1},
  pages = {107--113},
  doi = {10.3336/gm.52.1.08},
  abstract = {In this note we show that gradient of harmonic functions on a smooth domain with Lipschitz boundary values is pointwise bounded by a universal function which is in Lp for all finite p {$\geq$} 1.},
  keywords = {Dirichlet problem,Harmonic functions,Schauder estimates},
  file = {/home/wouter/Zotero/storage/BC599YRV/Katzourakis - 2017 - A remark on global W1,p bounds for harmonic functions with lipschitz boundary values.pdf}
}

@phdthesis{keese2004,
  title = {Numerical {{Solution}} of {{Systems}} with {{Stochastic Uncertainties}}: {{A General Purpose Framework}} for {{Stochastic Finite Elements}}},
  shorttitle = {Numerical {{Solution}} of {{Systems}} with {{Stochastic Uncertainties}}},
  author = {Keese, Andreas},
  year = {2004},
  month = apr,
  doi = {10.24355/DBBS.084-200511080100-436},
  urldate = {2025-02-24},
  abstract = {Inhalt der Arbeit ist die numerische Simulation von Systemen mit stochastischen Parametern, die durch stochastische partielle Differentialgleichungen (SPDGLn) beschrieben werden. Es werden die Theorie linearer und nichtlinearer elliptischer SPDGLn sowie Diskretisierungsverfahren beschrieben. F{\"u}r die r{\"a}umliche Diskretisierung wird eine existierende Simulationssoftware verwendet, w{\"a}hrend die stochastische Diskretisierung durch die direkte numerische Integration von Statistiken unter Verwendung von Monte Carlo- und Smolyak-Quadraturverfahren oder durch Reihenentwicklungen in Tensorprodukten finiter Elemente und stochastischer Ansatzfunktionen erfolgt. Die Reihenentwicklung wird dabei durch orthogonale Projektionen oder durch Galerkinverfahren gewonnen. Bei der Anwendung stochastischer Galerkinvervahren entstehen gro{\ss}e Systeme gekoppelter Blockgleichungssysteme, welche hier durch iterative Verfahren gel{\"o}st werden. Zur L{\"o}sung linearer SPDGln werden effiziente Darstellungen der Gleichungssysteme und iterative L{\"o}ser entwickelt. Aufgrund der Gr{\"o}{\ss}e der entstehenden Gleichungssysteme wird ein paralleler L{\"o}ser bereitgestellt. Die L{\"o}sung nichtlinearer SPDGLn geschieht durch approximative und Quasi-Newtonverfahren. Ein duales Verfahren erm{\"o}glicht die adaptive Verfeinerung der L{\"o}sung. Diese Verfahren werden in einer Allzwecksoftware f{\"u}r stochastische finite Elemente implementiert, die es erlaubt, existierende Simulationscodes um stochastische Unsicherheiten zu erweitern.},
  collaborator = {{Universit{\"a}tsbibliothek Braunschweig} and Matthies, Hermann G.},
  copyright = {all rights reserved},
  langid = {english},
  school = {Universit{\"a}tsbibliothek Braunschweig},
  keywords = {510},
  file = {/home/wouter/Zotero/storage/UXL94NVC/Keese - 2004 - Numerical Solution of Systems with Stochastic Uncertainties A General Purpose Framework for Stochas.pdf}
}

@article{keese2005,
  title = {Hierarchical Parallelisation for the Solution of Stochastic Finite Element Equations},
  author = {Keese, Andreas and Matthies, Hermann G.},
  year = {2005},
  month = may,
  journal = {Computers \& Structures},
  volume = {83},
  number = {14},
  pages = {1033--1047},
  issn = {00457949},
  doi = {10.1016/j.compstruc.2004.11.014},
  urldate = {2025-02-24},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/LG7QC26L/Keese and Matthies - 2005 - Hierarchical parallelisation for the solution of stochastic finite element equations.pdf}
}

@phdthesis{kent2023,
  title = {{{EFFICIENT APPROXIMATION OF PARAMETRIC PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS}}},
  author = {Kent, Benjamin M},
  year = {2023},
  file = {/home/wouter/Zotero/storage/DVJZSZFC/Kent - 2023 - EFFICIENT APPROXIMATION OF PARAMETRIC PARABOLIC PARTIAL DIFFERENTIAL EQUATIONS.PDF}
}

@article{khristenko2019,
  title = {Analysis of Boundary Effects on {{PDE-based}} Sampling of Whittle-Matern Random Fields},
  author = {Khristenko, U. and Scarabosio, Laura and Swierczynski, P. and Ullmann, E. and Wohlmuth, B.},
  year = {2019},
  journal = {SIAM-ASA Journal on Uncertainty Quantification},
  volume = {7},
  number = {3},
  pages = {948--974},
  doi = {10.1137/18M1215700},
  abstract = {We consider the generation of samples of a mean-zero Gaussian random field with Matfiern covariance function. Every sample requires the solution of a difierential equation with Gaussian white noise forcing, formulated on a bounded computational domain. This introduces unwanted boundary efiects since the stochastic partial difierential equation is originally posed on the whole Rd, without boundary conditions. We use a window technique, whereby one embeds the computational domain into a larger domain and postulates convenient boundary conditions on the extended domain. To mitigate the pollution from the artificial boundary it has been suggested in numerical studies to choose a window size that is at least as large as the correlation length of the Matfiern field. We provide a rigorous analysis for the error in the covariance introduced by the domain truncation, for homogeneous Dirichlet, homogeneous Neumann, and periodic boundary conditions. We show that the error decays exponentially in the window size, independently of the type of boundary condition. We conduct numerical experiments in one-and two-dimensional space, confirming our theoretical result.},
  keywords = {Gaussian random field,Matern covariance,spatial statistics,uncertainty quantification},
  file = {/home/wouter/Zotero/storage/ILG6HRLW/Khristenko et al. - 2019 - Analysis of boundary effects on PDE-based sampling of whittle-matern random fields.pdf}
}

@article{khristenko2020,
  title = {A {{Statistical Framework}} for {{Generating Microstructures}} of {{Two-Phase Random Materials}}: {{Application}} to {{Fatigue Analysis}}},
  author = {Khristenko, Ustim and Constantinescu, Andrei and Tallec, Patrick L.E. and Oden, J. Tinsley and Wohlmuth, Barbara},
  year = {2020},
  month = jan,
  journal = {Multiscale Modeling \& Simulation},
  volume = {18},
  number = {1},
  pages = {21--43},
  doi = {10.1137/19M1259286},
  abstract = {Random microstructures of heterogeneous materials play a crucial role in the material macroscopic behavior and in predictions of its effective properties. A common approach to modeling random multiphase materials is to develop so-called surrogate models approximating statistical features of the material. However, the surrogate models used in fatigue analysis usually employ simple microstructure, consisting of ideal geometries such as ellipsoidal inclusions, which generally does not capture complex geometries. In this paper, we introduce a simple but flexible surrogate microstructure model for two-phase materials through a level-cut of a Gaussian random field with covariance of Mat{\'e}rn class. Such parametrization of the covariance function allows for the representation of a few key design parameters while representing the geometry of inclusions in a more general setting for a large class of random heterogeneous two-phase media. In addition to the traditional morphology descriptors such as porosity, size, and aspect ratio, it provides control of the regularity of the inclusions interface and sphericity. These parameters are estimated from a small number of real material images using Bayesian inversion. An efficient process of evaluating the samples, based on the fast Fourier transform, makes possible the use of Monte Carlo methods to estimate statistical properties for the quantities of interest in a given material class. We demonstrate the overall framework of the use of the surrogate material model in application to the uncertainty quantification in fatigue analysis, its feasibility and efficiency, and its role in the microstructure design.},
  keywords = {Fatigue analysis,Gaussian level-set,Matern covariance,Random heterogeneous material,Two-phase material,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/E5D6CZUK/Khristenko et al. - 2020 - A Statistical Framework for Generating Microstructures of Two-Phase Random Materials Application to Fatigue A.pdf}
}

@article{khristenko2021,
  title = {Surrogate Models for Manufactured Materials with Random Imperfections},
  author = {Khristenko, Ustim and Constantinescu, Andrei and Tallec, Patrick Le and Oden, J. Tinsley and Wohlmuth, Barbara},
  year = {2021},
  abstract = {Manufactured materials usually contain random imperfections due to the fabrication process, e.g., the 3D-printing, casting, etc. In this work, we present a new flexible class of digital surrogate models which imitate the manufactured material respecting the statistical features of random imperfections. The surrogate model is constructed as the level-set of a linear combination of the intensity field representing the topological shape and the Gaussian perturbation representing the imperfections. The mathematical design parameters of the model are related to physical ones and thus easy to comprehend. The calibration of the model parameters is performed using progressive batching sub-sampled quasi-Newtion minimization, using a designed distance measure between synthetic samples and the data. Then, owing to a fast sampling algorithm, we have access to an arbitrary number of synthetic samples that can be used in Monte Carlo type methods for uncertainty quantification of the material response. In particular, we illustrate the method with a surrogate model for an imperfect octet-truss lattice cell, which plays an important role in additive manufacturing. We also discuss potential model extensions.},
  keywords = {additive manufacturing,admire him as a,and exceptional contributions in,as a kind and,dedication,elasto-plastic material,gentle,gratitude to dr,great scientist with unique,j,many areas,quantification,random fields,stochastic optimization,surrogate model,the authors would like,tinsley oden,to express their deepest,uncertainty,we},
  file = {/home/wouter/Zotero/storage/4WS5N3C6/Khristenko et al. - 2021 - Surrogate models for manufactured materials with random imperfections.pdf}
}

@misc{kindap2022,
  title = {Non-{{Gaussian Process Regression}}},
  author = {K{\i}ndap, Yaman and Godsill, Simon},
  year = {2022},
  month = sep,
  number = {arXiv:2209.03117},
  eprint = {2209.03117},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-08-20},
  abstract = {Standard GPs offer a flexible modelling tool for well-behaved processes. However, deviations from Gaussianity are expected to appear in real world datasets, with structural outliers and shocks routinely observed. In these cases GPs can fail to model uncertainty adequately and may over-smooth inferences. Here we extend the GP framework into a new class of time-changed GPs that allow for straightforward modelling of heavy-tailed non-Gaussian behaviours, while retaining a tractable conditional GP structure through an infinite mixture of non-homogeneous GPs representation. The conditional GP structure is obtained by conditioning the observations on a latent transformed input space and the random evolution of the latent transformation is modelled using a L{\textbackslash}'\{e\}vy process which allows Bayesian inference in both the posterior predictive density and the latent transformation function. We present Markov chain Monte Carlo inference procedures for this model and demonstrate the potential benefits compared to a standard GP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/BX38PEJN/Kındap and Godsill - 2022 - Non-Gaussian Process Regression.pdf;/home/wouter/Zotero/storage/HEMVKXZ3/2209.html}
}

@book{kirkup2006,
  title = {An Introduction to Uncertainty in Measurement Using the {{GUM}} (Guide to the Expression of Uncertainty in Measurement)},
  author = {Kirkup, Les},
  year = {2006},
  publisher = {Cambridge University Press},
  address = {Cambridge, UK},
  collaborator = {Frenkel, R. B.},
  isbn = {978-0-521-84428-4 978-0-511-19063-6},
  langid = {english}
}

@article{kitagawa1996,
  title = {Monte {{Carlo Filter}} and {{Smoother}} for {{Non-Gaussian Nonlinear State Space Models}}},
  author = {Kitagawa, Genshiro},
  year = {1996},
  month = mar,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {5},
  number = {1},
  eprint = {1390750},
  eprinttype = {jstor},
  pages = {1--1},
  doi = {10.2307/1390750},
  file = {/home/wouter/Zotero/storage/F7N9454A/Kitagawa - 1996 - Monte Carlo Filter and Smoother for Non-Gaussian Nonlinear State Space Models.pdf}
}

@article{kobyzev2021,
  title = {Normalizing {{Flows}}: {{An Introduction}} and {{Review}} of {{Current Methods}}},
  shorttitle = {Normalizing {{Flows}}},
  author = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
  year = {2021},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {43},
  number = {11},
  pages = {3964--3979},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2992934},
  urldate = {2024-10-29},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  file = {/home/wouter/Zotero/storage/Z26VCNHU/Kobyzev et al. - 2021 - Normalizing Flows An Introduction and Review of Current Methods.pdf}
}

@misc{koppen2000,
  title = {Curse of {{Dimensionality}}},
  author = {K{\"o}ppen, Mario},
  year = {2000},
  doi = {10.1007/978-0-387-39940-9_133},
  urldate = {2024-12-13},
  langid = {english},
  file = {/home/wouter/Zotero/storage/SKDSX7U7/Köppen - 2000 - Curse of Dimensionality.pdf}
}

@book{koren2010,
  title = {Advanced {{Computational Methods}} in {{Science}} and {{Engineering}}},
  editor = {Koren, Barry and Vuik, Kees},
  year = {2010},
  series = {Lecture {{Notes}} in {{Computational Science}} and {{Engineering}}},
  volume = {71},
  pages = {23},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03344-5},
  abstract = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell ``S'' karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
  isbn = {978-3-642-03343-8},
  file = {/home/wouter/Zotero/storage/U3RYJY3D/Unknown - 2010 - Advanced Computational Methods in Science and Engineering.pdf}
}

@article{koval2020,
  title = {Optimal Experimental Design under Irreducible Uncertainty for Linear Inverse Problems Governed by {{PDEs}}},
  author = {Koval, Karina and Alexanderian, Alen and Stadler, Georg},
  year = {2020},
  journal = {Inverse Problems},
  volume = {36},
  number = {7},
  doi = {10.1088/1361-6420/ab89c5},
  abstract = {We present a method for computing A-optimal sensor placements for infinite-dimensional Bayesian linear inverse problems governed by PDEs with irreducible model uncertainties. Here, irreducible uncertainties refers to uncertainties in the model that exist in addition to the parameters in the inverse problem, and that cannot be reduced through observations. Specifically, given a statistical distribution for the model uncertainties, we compute the optimal design that minimizes the expected value of the posterior covariance trace. The expected value is discretized using Monte Carlo leading to an objective function consisting of a sum of trace operators and a binary-inducing penalty. Minimization of this objective requires a large number of PDE solves in each step. To make this problem computationally tractable, we construct a composite low-rank basis using a randomized range finder algorithm to eliminate forward and adjoint PDE solves. We also present a novel formulation of the A-optimal design objective that requires the trace of an operator in the observation rather than the parameter space. The binary structure is enforced using a weighted regularized {$\ell$} 0-sparsification approach. We present numerical results for inference of the initial condition in a subsurface flow problem with inherent uncertainty in the flow fields and in the initial times.},
  keywords = {inverse problems,model reduction,model uncertainty,optimal design,optimization under uncertainty,subsurface flow},
  file = {/home/wouter/Zotero/storage/HTEGYXLC/Koval, Alexanderian, Stadler - 2020 - Optimal experimental design under irreducible uncertainty for linear inverse problems governed by.pdf}
}

@article{krah2025,
  title = {A {{Robust Shifted Proper Orthogonal Decomposition}}: {{Proximal Methods}} for {{Decomposing Flows}} with {{Multiple Transports}}},
  shorttitle = {A {{Robust Shifted Proper Orthogonal Decomposition}}},
  author = {Krah, Philipp and Marmin, Arthur and Zorawski, Beata and Reiss, Julius and Schneider, Kai},
  year = {2025},
  month = apr,
  journal = {SIAM Journal on Scientific Computing},
  volume = {47},
  number = {2},
  pages = {A633-A656},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/24M164392X},
  urldate = {2025-03-17},
  langid = {english},
  file = {/home/wouter/Zotero/storage/GV3BXZD7/Krah et al. - 2025 - A Robust Shifted Proper Orthogonal Decomposition Proximal Methods for Decomposing Flows with Multip.pdf}
}

@article{krasovskii1969,
  title = {Green {{Function Properties}} and {{Generalized Solutions}} of {{Elliptic Boundary Value Problems}}},
  author = {Krasovski{\u \i}, Ju P},
  year = {1969},
  month = feb,
  journal = {Mathematics of the USSR-Izvestiya},
  volume = {3},
  number = {1},
  pages = {105--130},
  doi = {10.1070/IM1969v003n01ABEH000750},
  file = {/home/wouter/Zotero/storage/KALUC9D8/Krasovskiĭ - 1969 - Green Function Properties and Generalized Solutions of Elliptic Boundary Value Problems.pdf}
}

@article{kresin2010,
  title = {Optimal Estimates for the Gradient of Harmonic Functions in the Multidimensional Half-Space},
  author = {Kresin, Gershon and Maz'ya, Vladimir},
  year = {2010},
  journal = {Discrete and Continuous Dynamical Systems},
  volume = {28},
  number = {2},
  pages = {425--440},
  doi = {10.3934/dcds.2010.28.425},
  abstract = {A representation of the sharp constant in a pointwise estimate of the gradient of a harmonic function in a multidimensional half-space is obtained under the assumption that function's boundary values belong to Lp. This representation is concretized for the cases p = 1, 2, and {$\infty$}.},
  keywords = {Estimates of the gradient,Khavinson's problem,Multidimensional harmonic functions,Real-part theorems},
  file = {/home/wouter/Zotero/storage/VNJ62C6Z/Kresin, Maz'ya - 2010 - Optimal estimates for the gradient of harmonic functions in the multidimensional half-space.pdf}
}

@article{kresin2010a,
  title = {Sharp Pointwise Estimates for Directional Derivatives of Harmonic Functions in a Multidimensional Ball},
  author = {Kresin, G. and Maz'ya, V.},
  year = {2010},
  journal = {Journal of Mathematical Sciences},
  volume = {169},
  number = {2},
  pages = {167--187},
  doi = {10.1007/s10958-010-0045-4},
  abstract = {A representation of the sharp constant in a pointwise estimate for the absolute value of the directional derivative of a harmonic function in a multidimensional ball is obtained under the assumption that the boundary values of the function belong to Lp. This representation is specified in the cases of radial and tangential derivatives. It is proved for p = 1 and p = 2 that the maximum of the absolute value of the directional derivative of a harmonic function with a fixed Lp-norm of its boundary values is attained at the radial direction. This confirms D. Khavinson's conjecture for p = 1 and p = 2. Bibliography: 11 titles. {\copyright} 2010 Springer Science+Business Media, Inc.},
  file = {/home/wouter/Zotero/storage/2J3NPBTZ/Kresin, Maz'ya - 2010 - Sharp pointwise estimates for directional derivatives of harmonic functions in a multidimensional ball.pdf}
}

@article{kresin2014,
  title = {Optimal {{Pointwise Stimates}} for {{Derivatives}} of {{Solutions}} to {{Laplace}}, {{Lam{\`e}}}, and {{Stokes Equations}}},
  author = {Kresin, G and Maz'ya, V. G.},
  year = {2014},
  month = jan,
  journal = {Journal of Mathematical Sciences (United States)},
  volume = {196},
  number = {3},
  pages = {300--321},
  doi = {10.1007/s10958-014-1660-2},
  abstract = {We obtain various optimal estimates for solutions of the Laplace, Lam{\'e}, and Stokes equations in multidimensional domains. We also prove new real-part theorems for analytic functions.},
  file = {/home/wouter/Zotero/storage/YGR68P76/Kresin, Maz’ya - 2014 - Optimal Pointwise Stimates for Derivatives of Solutions to Laplace, Lamè, and Stokes Equations.pdf}
}

@article{krotov1986,
  title = {Differential Properties of Boundary Functions of {{Hardy}} Spaces},
  author = {Krotov, Veniamin},
  year = {1986},
  journal = {Mathematische Nachrichten},
  volume = {126},
  number = {1},
  pages = {241--253},
  doi = {10.1002/mana.19861260116},
  file = {/home/wouter/Zotero/storage/ACUA3LKZ/Krotov - 1986 - Differential properties of boundary functions of Hardy spaces.pdf}
}

@article{kuenne1972,
  title = {Exact and Approximate Solutions to the Multisource Weber Problem},
  author = {Kuenne, Robert E. and Soland, Richard M.},
  year = {1972},
  journal = {Mathematical Programming},
  volume = {3},
  number = {1},
  pages = {193--209},
  doi = {10.1007/BF01584989},
  abstract = {The problem considered is the choice of locations for m sources so as to minimize the sum of weighted distances between n fixed sinks and the source closest to each sink. The weights represent the amounts to be shipped between the sinks and their respective sources; the allowable source locations are free of restriction. An algorithm for the approximate solution of the problem, and computational experience with it, are discussed first. A branch-and-bound algorithm for exact solution of the problem is then developed, and computational experience with it is described. {\copyright} 1972 The Mathematical Programming Society.},
  file = {/home/wouter/Zotero/storage/SIRALM4W/Kuenne, Soland - 1972 - Exact and approximate solutions to the multisource weber problem.pdf}
}

@misc{kuijpers2024,
  title = {Wavenumber-{{Explicit Well-Posedness}} of {{Bayesian Shape Inversion}} in {{Acoustic Scattering}}},
  author = {Kuijpers, Safiere and Scarabosio, Laura},
  year = {2024},
  month = oct,
  number = {arXiv:2410.23100},
  eprint = {2410.23100},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.23100},
  urldate = {2025-09-23},
  abstract = {We consider the Bayesian approach to the inverse problem of recovering the shape of an object from measurements of its scattered acoustic field. Working in the time-harmonic setting, we focus on a Helmholtz transmission problem and then extend our results to an exterior Dirichlet problem. We assume the scatterer to be star-shaped and we use, as prior, a truncated expansion with uniform random variables for a radial parametrization of the scatterer's boundary. The main novelty of our work is that we establish the well-posedness of the Bayesian shape inverse problem in a wavenumber-explicit way, under some conditions on the material parameters excluding quasi-resonant regimes. Our estimates highlight how the stability of the posterior with respect to the data is affected by the wavenumber (or, in other words, the frequency), whose magnitude has to be understood not in absolute terms but in relationship to the spatial scale of the problem.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Analysis of PDEs,Mathematics - Statistics Theory,Statistics - Statistics Theory},
  file = {/home/wouter/Zotero/storage/WSGZ3SXG/Kuijpers and Scarabosio - 2024 - Wavenumber-Explicit Well-Posedness of Bayesian Shape Inversion in Acoustic Scattering.pdf;/home/wouter/Zotero/storage/5QTSAFDH/2410.html}
}

@article{kulin1962,
  title = {{{AN EFFICIENT ALGORITHM FOR THE NUMERICAL SOLUTION OF THE GENERALIZED WEBER PROBLEM IN SPATIAL ECONOMICS}}},
  author = {Kulin, Harold W. and Kuenne, Robert E.},
  year = {1962},
  month = dec,
  journal = {Journal of Regional Science},
  volume = {4},
  number = {2},
  pages = {21--33},
  issn = {0022-4146, 1467-9787},
  doi = {10.1111/j.1467-9787.1962.tb00902.x},
  urldate = {2025-01-28},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@article{kuo2016,
  title = {Application of {{Quasi-Monte Carlo Methods}} to {{Elliptic PDEs}} with {{Random Diffusion Coefficients}}: {{A Survey}} of {{Analysis}} and {{Implementation}}},
  author = {Kuo, Frances Y. and Nuyens, Dirk},
  year = {2016},
  journal = {Foundations of Computational Mathematics},
  volume = {16},
  number = {6},
  pages = {1631--1696},
  publisher = {Springer US},
  doi = {10.1007/s10208-016-9329-5},
  abstract = {This article provides a survey of recent research efforts on the application of quasi-Monte Carlo (QMC) methods to elliptic partial differential equations (PDEs) with random diffusion coefficients. It considers and contrasts the uniform case versus the lognormal case, single-level algorithms versus multi-level algorithms, first-order QMC rules versus higher-order QMC rules, and deterministic QMC methods versus randomized QMC methods. It gives a summary of the error analysis and proof techniques in a unified view, and provides a practical guide to the software for constructing and generating QMC points tailored to the PDE problems. The analysis for the uniform case can be generalized to cover a range of affine parametric operator equations.},
  keywords = {Deterministic,First order,Higher order,Infinite-dimensional integration,Lognormal,Multi-level,Partial differential equations with random coeffic,Quasi-Monte Carlo methods,Randomized,Single-level,Uniform},
  file = {/home/wouter/Zotero/storage/P8L8FZMM/Kuo, Nuyens - 2016 - Application of Quasi-Monte Carlo Methods to Elliptic PDEs with Random Diffusion Coefficients A Survey of Analysis a.pdf}
}

@article{kutyniok2022,
  title = {A {{Theoretical Analysis}} of {{Deep Neural Networks}} and {{Parametric PDEs}}},
  author = {Kutyniok, Gitta and Petersen, Philipp and Raslan, Mones and Schneider, Reinhold},
  year = {2022},
  journal = {Constructive Approximation},
  volume = {55},
  number = {1},
  pages = {73--125},
  publisher = {Springer US},
  doi = {10.1007/s00365-021-09551-4},
  abstract = {We derive upper bounds on the complexity of ReLU neural networks approximating the solution maps of parametric partial differential equations. In particular, without any knowledge of its concrete shape, we use the inherent low dimensionality of the solution manifold to obtain approximation rates which are significantly superior to those provided by classical neural network approximation results. Concretely, we use the existence of a small reduced basis to construct, for a large variety of parametric partial differential equations, neural networks that yield approximations of the parametric solution maps in such a way that the sizes of these networks essentially only depend on the size of the reduced basis.},
  keywords = {Approximation rates,Deep neural networks,Parametric PDEs,Reduced basis method},
  file = {/home/wouter/Zotero/storage/VG323MUU/Kutyniok et al. - 2022 - A Theoretical Analysis of Deep Neural Networks and Parametric PDEs.pdf}
}

@inproceedings{lackner2007,
  title = {Uncertainty Analysis in Wind Resource Assessment and Wind Energy Production Estimation},
  booktitle = {45th {{AIAA Aerospace Sciences Meeting}} and {{Exhibit}}},
  author = {Lackner, Matthew and Rogers, Anthony and Manwell, James},
  year = {2007},
  pages = {1222--1222}
}

@article{lannes2013,
  title = {The {{Dirichlet-Neumann}} Operator},
  author = {Lannes, David},
  year = {2013},
  pages = {61--89},
  doi = {10.1090/surv/188/03},
  file = {/home/wouter/Zotero/storage/C3CANXDS/Lannes - 2013 - The Dirichlet-Neumann operator.pdf}
}

@article{lantaron2021,
  title = {The Dirichlet-to-Neumann Map in a Disk with a One-Step Radial Potential: {{An}} Analytical and Numerical Study},
  author = {Lantar{\'o}n, Sagrario and Merch{\'a}n, Susana},
  year = {2021},
  journal = {Mathematics},
  volume = {9},
  number = {8},
  pages = {1--17},
  doi = {10.3390/math9080794},
  abstract = {Herein, we considered the Schr{\"o}dinger operator with a potential q on a disk and the map that associates to q the corresponding Dirichlet-to-Neumann (DtN) map. We provide some numerical and analytical results on the range of this map and its stability for the particular class of one-step radial potentials.},
  keywords = {Dirichlet-to-Neumann map,Schrodinger operator,Stability},
  file = {/home/wouter/Zotero/storage/CMLL8IJB/Lantarón, Merchán - 2021 - The dirichlet-to-neumann map in a disk with a one-step radial potential An analytical and numerical study.pdf}
}

@book{laplace1798,
  title = {Trait{\'e} de M{\'e}canique C{\'e}leste},
  author = {Laplace, Pierre S. and Gordon, Hugh and Gordon, John and {Burndy Library}},
  year = {1798},
  publisher = {De L'Imprimerie de Crapelet : Chez J.B.M. Duprat},
  address = {A Paris},
  doi = {10.5479/sil.338664.39088005644752},
  urldate = {2025-04-15},
  langid = {english}
}

@article{lara2018,
  title = {Global Optimization Algorithm for Capacitated Multi-Facility Continuous Location-Allocation Problems},
  author = {Lara, Cristiana L. and Trespalacios, Francisco and Grossmann, Ignacio E.},
  year = {2018},
  month = aug,
  journal = {Journal of Global Optimization},
  volume = {71},
  number = {4},
  pages = {871--889},
  issn = {0925-5001, 1573-2916},
  doi = {10.1007/s10898-018-0621-6},
  urldate = {2024-09-13},
  abstract = {In this paper we propose a nonlinear Generalized Disjunctive Programming model to optimize the 2-dimensional continuous location and allocation of the potential facilities based on their maximum capacity and the given coordinates of the suppliers and customers. The model belongs to the class of Capacitated Multi-facility Weber Problem. We propose a bilevel decomposition algorithm that iteratively solves a discretized MILP version of the model, and its nonconvex NLP for a fixed selection of discrete variables. Based on the bounding properties of the subproblems, -convergence is proved for this algorithm. We apply the proposed method to random instances varying from 2 suppliers and 2 customers to 40 suppliers and 40 customers, from one type of facility to 3 different types, and from 2 to 32 potential facilities. The results show that the algorithm is more effective at finding global optimal solutions than general purpose global optimization solvers tested.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/FBAS895L/Lara et al. - 2018 - Global optimization algorithm for capacitated multi-facility continuous location-allocation problems.pdf}
}

@article{larcher2003,
  title = {On the Tractability of the {{Brownian Bridge}} Algorithm},
  author = {Larcher, Gerhard and Leobacher, Gunther and Scheicher, Klaus},
  year = {2003},
  journal = {Journal of Complexity},
  volume = {19},
  number = {4},
  pages = {511--528},
  doi = {10.1016/S0885-064X(03)00045-1},
  abstract = {Recent results in the theory of quasi-Monte Carlo methods have shown that the weighted Koksma-Hlawka inequality gives better estimates for the error of quasi-Monte Carlo algorithms. We present a method for finding good weights for several classes of functions and apply it to certain algorithms using the Brownian Bridge construction, which are important for financial applications. {\copyright} 2003 Elsevier Science (USA). All rights reserved.},
  file = {/home/wouter/Zotero/storage/PWWZW39N/Larcher, Leobacher, Scheicher - 2003 - On the tractability of the Brownian Bridge algorithm.pdf}
}

@book{larson2013,
  title = {The {{Finite Element Method}}: {{Theory}}, {{Implementation}}, and {{Applications}}},
  author = {Larson, Mats G and Bengzon, Fredrik},
  year = {2013},
  pages = {726},
  isbn = {978-3-642-33286-9},
  file = {/home/wouter/Zotero/storage/ZY9ZMMCJ/Larson, Bengzon - 2013 - The Finite Element Method Theory, Implementation, and Applications.pdf}
}

@book{lax1989,
  title = {Scattering Theory},
  author = {Lax, Peter D. and Phillips, Ralph S.},
  year = {1989},
  series = {Pure and Applied Mathematics},
  edition = {Rev. ed},
  number = {v. 26},
  publisher = {Academic Press},
  address = {Boston},
  isbn = {978-0-08-087338-1},
  langid = {english},
  file = {/home/wouter/Zotero/storage/882SPHQH/(Pure and applied mathematics 26) Peter D. Lax, Ralph S. Phillips - Scattering theory-Academic Press (1989).djvu}
}

@article{lazarev2005,
  title = {Interface Dynamics in Randomly Heterogeneous Porous Media},
  author = {Lazarev, Yu N. and Petrov, P. V. and Tartakovsky, Daniel M.},
  year = {2005},
  journal = {Advances in Water Resources},
  volume = {28},
  number = {4},
  pages = {393--403},
  doi = {10.1016/j.advwatres.2004.11.003},
  abstract = {We consider the dynamics of a fluid interface in heterogeneous porous media, whose hydraulic properties are uncertain. Modeling hydraulic conductivity as a random field of given statistics allows us to predict the interface dynamics and to estimate the corresponding predictive uncertainty by means of statistical moments. The novelty of our approach to obtaining the interface statistics consists of dynamically mapping the Cartesian coordinate system onto a coordinate system associated with the moving front. This transforms a difficult problem of deriving closure relationships for highly nonlinear stochastic flows with free surfaces into a relatively simple problem of deriving stochastic closures for linear flows in domains with fixed boundaries. We derive a set of deterministic equations for the statistical moments of the interfacial dynamics, which hold in one and two spatial dimensions, and analyze their solutions for one-dimensional flow. {\copyright} 2004 Elsevier Ltd. All rights reserved.},
  keywords = {Conductivity tensor,Free surface,Moment equations,Random fluctuations,Stochastic},
  file = {/home/wouter/Zotero/storage/SBRIYKRR/Lazarev, Petrov, Tartakovsky - 2005 - Interface dynamics in randomly heterogeneous porous media.pdf}
}

@article{lazzarini1901,
  title = {Un'applicazione Del Calcolo Della Probabilit{\'a} Alla Ricerca Sperimentale Di Un Valore Approssimato Di \${$\pi\$$}},
  author = {Lazzarini, Mario},
  year = {1901},
  journal = {Periodico di Matematica},
  volume = {4},
  pages = {140--143}
}

@article{lee2007,
  title = {A Parallel Implementation of the Simplex Function Minimization Routine},
  author = {Lee, Donghoon and Wiswall, Matthew},
  year = {2007},
  journal = {Computational Economics},
  volume = {30},
  number = {2},
  pages = {171--187},
  doi = {10.1007/s10614-007-9094-2},
  abstract = {This paper generalizes the widely used Nelder and Mead (Comput J 7:308-313, 1965) simplex algorithm to parallel processors. Unlike most previous parallelization methods, which are based on parallelizing the tasks required to compute a specific objective function given a vector of parameters, our parallel simplex algorithm uses parallelization at the parameter level. Our parallel simplex algorithm assigns to each processor a separate vector of parameters corresponding to a point on a simplex. The processors then conduct the simplex search steps for an improved point, communicate the results, and a new simplex is formed. The advantage of this method is that our algorithm is generic and can be applied, without re-writing computer code, to any optimization problem which the non-parallel Nelder-Mead is applicable. The method is also easily scalable to any degree of parallelization up to the number of parameters. In a series of Monte Carlo experiments, we show that this parallel simplex method yields computational savings in some experiments up to three times the number of processors. {\copyright} Springer Science+Business Media, LLC 2007.},
  keywords = {Optimization algorithms,Parallel computing},
  file = {/home/wouter/Zotero/storage/EWDPNYIZ/Lee, Wiswall - 2007 - A parallel implementation of the simplex function minimization routine.pdf}
}

@article{lee2019,
  title = {{{PyWavelets}}: {{A Python}} Package for Wavelet Analysis},
  author = {Lee, Gregory and Gommers, Ralf and Waselewski, Filip and Wohlfahrt, Kai and O'Leary, Aaron},
  year = {2019},
  month = apr,
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {36},
  pages = {1237--1237},
  issn = {9781611970104},
  doi = {10.21105/joss.01237},
  keywords = {Education,Image processing,Open source,Python,Reproducible research,Scientific programming,Visualization},
  file = {/home/wouter/Zotero/storage/3X7MHLL4/Lee et al. - 2019 - PyWavelets A Python package for wavelet analysis.pdf}
}

@misc{leibfried2020,
  title = {A {{Tutorial}} on {{Sparse Gaussian Processes}} and {{Variational Inference}}},
  author = {Leibfried, Felix and Dutordoir, Vincent and John, {\relax ST} and Durrande, Nicolas},
  year = {2020},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2012.13962},
  urldate = {2024-09-30},
  abstract = {Gaussian processes (GPs) provide a framework for Bayesian inference that can offer principled uncertainty estimates for a large range of problems. For example, if we consider regression problems with Gaussian likelihoods, a GP model enjoys a posterior in closed form. However, identifying the posterior GP scales cubically with the number of training examples and requires to store all examples in memory. In order to overcome these obstacles, sparse GPs have been proposed that approximate the true posterior GP with pseudo-training examples. Importantly, the number of pseudo-training examples is user-defined and enables control over computational and memory complexity. In the general case, sparse GPs do not enjoy closed-form solutions and one has to resort to approximate inference. In this context, a convenient choice for approximate inference is variational inference (VI), where the problem of Bayesian inference is cast as an optimization problem -- namely, to maximize a lower bound of the log marginal likelihood. This paves the way for a powerful and versatile framework, where pseudo-training examples are treated as optimization arguments of the approximate posterior that are jointly identified together with hyperparameters of the generative model (i.e. prior and likelihood). The framework can naturally handle a wide scope of supervised learning problems, ranging from regression with heteroscedastic and non-Gaussian likelihoods to classification problems with discrete labels, but also problems with multidimensional labels. The purpose of this tutorial is to provide access to the basic matter for readers without prior knowledge in both GPs and VI. A proper exposition to the subject enables also access to more recent advances (like importance-weighted VI as well as interdomain, multioutput and deep GPs) that can serve as an inspiration for new research ideas.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/home/wouter/Zotero/storage/9IQNZVHH/Leibfried et al. - 2020 - A Tutorial on Sparse Gaussian Processes and Variational Inference.pdf}
}

@article{levitin2016,
  title = {Dirichlet-to-{{Neumann Maps}} : {{Spectral Theory}} , {{Inverse Problems}} and {{Applications}} ( 16w5083 ) {{Overview}} of the {{Field}}},
  author = {Levitin, Michael},
  year = {2016},
  pages = {1--11},
  file = {/home/wouter/Zotero/storage/I6S5EGMT/Levitin - 2016 - Dirichlet-to-Neumann Maps Spectral Theory , Inverse Problems and Applications ( 16w5083 ) Overview of the Field.pdf}
}

@article{li2001,
  title = {Moving {{Mesh Methods}} in {{Multiple Dimensions Based}} on {{Harmonic Maps}}},
  author = {Li, Ruo and Tang, Tao and Zhang, Pingwen},
  year = {2001},
  journal = {Journal of Computational Physics},
  volume = {170},
  number = {2},
  pages = {562--588},
  doi = {10.1006/jcph.2001.6749},
  abstract = {In practice, there are three types of adaptive methods using the finite element approach, namely the h-method, p-method, and r-method. In the h-method, the overall method contains two parts, a solution algorithm and a mesh selection algorithm. These two parts are independent of each other in the sense that the change of the PDEs will affect the first part only. However, in some of the existing versions of the r-method (also known as the moving mesh method), these two parts are strongly associated with each other and as a result any change of the PDEs will result in the rewriting of the whole code. In this work, we will propose a moving mesh method which also contains two parts, a solution algorithm and a mesh-redistribution algorithm. Our efforts are to keep the advantages of the r-method (e.g., keep the number of nodes unchanged) and of the h-method (e.g., the two parts in the code are independent). A framework for adaptive meshes based on the Hamilton-Schoen-Yau theory was proposed by Dvinsky. In this work, we will extend Dvinsky's method to provide an efficient solver for the mesh-redistribution algorithm. The key idea is to construct the harmonic map between the physical space and a parameter space by an iteration procedure. Each iteration step is to move the mesh closer to the harmonic map. This procedure is simple and easy to program and also enables us to keep the map harmonic even after long times of numerical integration.The numerical schemes are applied to a number of test problems in two dimensions. It is observed that the mesh-redistribution strategy based on the harmonic maps adapts the mesh extremely well to the solution without producing skew elements for multi-dimensional computations. {\copyright} 2001 Academic Press.},
  keywords = {Adaptive grids,Finite element methods,Harmonic map,Partial differential equations},
  file = {/home/wouter/Zotero/storage/TKY5CRTN/Li, Tang, Zhang - 2001 - Moving Mesh Methods in Multiple Dimensions Based on Harmonic Maps.pdf}
}

@article{li2005,
  title = {Bivariate Real-Valued Orthogonal Periodic Wavelets},
  author = {Li, Qiang and Liang, Xuezhang},
  year = {2005},
  journal = {Analysis in Theory and Applications},
  volume = {21},
  number = {3},
  pages = {266--279},
  doi = {10.1007/BF02836957},
  abstract = {In this paper, we construct a kind of bivariate real-valued orthogonal periodic wavelets. The corresponding decomposition and reconstruction algorithms involve only 8 terms respectively which are very simple in practical computation. Moreover, the relation between periodic wavelets and Fourier series is also discussed. {\copyright} 2005 Springer.},
  keywords = {Discrete fourier transform,Periodic multiresolution analysis,periodic wavelet,Two-scale dilation equation},
  file = {/home/wouter/Zotero/storage/WTCQD3TK/Li, Liang - 2005 - Bivariate real-valued orthogonal periodic wavelets.pdf}
}

@article{li2010,
  title = {Optimal a Priori Estimates for Higher Order Finite Elements for Elliptic Interface Problems},
  author = {Li, Jingzhi and Melenk, Jens Markus and Wohlmuth, Barbara and Zou, Jun},
  year = {2010},
  month = jan,
  journal = {Applied Numerical Mathematics},
  volume = {60},
  number = {1-2},
  pages = {19--37},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.apnum.2009.08.005},
  abstract = {We analyze higher order finite elements applied to second order elliptic interface problems. Our a priori error estimates in the L2- and H1-norm are expressed in terms of the approximation order p and a parameter {$\delta$} that quantifies how well the interface is resolved by the finite element mesh. The optimal p-th order convergence in the H1 ({\textohm})-norm is only achieved under stringent assumptions on {$\delta$}, namely, {$\delta$} = O (h2 p). Under weaker conditions on {$\delta$}, optimal a priori estimates can be established in the L2- and in the H1 ({\textohm}{$\delta$})-norm, where {\textohm}{$\delta$} is a subdomain that excludes a tubular neighborhood of the interface of width O ({$\delta$}). In particular, if the interface is approximated by an interpolation spline of order p and if full regularity is assumed, then optimal convergence orders p + 1 and p for the approximation in the L2 ({\textohm})- and the H1 ({\textohm}{$\delta$})-norm can be expected but not order p for the approximation in the H1 ({\textohm})-norm. Numerical examples in 2D and 3D illustrate and confirm our theoretical results. {\copyright} 2009 IMACS.},
  keywords = {A priori estimates,Elliptic interface problems,Higher order finite elements,Optimal convergence rates},
  file = {/home/wouter/Zotero/storage/HRPUZGCZ/Li et al. - 2010 - Optimal a priori estimates for higher order finite elements for elliptic interface problems.pdf}
}

@article{li2019,
  title = {Sparse Solutions in Optimal Control of {{PDEs}} with Uncertain Parameters: {{The}} Linear Case},
  author = {Li, Chen and Stadler, Georg},
  year = {2019},
  journal = {SIAM Journal on Control and Optimization},
  volume = {57},
  number = {1},
  pages = {633--658},
  doi = {10.1137/18M1181419},
  abstract = {We study sparse solutions of optimal control problems governed by PDEs with uncertain coefficients. We propose two formulations, one where the solution is a deterministic control optimizing the mean objective, and a formulation aiming at stochastic controls that share the same sparsity structure. In both formulations, regions where the controls do not vanish can be interpreted as optimal locations for placing control devices. In this paper, we focus on linear PDEs with linearly entering uncertain parameters. Under these assumptions, the deterministic formulation reduces to a problem with known structure, and thus we mainly focus on the stochastic control formulation. Here, shared sparsity is achieved by incorporating the L 1 -norm of the mean of the pointwise squared controls in the objective. We reformulate the problem using a norm reweighting function that is defined over physical space only and thus helps to avoid approximation of the random space using samples or quadrature. We show that a fixed point algorithm applied to the norm reweighting formulation leads to a variant of the well-studied iterative reweighted least squares (IRLS) algorithm, and we propose a novel preconditioned Newton-conjugate gradient method to speed up the IRLS algorithm. We combine our algorithms with low-rank operator approximations, for which we provide estimates of the truncation error. We carefully examine the computational complexity of the resulting algorithms. The sparsity structure of the optimal controls and the performance of the solution algorithms are studied numerically using control problems governed by the Laplace and Helmholtz equations. In these experiments the Newton variant clearly outperforms the IRLS method.},
  keywords = {Iterative reweighting,L 1 minimization,Newton method,Optimal control of PDEs,Sparse controls,Uncertainty},
  file = {/home/wouter/Zotero/storage/CRS22T8Z/Li, Stadler - 2019 - Sparse solutions in optimal control of PDEs with uncertain parameters The linear case.pdf}
}

@article{liang2001,
  title = {Real-Parameter Evolutionary Monte Carlo with Applications to Bayesian Mixture Models},
  author = {Liang, Faming and Wong, Wing Hung},
  year = {2001},
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {454},
  pages = {653--666},
  doi = {10.1198/016214501753168325},
  abstract = {We propose an evolutionary Monte Carlo algorithm to sample from a target distribution with real-valued parameters. The attractive features of the algorithm include the ability to learn from the samples obtained in previous steps and the ability to improve the mixing of a system by sampling along a temperature ladder. The effectiveness of the algorithm is examined through three multimodal examples and Bayesian neural networks. The numerical results confirm that the real-coded evolutionary algorithm is a promising general approach for simulation and optimization. {\copyright} 2001 American Statistical Association.},
  keywords = {Crossover,Evolutionary Monte Carlo,Exchange,Genetic algorithm,Markov chain Monte Carlo,Metropolis algorithm,Mixture model,Mutation,Neural network,Parallel tempering},
  file = {/home/wouter/Zotero/storage/AFZVE6X6/Liang, Wong - 2001 - Real-parameter evolutionary monte carlo with applications to bayesian mixture models.pdf}
}

@article{lieberman2006,
  title = {Smooth Solutions of Elliptic Equations in Nonsmooth Domains},
  author = {Lieberman, Gary M},
  year = {2006},
  journal = {Differential \& difference equations and applications},
  pages = {677--682},
  file = {/home/wouter/Zotero/storage/XY2NZFC9/Lieberman - 2006 - Smooth solutions of elliptic equations in nonsmooth domains.pdf}
}

@book{liu2001,
  title = {Monte {{Carlo}} Strategies in Scientific Computing},
  author = {Liu, Jun S and Liu, Jun S},
  year = {2001},
  volume = {10},
  publisher = {Springer}
}

@incollection{liu2012,
  title = {Hilbert {{Transform}} and {{Applications}}},
  booktitle = {Fourier {{Transform}}},
  author = {Liu, Yi-Wen},
  editor = {Salih, Salih Mohammed},
  year = {2012},
  publisher = {IntechOpen},
  address = {Rijeka},
  doi = {10.5772/37727}
}

@article{logg2010,
  title = {{{DOLFIN}}: {{Automated}} Finite Element Computing},
  author = {Logg, Anders and Wells, Garth N.},
  year = {2010},
  journal = {ACM Transactions on Mathematical Software},
  volume = {37},
  number = {2},
  doi = {10.1145/1731022.1731030},
  abstract = {We describe here a library aimed at automating the solution of partial differential equations using the finite element method. By employing novel techniques for automated code generation, the library combines a high level of expressiveness with efficient computation. Finite element variational forms may be expressed in near mathematical notation, from which low-level code is automatically generated, compiled, and seamlessly integrated with efficient implementations of computational meshes and high-performance linear algebra. Easy-to-use object-oriented interfaces to the library are provided in the form of a C++ library and a Python module. This article discusses the mathematical abstractions and methods used in the design of the library and its implementation. A number of examples are presented to demonstrate the use of the library in application code. {\copyright} 2010 ACM.},
  keywords = {Code generation,DOLFIN,FEniCS project,Form compiler},
  file = {/home/wouter/Zotero/storage/89B6PT9G/Logg, Wells - 2010 - DOLFIN Automated finite element computing.pdf}
}

@article{loghin2006,
  title = {Adaptive Preconditioners for Nonlinear Systems of Equations},
  author = {Loghin, D. and Ruiz, D. and Touhami, A.},
  year = {2006},
  journal = {Journal of Computational and Applied Mathematics},
  volume = {189},
  number = {1-2},
  pages = {362--374},
  doi = {10.1016/j.cam.2005.04.060},
  abstract = {The use of preconditioned Krylov methods is in many applications mandatory for computing efficiently the solution of large sparse nonlinear systems of equations. However, the available preconditioners are often sub-optimal, due to the changing nature of the linearized operator. In this work we introduce and analyse an adaptive preconditioning technique based on the Krylov subspace information generated at previous steps in the nonlinear iteration. In particular, we use an adaptive technique suggested in [J. Baglama, D. Calvetti, G.H. Golub, L. Reichel, Adaptively preconditioned GMRES algorithms, SIAM J. Sci. Comput. 20(1) (1998) 243-269] for restarted GMRES to enhance existing preconditioners with information available from previous stages in the nonlinear iteration. Numerical experiments drawn from domain decomposition techniques and fluid flow applications are used to validate the increased efficiency of our approach. {\copyright} 2005 Elsevier B.V. All rights reserved.},
  keywords = {Adaptive preconditioners,Augmented systems,Domain decomposition techniques,Iterative methods,Newton's method,Nonlinear systems},
  file = {/home/wouter/Zotero/storage/DL3AWMLN/Loghin, Ruiz, Touhami - 2006 - Adaptive preconditioners for nonlinear systems of equations.pdf}
}

@article{loghin2006a,
  title = {Bounds on the Eigenvalue Range and on the Field of Values of Non-{{Hermitian}} and Indefinite Finite Element Matrices},
  author = {Loghin, Daniel and {van Gijzen}, Martin and Jonkers, Eline},
  year = {2006},
  month = may,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {189},
  number = {1-2},
  pages = {304--323},
  doi = {10.1016/j.cam.2005.04.040},
  abstract = {In the early seventies, Fried formulated bounds on the spectrum of assembled Hermitian positive (semi-) definite finite element matrices using the extreme eigenvalues of the element matrices. In this paper we will generalise these results by presenting bounds on the field of values, the numerical radius and on the spectrum of general, possibly complex matrices, for both the standard and the generalised problem. The bounds are cheap to compute, involving operations with element matrices only. We illustrate our results with an example from acoustics involving a complex, non-Hermitian matrix. As an application, we show how our estimates can be used to derive an upper bound on the number of iterations needed to achieve a given residual reduction in the GMRES-algorithm for solving linear systems. {\copyright} 2005 Elsevier B.V. All rights reserved.},
  keywords = {Eigenvalue bounds,Field of values,Iterative methods,Non-Hermitian finite element matrices,Numerical radius},
  file = {/home/wouter/Zotero/storage/VVFSUZX3/Loghin, van Gijzen, Jonkers - 2006 - Bounds on the eigenvalue range and on the field of values of non-Hermitian and indefinite finite el.pdf}
}

@article{lu2021,
  title = {Learning Nonlinear Operators via {{DeepONet}} Based on the Universal Approximation Theorem of Operators},
  author = {Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George E.},
  year = {2021},
  month = mar,
  journal = {Nature Machine Intelligence},
  volume = {3},
  number = {3},
  pages = {218--229},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00302-5},
  urldate = {2025-05-01},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  langid = {english},
  file = {/home/wouter/Zotero/storage/V6JFQRXQ/Lu et al. - 2021 - Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators.pdf}
}

@article{luong2021,
  title = {Adaptive Cost-Aware {{Bayesian}} Optimization},
  author = {Luong, Phuc and Nguyen, Dang and Gupta, Sunil and Rana, Santu and Venkatesh, Svetha},
  year = {2021},
  month = nov,
  journal = {Knowledge-Based Systems},
  volume = {232},
  pages = {107481},
  issn = {09507051},
  doi = {10.1016/j.knosys.2021.107481},
  urldate = {2024-09-24},
  langid = {english},
  file = {/home/wouter/Zotero/storage/ZD92L9PZ/Luong et al. - 2021 - Adaptive cost-aware Bayesian optimization.pdf}
}

@article{lye2020,
  title = {Deep Learning Observables in Computational Fluid Dynamics},
  author = {Lye, Kjetil O. and Mishra, Siddhartha and Ray, Deep},
  year = {2020},
  journal = {Journal of Computational Physics},
  volume = {410},
  pages = {109339--109339},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jcp.2020.109339},
  abstract = {Many large scale problems in computational fluid dynamics such as uncertainty quantification, Bayesian inversion, data assimilation and PDE constrained optimization are considered very challenging computationally as they require a large number of expensive (forward) numerical solutions of the corresponding PDEs. We propose a machine learning algorithm, based on deep artificial neural networks, that predicts the underlying input parameters to observable map from a few training samples (computed realizations of this map). By a judicious combination of theoretical arguments and empirical observations, we find suitable network architectures and training hyperparameters that result in robust and efficient neural network approximations of the parameters to observable map. Numerical experiments are presented to demonstrate low prediction errors for the trained network networks, even when the network has been trained with a few samples, at a computational cost which is several orders of magnitude lower than the underlying PDE solver. Moreover, we combine the proposed deep learning algorithm with Monte Carlo (MC) and Quasi-Monte Carlo (QMC) methods to efficiently compute uncertainty propagation for nonlinear PDEs. Under the assumption that the underlying neural networks generalize well, we prove that the deep learning MC and QMC algorithms are guaranteed to be faster than the baseline (quasi-) Monte Carlo methods. Numerical experiments demonstrating one to two orders of magnitude speed up over baseline QMC and MC algorithms, for the intricate problem of computing probability distributions of the observable, are also presented.},
  keywords = {CFD,Deep learning,Neural networks,Observables,Quasi-Monte Carlo,UQ},
  file = {/home/wouter/Zotero/storage/MY65WNXL/Lye, Mishra, Ray - 2020 - Deep learning observables in computational fluid dynamics.pdf}
}

@article{madrigal-cianci2021,
  title = {Analysis of a Class of {{Multi-Level Markov Chain Monte Carlo}} Algorithms Based on {{Independent Metropolis-Hastings}}},
  author = {{Madrigal-Cianci}, Juan Pablo and Nobile, Fabio and Tempone, Raul},
  year = {2021},
  abstract = {In this work, we present, analyze, and implement a class of Multi-Level Markov chain Monte Carlo (ML-MCMC) algorithms based on independent Metropolis-Hastings proposals for Bayesian inverse problems. In this context, the likelihood function involves solving a complex differential model, which is then approximated on a sequence of increasingly accurate discretizations. The key point of this algorithm is to construct highly coupled Markov chains together with the standard Multi-level Monte Carlo argument to obtain a better cost-tolerance complexity than a single-level MCMC algorithm. Our method extends the ideas of Dodwell, et al. "A hierarchical multilevel Markov chain Monte Carlo algorithm with applications to uncertainty quantification in subsurface flow," {\textbackslash}textit\{SIAM/ASA Journal on Uncertainty Quantification 3.1 (2015): 1075-1108,\} to a wider range of proposal distributions. We present a thorough convergence analysis of the ML-MCMC method proposed, and show, in particular, that (i) under some mild conditions on the (independent) proposals and the family of posteriors, there exists a unique invariant probability measure for the coupled chains generated by our method, and (ii) that such coupled chains are uniformly ergodic. We also generalize the cost-tolerance theorem of Dodwell et al., to our wider class of ML-MCMC algorithms. Finally, we propose a self-tuning continuation-type ML-MCMC algorithm (C-ML-MCMC). The presented method is tested on an array of academic examples, where some of our theoretical results are numerically verified. These numerical experiments evidence how our extended ML-MCMC method is robust when targeting some {\textbackslash}emph\{pathological\} posteriors, for which some of the previously proposed ML-MCMC algorithms fail.},
  keywords = {35r30,60j05,60j22,62f15,62p30,65m32,ams subject classifications,bayesian inversion,markov chain monte carlo,multi-level monte carlo,tainty quantification,uncer-},
  file = {/home/wouter/Zotero/storage/IQGGJTA7/Madrigal-Cianci, Nobile, Tempone - 2021 - Analysis of a class of Multi-Level Markov Chain Monte Carlo algorithms based on Independent Me.pdf}
}

@article{magnus2010,
  title = {On the Concept of Matrix Derivative},
  author = {Magnus, Jan R.},
  year = {2010},
  journal = {Journal of Multivariate Analysis},
  volume = {101},
  number = {9},
  pages = {2200--2206},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jmva.2010.05.005},
  abstract = {We discuss how to generalize the concept of vector derivative to matrix derivative, propose two definitions, a 'broad' and a 'narrow' one, compare the two definitions, and argue in favor of the narrow definition. {\copyright} 2010 Elsevier Inc.},
  keywords = {Definitions,Matrix calculus,Matrix derivative},
  file = {/home/wouter/Zotero/storage/YX425LWA/Magnus - 2010 - On the concept of matrix derivative.pdf}
}

@book{maier2007,
  title = {Plasmonics: Fundamentals and Applications},
  shorttitle = {Plasmonics},
  author = {Maier, Stefan A.},
  year = {2007},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-33150-8 978-0-387-37825-1},
  lccn = {QC176.8.P55 M35 2007},
  keywords = {Photonics,Plasmons (Physics)},
  file = {/home/wouter/Zotero/storage/7IG2BWUG/Maier - 2007 - Plasmonics fundamentals and applications.pdf}
}

@article{mallat1989,
  title = {Multiresolution Approximations and Wavelet Orthonormal Bases of {{L2}}({{R}})},
  author = {Mallat, Stephane G.},
  year = {1989},
  journal = {Fundamental Papers in Wavelet Theory},
  volume = {315},
  number = {1},
  pages = {524--542},
  issn = {9781400827268},
  doi = {10.1090/s0002-9947-1989-1008470-5},
  abstract = {A multiresolution approximation is a sequence of embedded vector spaces (Vj)j{$E$}Z for approximating L2(R) functions. We study the properties of a multiresolution approximation and prove that it is characterized by a 2{$\pi$}-periodic function which is further described. From any multiresolution approximation, we can derive a function {$\Psi$}(x) called a wavelet such that ({\textsurd}2j{$\Psi$} (2jx - k))(k,j){$E$}Z2 is an orthonormal basis of L2(R). This provides a new approach for understanding and computing wavelet orthonormal bases. Finally, we characterize the asymptotic decay rate of multiresolution approximation errors for functions in a Sobolev space HS.},
  keywords = {Approximation theory,Orthonormal bases,Wavelets},
  file = {/home/wouter/Zotero/storage/TGM8XXXB/Mallat - 1989 - Multiresolution approximations and wavelet orthonormal bases of L2(R).pdf}
}

@article{manzhos2023,
  title = {On the Optimization of Hyperparameters in {{Gaussian}} Process Regression with the Help of Low-Order High-Dimensional Model Representation},
  author = {Manzhos, Sergei and Ihara, Manabu},
  year = {2023},
  month = jan,
  journal = {Journal of Mathematical Chemistry},
  volume = {61},
  number = {1},
  eprint = {2112.01374},
  primaryclass = {cs, math, stat},
  pages = {7--20},
  issn = {0259-9791, 1572-8897},
  doi = {10.1007/s10910-022-01407-x},
  urldate = {2024-09-02},
  abstract = {When the data are sparse, optimization of hyperparameters of the kernel in Gaussian process regression by the commonly used maximum likelihood estimation (MLE) criterion often leads to overfitting. We show that choosing hyperparameters (in this case, kernel length parameter and regularization parameter) based on a criterion of the completeness of the basis in the corresponding linear regression problem is superior to MLE. We show that this is facilitated by the use of high-dimensional model representation (HDMR) whereby a low-order HDMR representation can provide reliable reference functions and large synthetic test data sets needed for basis parameter optimization even when the original data are few.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Numerical Analysis,Statistics - Methodology},
  file = {/home/wouter/Zotero/storage/ES7SG2GI/Manzhos and Ihara - 2023 - On the optimization of hyperparameters in Gaussian process regression with the help of low-order hig.pdf;/home/wouter/Zotero/storage/RN5D93TC/2112.html}
}

@article{marchand2022,
  title = {Applying {{GMRES}} to the {{Helmholtz}} Equation with Strong Trapping: How Does the Number of Iterations Depend on the Frequency?},
  author = {Marchand, P. and Galkowski, J. and Spence, E. A. and Spence, A.},
  year = {2022},
  journal = {Advances in Computational Mathematics},
  volume = {48},
  number = {4},
  publisher = {Advances in Computational Mathematics},
  doi = {10.1007/s10444-022-09931-9},
  abstract = {We consider GMRES applied to discretisations of the high-frequency Helmholtz equation with strong trapping; recall that in this situation the problem is exponentially ill-conditioned through an increasing sequence of frequencies. Our main focus is on boundary-integral-equation formulations of the exterior Dirichlet and Neumann obstacle problems in 2- and 3-d. Under certain assumptions about the distribution of the eigenvalues of the integral operators, we prove upper bounds on how the number of GMRES iterations grows with the frequency; we then investigate numerically the sharpness (in terms of dependence on frequency) of both our bounds and various quantities entering our bounds. This paper is therefore the first comprehensive study of the frequency-dependence of the number of GMRES iterations for Helmholtz boundary-integral equations under trapping.},
  keywords = {GMRES,Helmholtz equation,High frequency,Trapping},
  file = {/home/wouter/Zotero/storage/LM5RCFF5/Marchand et al. - 2022 - Applying GMRES to the Helmholtz equation with strong trapping how does the number of iterations depend on the f.pdf}
}

@article{martins2022,
  title = {Aerodynamic Design Optimization: {{Challenges}} and Perspectives},
  author = {Martins, Joaquim R.R.A.},
  year = {2022},
  journal = {Computers and Fluids},
  volume = {239},
  number = {October 2020},
  pages = {105391--105391},
  publisher = {Elsevier Ltd},
  doi = {10.1016/j.compfluid.2022.105391},
  abstract = {Antony Jameson pioneered CFD-based aerodynamic design optimization in the late 1980s. In addition to developing the fundamental theory, Jameson implemented that theory in codes that were practical enough to be used in industry. As a result of Jameson's seminal efforts, a research community has been established in aerodynamic design optimization. This research area has experienced sustained improvements in CFD solvers, mesh deformation, sensitivity computation, and optimization tools. We review recent developments for each of these components and present open-source tools available for aerodynamic shape optimization. A variety of applications is presented, including the optimization of a supercritical airfoil starting from a circle, a web application that optimizes airfoils within a few seconds, aircraft aerodynamic and aerostructural optimization, and aeropropulsive optimization. We also review the Aerodynamic Design Optimization Discussion Group (ADODG) benchmarks and other aerodynamic shape optimization problems. Among the ADODG benchmarks, we focus on the RANS-based problems and discuss some of the issues encountered, including comparing Euler and RANS results and design-space multimodality. The availability of these benchmarks and the open-source tools is expected to enable further studies and benchmarks in CFD-based aerodynamic design optimization and MDO.},
  keywords = {Aerodynamic design optimization,Aerodynamic shape optimization,Aerostructural optimization,Airfoil optimization,Computational fluid dynamics,Wing design},
  file = {/home/wouter/Zotero/storage/PSHIKZPU/Martins - 2022 - Aerodynamic design optimization Challenges and perspectives.pdf}
}

@article{marzouk2009,
  title = {A {{Stochastic Collocation Approach}} to {{Bayesian Inference}} in {{Inverse Problems}}},
  author = {Marzouk, Youssef and Xiu, Dongbin},
  year = {2009},
  journal = {Communications in Computational Physics},
  volume = {6},
  number = {4},
  pages = {826--847},
  doi = {10.4208/cicp.2009.v6.p826},
  abstract = {We present an efficient numerical strategy for the Bayesian solution of inverse problems. Stochastic collocation methods, based on generalized polynomial chaos (gPC), are used to construct a polynomial approximation of the forward solution over the support of the prior distribution. This approximation then defines a surrogate posterior probability density that can be evaluated repeatedly at minimal computational cost. The ability to simulate a large number of samples from the posterior distribution results in very accurate estimates of the inverse solution and its associated uncertainty. Combined with high accuracy of the gPC-based forward solver, the new algorithm can provide great efficiency in practical applications. A rigorous error analysis of the algorithm is conducted, where we establish convergence of the approximate posterior to the true posterior and obtain an estimate of the convergence rate. It is proved that fast (exponential) convergence of the gPC forward solution yields similarly fast (exponential) convergence of the posterior. The numerical strategy and the predicted convergence rates are then demonstrated on nonlinear inverse problems of varying smoothness and dimension. {\copyright} 2009 Global-Science Press.},
  keywords = {Bayesian inference,Generalized polynomial chaos,Inverse problems,Stochastic collocation,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/ADZ7P2K6/Marzouk, Xiu - 2009 - A Stochastic Collocation Approach to Bayesian Inference in Inverse Problems.pdf}
}

@article{mayhickey1929,
  title = {The {{Equilibrium Point}} of {{Green}} ' s {{Function}} for an {{Annular Region}}},
  author = {May Hickey, Deborah},
  year = {1929},
  journal = {Annals of Mathematics},
  volume = {30},
  number = {1},
  pages = {373--383},
  file = {/home/wouter/Zotero/storage/6DM9S5N6/May Hickey - 1929 - The Equilibrium Point of Green ' s Function for an Annular Region.pdf}
}

@book{mclean2000,
  title = {Strongly Elliptic Systems and Boundary Integral Equations},
  author = {McLean, William Charles Hector},
  year = {2000},
  journal = {The Mathematical Gazette},
  volume = {86},
  pages = {182},
  abstract = {Partial differential equations provide mathematical models of many important problems in the physical sciences and engineering. This book treats one class of such equations, concentrating on methods involving the use of surface po-tentials. It provides the first detailed exposition of the mathematical theory of boundary integral equations of the first kind on non-smooth domains. Included are chapters on three specific examples: the Laplace equation, the Helmholtz equation and the equations of linear elasticity. The book is designed to provide an ideal preparation for studying the modern research literature on boundary element methods.},
  isbn = {0-521-66332-6},
  file = {/home/wouter/Zotero/storage/YYFEXZ2S/McLean - 2000 - Strongly elliptic systems and boundary integral equations.pdf}
}

@book{medkova2018,
  title = {The Laplace Equation: {{Boundary}} Value Problems on Bounded and Unbounded Lipschitz Domains},
  author = {Medkov{\'a}, Dagmar},
  year = {2018},
  journal = {The Laplace Equation: Boundary Value Problems on Bounded and Unbounded Lipschitz Domains},
  pages = {660},
  doi = {10.1007/978-3-319-74307-3},
  abstract = {This book is devoted to boundary value problems of the Laplace equation on bounded and unbounded Lipschitz domains. It studies the Dirichlet problem, the Neumann problem, the Robin problem, the derivative oblique problem, the transmission problem, the skip problem and mixed problems. It also examines different solutions - classical, in Sobolev spaces, in Besov spaces, in homogeneous Sobolev spaces and in the sense of non-tangential limit. It also explains relations between different solutions. The book has been written in a way that makes it as readable as possible for a wide mathematical audience, and includes all the fundamental definitions and propositions from other fields of mathematics. This book is of interest to research students, as well as experts in partial differential equations and numerical analysis.},
  isbn = {978-3-319-74307-3},
  keywords = {Derivative oblique problem,Dirichlet problem,Neumann problem,Poisson equation,Robin problem,Transmission problem},
  file = {/home/wouter/Zotero/storage/WMMBKPJJ/Medková - 2018 - The laplace equation Boundary value problems on bounded and unbounded lipschitz domains.pdf}
}

@book{meliani2022,
  title = {Analysis of {{General Shape Optimization Problems}} in {{Nonlinear Acoustics}}},
  author = {Meliani, Mostafa and Nikoli{\'c}, Vanja},
  year = {2022},
  journal = {Applied Mathematics \& Optimization},
  volume = {86},
  pages = {35},
  doi = {10.1007/s00245-022-09906-8},
  abstract = {In various biomedical applications, precise focusing of nonlinear ultrasonic waves is crucial for efficiency and safety of the involved procedures. This work analyzes a class of shape optimization problems constrained by general quasi-linear acoustic wave equations that arise in high-intensity focused ultrasound (HIFU) applications. Within our theoretical framework, the Westervelt and Kuznetsov equations of nonlinear acoustics are obtained as particular cases. The quadratic gradient nonlinearity, specific to the Kuznetsov equation, requires special attention throughout. To prove the existence of the Eulerian shape derivative, we successively study the local well-posedness and regularity of the forward problem, uniformly with respect to shape variations, and prove that it does not degenerate under the hypothesis of small initial and boundary data. Additionally, we prove H{\"o}lder-continuity of the acoustic potential with respect to domain deformations. We then derive and analyze the corresponding adjoint problems for several different cost functionals of practical interest and conclude with the expressions of well-defined shape derivatives.},
  isbn = {0-12-345678-9},
  keywords = {energy,kuznetsov,nonlinear acoustics,s equation,shape optimization},
  file = {/home/wouter/Zotero/storage/S694XHC7/Meliani, Nikolić - 2022 - Analysis of General Shape Optimization Problems in Nonlinear Acoustics.pdf}
}

@phdthesis{meliani2024,
  title = {Well-Posedness and Asymptotic Behavior of Inegro-Differential Models in Linear and Nonlinear Acoustics},
  author = {Meliani, Mostafa},
  year = {2024},
  school = {Radboud university},
  file = {/home/wouter/Zotero/storage/ZNLTM6SD/Meliani - Well-posedness and asymptotic behavior of inegro-differential models in linear and nonlinear acousti.pdf}
}

@article{metropolis1949,
  title = {The Monte Carlo Method},
  author = {Metropolis, Nicholas and Ulam, Stanislaw},
  year = {1949},
  journal = {Journal of the American statistical association},
  volume = {44},
  number = {247},
  pages = {335--341},
  publisher = {Taylor {\textbackslash}\& Francis}
}

@article{metropolis1987,
  title = {The Beginning of the {{Monte Carlo}} Method},
  author = {Metropolis, Nicholas and others},
  year = {1987},
  journal = {Los Alamos Science},
  volume = {15},
  number = {584},
  pages = {125--130}
}

@article{meyer1985,
  title = {Principe d'incertitude, Bases Hilbertiennes et Alg{\`e}bres d'op{\'e}rateurs {{S{\'e}minaire}}},
  author = {Meyer, Yves},
  year = {1985},
  journal = {Seminaire Bourbaki},
  volume = {146},
  pages = {209--223},
  file = {/home/wouter/Zotero/storage/LR25R8EI/Meyer - 1985 - Principe d’incertitude, bases hilbertiennes et algèbres d’opérateurs Séminaire.pdf}
}

@book{meyer1992,
  title = {Wavelets and Operators},
  author = {Meyer, Yves},
  year = {1992},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1090/psapm/047/1267996},
  isbn = {0-521-42000-8},
  file = {/home/wouter/Zotero/storage/MYELEWM9/Meyer - 1992 - Wavelets and operators.pdf}
}

@book{meyer1994,
  title = {Wavelets: Algorithms \& Applications},
  shorttitle = {Wavelets},
  author = {Meyer, Yves and Ryan, Robert D.},
  year = {1994},
  edition = {2. printing},
  publisher = {{SIAM, Society for Industrial and Applied Mathematics}},
  address = {Philadelphia, Pa},
  isbn = {978-0-89871-309-1},
  langid = {english},
  file = {/home/wouter/Zotero/storage/6892HKH3/Meyer et al. - 1994 - Wavelets algorithms & applications.pdf}
}

@article{mizuta1988,
  title = {On the Boundary Limits of Harmonic Functions},
  author = {Mizuta, Yoshihiro},
  year = {1988},
  journal = {Hiroshima Mathematical Journal},
  volume = {18},
  number = {1},
  pages = {207--217},
  doi = {10.32917/hmj/1206129868},
  file = {/home/wouter/Zotero/storage/D65XZAB5/Mizuta - 1988 - On the boundary limits of harmonic functions.pdf}
}

@article{moiola2014,
  title = {Is the {{Helmholtz Equation Really Sign-Indefinite}}?},
  author = {Moiola, Andrea and Spence, Euan A.},
  year = {2014},
  month = jan,
  journal = {SIAM Review},
  volume = {56},
  number = {2},
  pages = {274--312},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/120901301},
  urldate = {2025-02-04},
  langid = {english},
  file = {/home/wouter/Zotero/storage/QGAEV6X2/Moiola and Spence - 2014 - Is the Helmholtz Equation Really Sign-Indefinite.pdf}
}

@article{moiola2019,
  title = {Acoustic Transmission Problems: {{Wavenumber-explicit}} Bounds and Resonance-Free Regions},
  author = {Moiola, Andrea and Spence, Euan A.},
  year = {2019},
  month = feb,
  journal = {Mathematical Models and Methods in Applied Sciences},
  volume = {29},
  number = {02},
  pages = {317--354},
  doi = {10.1142/S0218202519500106},
  abstract = {We consider the Helmholtz transmission problem with one penetrable star-shaped Lipschitz obstacle. Under a natural assumption about the ratio of the wavenumbers, we prove bounds on the solution in terms of the data, with these bounds explicit in all parameters. In particular, the (weighted) [Formula: see text] norm of the solution is bounded by the [Formula: see text] norm of the source term, independently of the wavenumber. These bounds then imply the existence of a resonance-free strip beneath the real axis. The main novelty is that the only comparable results currently in the literature are for smooth, convex obstacles with strictly positive curvature, while here we assume only Lipschitz regularity and star-shapedness with respect to a point. Furthermore, our bounds are obtained using identities first introduced by Morawetz (essentially integration by parts), whereas the existing bounds use the much-more sophisticated technology of microlocal analysis and propagation of singularities. We also adapt existing results to show that if the assumption on the wavenumbers is lifted, then no bound with polynomial dependence on the wavenumber is possible.},
  keywords = {acoustic,frequency explicit,Helmholtz equation,Lipschitz domain,Morawetz identity,resonance,semiclassical,Transmission problem,wavenumber explicit},
  file = {/home/wouter/Zotero/storage/H3IYN77J/Moiola, Spence - 2019 - Acoustic transmission problems Wavenumber-explicit bounds and resonance-free regions.pdf}
}

@article{moriconi2020,
  title = {High-Dimensional {{Bayesian}} Optimization Using Low-Dimensional Feature Spaces},
  author = {Moriconi, Riccardo and Deisenroth, Marc Peter and Sesh Kumar, K. S.},
  year = {2020},
  month = sep,
  journal = {Machine Learning},
  volume = {109},
  number = {9-10},
  pages = {1925--1943},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-020-05899-z},
  urldate = {2024-09-24},
  abstract = {Abstract             Bayesian optimization (BO) is a powerful approach for seeking the global optimum of expensive black-box functions and has proven successful for fine tuning hyper-parameters of machine learning models. However, BO is practically limited to optimizing 10--20 parameters. To scale BO to high dimensions, we usually make structural assumptions on the decomposition of the objective and/or exploit the intrinsic lower dimensionality of the problem, e.g. by using linear projections. We could achieve a higher compression rate with nonlinear projections, but learning these nonlinear embeddings typically requires much data. This contradicts the BO objective of a relatively small evaluation budget. To address this challenge, we propose to learn a low-dimensional feature space jointly with (a) the response surface and (b) a reconstruction mapping. Our approach allows for optimization of BO's acquisition function in the lower-dimensional subspace, which significantly simplifies the optimization problem. We reconstruct the original parameter space from the lower-dimensional subspace for evaluating the black-box function. For meaningful exploration, we solve a constrained optimization problem.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/N5MEDXVH/Moriconi et al. - 2020 - High-dimensional Bayesian optimization using low-dimensional feature spaces.pdf}
}

@article{motamed2013,
  title = {A Stochastic Collocation Method for the Second Order Wave Equation with a Discontinuous Random Speed},
  author = {Motamed, Mohammad and Nobile, Fabio and Tempone, Ra{\'u}l},
  year = {2013},
  journal = {Numerische Mathematik},
  volume = {123},
  pages = {493--536},
  publisher = {Springer}
}

@article{moustapha2023,
  title = {Learning Non-Stationary and Discontinuous Functions Using Clustering, Classification and {{Gaussian}} Process Modelling},
  author = {Moustapha, Maliki and Sudret, Bruno},
  year = {2023},
  month = jun,
  journal = {Computers \& Structures},
  volume = {281},
  pages = {107035},
  issn = {00457949},
  doi = {10.1016/j.compstruc.2023.107035},
  urldate = {2024-10-25},
  langid = {english},
  file = {/home/wouter/Zotero/storage/WD3JIUXF/Moustapha and Sudret - 2023 - Learning non-stationary and discontinuous functions using clustering, classification and Gaussian pr.pdf}
}

@article{multerer2019,
  title = {A Note on the Domain Mapping Method with Rough Diffusion Coefficients},
  author = {Multerer, Michael D.},
  year = {2019},
  month = nov,
  journal = {Applied Numerical Mathematics},
  volume = {145},
  pages = {283--296},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.apnum.2019.06.013},
  abstract = {In this article, we consider elliptic diffusion problems on random domains with non-smooth diffusion coefficients. We start by illustrating the problems that arise from a non-smooth diffusion coefficient by recapitulating the corresponding regularity analysis. Then, we propose an alternative approach to address this problem by means of a perturbation method. Based on the assumption that the diffusion coefficient can be decomposed into a possibly deterministic, analytic part and a rough random perturbation, we derive approximation results in terms of the perturbations amplitude for the approximation of quantities of interest of the solution. Numerical examples are given in order to validate and quantify the theoretical results.},
  keywords = {Domain mapping method,Parametric PDE,Perturbation method,Random domain},
  file = {/home/wouter/Zotero/storage/NE8B992L/Multerer - 2019 - A note on the domain mapping method with rough diffusion coefficients.pdf}
}

@article{narayan2014,
  title = {Adaptive {{Leja}} Sparse Grid Constructions for Stochastic Collocation and High-Dimensional Approximation},
  author = {Narayan, Akil and Jakeman, John D.},
  year = {2014},
  journal = {SIAM Journal on Scientific Computing},
  volume = {36},
  number = {6},
  pages = {A2952-A2983},
  doi = {10.1137/140966368},
  abstract = {We propose an adaptive sparse grid stochastic collocation approach based upon Leja interpolation sequences for approximation of parameterized functions with high-dimensional parameters. Leja sequences are arbitrarily granular (any number of nodes may be added to a current sequence, producing a new sequence) and thus are a good choice for the univariate composite rule used to construct adaptive sparse grids in high dimensions. When undertaking stochastic collocation one is often interested in constructing weighted approximation where the weights are determined by the probability densities of the random variables. This paper establishes that a certain weighted formulation of one-dimensional Leja sequences produces a sequence of nodes whose empirical distribution converges to the corresponding limiting distribution of the Gauss quadrature nodes associated with the weight function. This property is true even for unbounded domains. We apply the Leja sparse grid approach to several high-dimensional problems and demonstrate that Leja sequences are often superior to more standard sparse grid constructions (e.g., Clenshaw-Curtis), at least for interpolatory metrics.},
  keywords = {Leja sequences,Sparse grids,Stochastic collocation},
  file = {/home/wouter/Zotero/storage/QE8QE73F/Narayan, Jakeman - 2014 - Adaptive Leja sparse grid constructions for stochastic collocation and high-dimensional approximation.pdf}
}

@article{nataf2013,
  title = {Absorbing Boundary Conditions and Perfectly Matched Layers in Wave Propagation Problems},
  author = {Nataf, Fr{\'e}d{\'e}ric},
  year = {2013},
  journal = {Direct and Inverse Problems in Wave Propagation and Applications},
  pages = {219--232},
  issn = {9783110282283},
  doi = {10.1515/9783110282283.219},
  abstract = {In this article we discuss different techniques to solve numerically wave propagation phenomena in unbounded domains. We present in a unified and simple way the two ways to restrict the computation to a finite domain: absorbing (or artificial) boundary conditions (ABC) and perfectly matched layers (PML). The intent is to give the possibility to the reader to grasp easily similarities and differences between these two truncation techniques. It should also allow the reader to adapt a truncation technique to the peculiarities of his physical modeling.},
  keywords = {35l05,65mxx,ams classification,artificial boundary condition,perfectly matched layer},
  file = {/home/wouter/Zotero/storage/KZUDFISW/Nataf - 2013 - Absorbing boundary conditions and perfectly matched layers in wave propagation problems.pdf}
}

@article{natalini2008,
  title = {The {{Dirichlet}} Problem for the {{Laplace}} Equation in a Starlike Domain of a {{Riemann}} Surface},
  author = {Natalini, Pierpaolo and Patrizi, Roberto and Ricci, Paolo E.},
  year = {2008},
  month = dec,
  journal = {Numerical Algorithms},
  volume = {49},
  number = {1-4},
  pages = {299--313},
  doi = {10.1007/s11075-008-9201-z},
  abstract = {We consider the Dirichlet problem for the Laplace equation in a starlike domain, i.e. a domain which is normal with respect to a suitable polar co-ordinates system. Such a domain can be interpreted as a non-isotropically stretched unit circle. We write down the explicit solution in terms of a Fourier series whose coefficients are determined by solving an infinite system of linear equations depending on the boundary data. Numerical experiments show that the same method works even if the considered starlike domain belongs to a two-fold Riemann surface. {\copyright} 2008 Springer Science+Business Media, LLC.},
  keywords = {Dirichlet problem,Laplace equation},
  file = {/home/wouter/Zotero/storage/KU7Q33TN/Natalini, Patrizi, Ricci - 2008 - The Dirichlet problem for the Laplace equation in a starlike domain of a Riemann surface.pdf}
}

@misc{neal1997,
  title = {Monte {{Carlo Implementation}} of {{Gaussian Process Models}} for {{Bayesian Regression}} and {{Classification}}},
  author = {Neal, Radford M.},
  year = {1997},
  publisher = {arXiv},
  urldate = {2025-01-09},
  abstract = {Gaussian processes are a natural way of defining prior distributions over functions of one or more input variables. In a simple nonparametric regression problem, where such a function gives the mean of a Gaussian distribution for an observed response, a Gaussian process model can easily be implemented using matrix computations that are feasible for datasets of up to about a thousand cases. Hyperparameters that define the covariance function of the Gaussian process can be sampled using Markov chain methods. Regression models where the noise has a t distribution and logistic or probit models for classification applications can be implemented by sampling as well for latent values underlying the observations. Software is now available that implements these methods using covariance functions with hierarchical parameterizations. Models defined in this way can discover high-level properties of the data, such as which inputs are relevant to predicting the response.},
  keywords = {Physics - Data Analysis Statistics and Probability},
  file = {/home/wouter/Zotero/storage/JNICCCND/Neal - 1997 - Monte Carlo Implementation of Gaussian Process Models for Bayesian Regression and Classification.pdf;/home/wouter/Zotero/storage/LSMYT27X/9701026.html}
}

@book{nedelec2001,
  title = {Acoustic and {{Electromagnetic Equations}}},
  author = {N{\'e}d{\'e}lec, Jean-Claude},
  year = {2001},
  series = {Applied {{Mathematical Sciences}}},
  volume = {144},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4757-4393-7},
  urldate = {2025-03-19},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-1-4419-2889-4 978-1-4757-4393-7},
  file = {/home/wouter/Zotero/storage/M9EUEIAH/Nédélec - 2001 - Acoustic and Electromagnetic Equations.pdf}
}

@article{nicholls2006,
  title = {Error Analysis of an Enhanced {{DtN-FE}} Method for Exterior Scattering Problems},
  author = {Nicholls, David P. and Nigam, Nilima},
  year = {2006},
  journal = {Numerische Mathematik},
  volume = {105},
  number = {2},
  pages = {267--298},
  doi = {10.1007/s00211-006-0040-3},
  abstract = {In this work we analyze the convergence of the high-order Enhanced DtN-FEM algorithm, described in our previous work (Nicholls and Nigam, J. Comput. Phys. 194:278-303, 2004), for solving exterior acoustic scattering problems in R 2. This algorithm consists of using an exact Dirichlet-to-Neumann (DtN) map on a hypersurface enclosing the scatterer, where the hypersurface is a perturbation of a circle, and, in practice, the perturbation can be very large. Our theoretical work had shown the DtN map was analytic as a function of this perturbation. In the present work, we carefully analyze the error introduced by virtue of using this algorithm. Specifically, we give a full account of the error introduced by truncating the DtN map at a finite order in the perturbation expansion, and study the well-posedness of the associated formulation. During computation, the Fourier series of the Dirichlet data on the artificial boundary must be truncated. To deal with the ensuing loss of uniqueness of solutions, we propose a modified DtN map, and prove well-posedness of the resulting problem. We quantify the spectral error introduced due to this truncation of the data. The key tools in the analysis include a new theorem on the analyticity of the DtN map in a suitable Sobolev space, and another on the perturbation of non-self-adjoint Fredholm operators. {\copyright} Springer-Verlag 2006.},
  file = {/home/wouter/Zotero/storage/S3X67BU6/Nicholls, Nigam - 2006 - Error analysis of an enhanced DtN-FE method for exterior scattering problems.pdf}
}

@article{nobile2008,
  title = {An Anisotropic Sparse Grid Stochastic Collocation Method for Partial Differential Equations with Random Input Data},
  author = {Nobile, F. and Tempone, R. and Webster, C. G.},
  year = {2008},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {46},
  number = {5},
  pages = {2411--2442},
  doi = {10.1137/070680540},
  abstract = {This work proposes and analyzes an anisotropic sparse grid stochastic collocation method for solving partial differential equations with random coefficients and forcing terms (input data of the model). The method consists of a Galerkin approximation in the space variables and a collocation, in probability space, on sparse tensor product grids utilizing either Clenshaw-Curtis or Gaussian knots. Even in the presence of nonlinearities, the collocation approach leads to the solution of uncoupled deterministic problems, just as in the Monte Carlo method. This work includes a priori and a posteriori procedures to adapt the anisotropy of the sparse grids to each given problem. These procedures seem to be very effective for the problems under study. The proposed method combines the advantages of Isotropic sparse collocation with those of anisotropic full tensor product collocation: the first approach is effective for problems depending on random variables which weigh approximately equally in the solution, while the benefits of the latter approach become apparent when solving highly anisotropic problems depending on a relatively small number of random variables, as in the case where input random variables are Karhunen-Lo{\`e}ve truncations of "smooth" random fields. This work also provides a rigorous convergence analysis of the fully discrete problem and demonstrates (sub)exponential convergence in the asymptotic regime and algebraic convergence in the preasymptotic regime, with respect to the total number of collocation points. It also shows that the anisotropic approximation breaks the curse of dimensionality for a wide set of problems. Numerical examples illustrate the theoretical results and are used to compare this approach with several others, including the standard Monte Carlo. In particular, for moderately large-dimensional problems, the sparse grid approach with a properly chosen anisotropy seems to be very efficient and superior to all examined methods. {\copyright} 2008 Society for Industrial and Applied Mathematics.},
  keywords = {Anisotropic sparse grids,Collocation techniques,Differential equations,Finite elements,Multivariate polynomial approximation,PDEs with random data,Smolyak sparse approximation,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/845ENQSC/Nobile, Tempone, Webster - 2008 - An anisotropic sparse grid stochastic collocation method for partial differential equations with rando.pdf}
}

@article{nobile2015,
  title = {Comparison of Clenshaw--Curtis and Leja Quasi-Optimal Sparse Grids for the Approximation of Random {{PDEs}}},
  author = {Nobile, Fabio and Tamellini, Lorenzo and Tempone, Raul},
  year = {2015},
  journal = {Lecture Notes in Computational Science and Engineering},
  volume = {106},
  number = {41},
  pages = {475--482},
  issn = {9783319197999},
  doi = {10.1007/978-3-319-19800-2_44},
  abstract = {In this work we compare different families of nested quadrature points, i. e. the classic Clenshaw--Curtis and various kinds of Leja points, in the context of the quasi-optimal sparse grid approximation of random elliptic PDEs. Numerical evidence suggests that both families perform comparably within such framework.},
  file = {/home/wouter/Zotero/storage/82RBGUFX/Nobile, Tamellini, Tempone - 2015 - Comparison of clenshaw–curtis and leja quasi-optimal sparse grids for the approximation of random.pdf}
}

@article{nobile2016,
  title = {An Adaptive Sparse Grid Algorithm for Elliptic {{PDEs}} with Lognormal Diffusion Coefficient},
  author = {Nobile, Fabio and Tamellini, Lorenzo and Tesei, Francesco and Tempone, Ra{\'u}l},
  year = {2016},
  journal = {Lecture Notes in Computational Science and Engineering},
  volume = {109},
  number = {04},
  pages = {191--220},
  issn = {9783319282602},
  doi = {10.1007/978-3-319-28262-6_8},
  abstract = {In this work we build on the classical adaptive sparse grid algorithm (T. Gerstner and M. Griebel, Dimension-adaptive tensor-product quadrature), obtaining an enhanced version capable of using non-nested collocation points, and supporting quadrature and interpolation on unbounded sets. We also consider several profit indicators that are suitable to drive the adaptation process. We then use such algorithm to solve an important test case in Uncertainty Quantification problem, namely the Darcy equation with lognormal permeability random field, and compare the results with those obtained with the quasi-optimal sparse grids based on profit estimates, which we have proposed in our previous works (cf. e.g. Convergence of quasi-optimal sparse grids approximation of Hilbert-valued functions: application to random elliptic PDEs). To treat the case of rough permeability fields, in which a sparse grid approach may not be suitable, we propose to use the adaptive sparse grid quadrature as a control variate in a Monte Carlo simulation. Numerical results show that the adaptive sparse grids have performances similar to those of the quasi-optimal sparse grids and are very effective in the case of smooth permeability fields. Moreover, their use as control variate in a Monte Carlo simulation allows to tackle efficiently also problems with rough coefficients, significantly improving the performances of a standard Monte Carlo scheme.},
  file = {/home/wouter/Zotero/storage/98J6CQHK/Nobile et al. - 2016 - An adaptive sparse grid algorithm for elliptic PDEs with lognormal diffusion coefficient.pdf}
}

@article{nobile2023,
  title = {Preconditioners for Robust Optimal Control Problems under Uncertainty},
  author = {Nobile, Fabio and Vanzan, Tommaso},
  year = {2023},
  month = mar,
  journal = {Numerical Linear Algebra with Applications},
  volume = {30},
  number = {2},
  pages = {1--30},
  doi = {10.1002/nla.2472},
  abstract = {The discretization of robust quadratic optimal control problems under uncertainty using the finite element method and the stochastic collocation method leads to large saddle-point systems, which are fully coupled across the random realizations. Despite its relevance for numerous engineering problems, the solution of such systems is notoriously challenging. In this manuscript, we study efficient preconditioners for all-at-once approaches using both an algebraic and an operator preconditioning framework. We show in particular that for values of the regularization parameter not too small, the saddle-point system can be efficiently solved by preconditioning in parallel all the state and adjoint equations. For small values of the regularization parameter, robustness can be recovered by the additional solution of a small linear system, which however couples all realizations. A mean approximation and a Chebyshev semi-iterative method are proposed to solve this reduced system. We consider a random elliptic partial differential equation whose diffusion coefficient is modeled as an almost surely continuous and positive random field, though not necessarily uniformly bounded and coercive. We further provide estimates of the dependence of the spectrum of the preconditioned system matrix on the statistical properties of the random field and on the discretization of the probability space. Such estimates involve either the first or second moment of the random variables and , where is the spatial domain. The theoretical results are confirmed by numerical experiments, and implementation details are further addressed.},
  keywords = {lognormal fields,optimal control problems under uncertainty,parameter robust preconditioners,random PDE},
  file = {/home/wouter/Zotero/storage/62S2M6RH/Nobile, Vanzan - 2023 - Preconditioners for robust optimal control problems under uncertainty.pdf}
}

@book{nocedal1996,
  title = {Numerical {{Optimization Second Edition}}},
  author = {Nocedal, Jorge and Wright, Stephen},
  year = {1996},
  journal = {Ear and Hearing},
  volume = {17},
  pages = {123},
  abstract = {Objective: Establish the test-retest reliability of loudness scaling using a bounded category rating method. Design: The individual loudness functions were investigated in three groups of listeners: seven normal-hearing listeners aged 18 to 35 yr, five normal-hearing listeners aged 57 to 84 yr, and five listeners aged 54 to 82 yr with bilateral sloping sensorineural hearing loss. Test-retest reliability was investigated by determining the intralistener, between-session standard deviation. Results: The pattern of test-retest reliability was similar across all three groups. It improved as the intensity of the stimulus increased: 7 dB at the first quartile of the loudness function, and 3 dB at the third quartile. Two to four runs of the task appear to be sufficient to obtain a stable loudness function, and it was shown that an exponential function provided a better goodness of fit than a linear function (r2: 0.99 compared with 0.94). Conclusions: Loudness scaling is a longer test than most conventional suprathreshold measures and requires special equipment. However, it has good test-retest reliability and provides more information on the loudness function that might be useful in the fitting of nonlinear hearing aids. The data show that an exponential function provides a good fit to the loudness growth data, and should probably be incorporated into fitting algorithms associated with loudness scaling.},
  isbn = {0-387-30303-0},
  file = {/home/wouter/Zotero/storage/7R6MF8DT/Nocedal, Wright - 1996 - Numerical Optimization Second Edition.pdf}
}

@article{normankatz2010,
  title = {A {{Weiszfeld}} Algorithm for the Solution of an Asymmetric Extension of the Generalized {{Fermat}} Location Problem},
  author = {Norman Katz, I. and Vogl, Steven R.},
  year = {2010},
  month = jan,
  journal = {Computers \& Mathematics with Applications},
  volume = {59},
  number = {1},
  pages = {399--410},
  issn = {08981221},
  doi = {10.1016/j.camwa.2009.07.007},
  urldate = {2024-10-02},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/LNXKMUPI/Norman Katz and Vogl - 2010 - A Weiszfeld algorithm for the solution of an asymmetric extension of the generalized Fermat location.pdf}
}

@article{nouy2007,
  title = {X-{{SFEM}}, a Computational Technique Based on {{X-FEM}} to Deal with Random Shapes},
  author = {Nouy, Anthony and Schoefs, Franck and Mo{\"e}s, Nicolas},
  year = {2007},
  month = jan,
  journal = {European Journal of Computational Mechanics},
  volume = {16},
  number = {2},
  pages = {277--293},
  doi = {10.3166/remn.16.277-293},
  file = {/home/wouter/Zotero/storage/KUHVGFB5/Nouy, Schoefs, Moës - 2007 - X-SFEM, a computational technique based on X-FEM to deal with random shapes.pdf}
}

@article{nouy2008,
  title = {An Extended Stochastic Finite Element Method for Solving Stochastic Partial Differential Equations on Random Domains},
  author = {Nouy, Anthony and Cl{\'e}ment, Alexandre and Schoefs, Franck and Mo{\"e}s, Nicolas},
  year = {2008},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {197},
  number = {51-52},
  pages = {4663--4682},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.cma.2008.06.010},
  abstract = {Recently, a new strategy was proposed to solve stochastic partial differential equations on random domains. It is based on the extension to the stochastic framework of the extended finite element method (X-FEM). This method leads by a "direct" calculus to an explicit solution in terms of the variables describing the randomness on the geometry. It relies on two major points: the implicit representation of complex geometries using random level-set functions and the use of a Galerkin approximation at both stochastic and deterministic levels. In this article, we detail the basis of this technique, from theoretical and technical points of view. Several numerical examples illustrate the efficiency of this method and compare it to other approaches. {\copyright} 2008 Elsevier B.V. All rights reserved.},
  keywords = {Computational stochastic mechanics,Extended finite element method,Polynomial chaos,Random domain,Stochastic finite element,Stochastic partial differential equations},
  file = {/home/wouter/Zotero/storage/CHMXPQRC/Nouy et al. - 2008 - An extended stochastic finite element method for solving stochastic partial differential equations on random domain.pdf}
}

@article{nuyens2006,
  title = {Fast Algorithms for Component-by-Component Construction of Rank-1 Lattice Rules in Shift-Invariant Reproducing Kernel {{Hilbert}} Spaces},
  author = {Nuyens, Dirk and Cools, Ronald},
  year = {2006},
  month = jan,
  journal = {Mathematics of Computation},
  volume = {75},
  number = {254},
  pages = {903--920},
  doi = {10.1090/s0025-5718-06-01785-6},
  abstract = {We reformulate the original component-by-component algorithm for rank- 1 1 lattices in a matrix-vector notation so as to highlight its structural properties. For function spaces similar to a weighted Korobov space, we derive a technique which has construction cost O ( s n log ⁡ ( n ) ) O(s n {\textbackslash}log (n)) , in contrast with the original algorithm which has construction cost O ( s n 2 ) O(s n{\textasciicircum}2) . Herein s s is the number of dimensions and n n the number of points (taken prime). In contrast to other approaches to speed up construction, our fast algorithm computes exactly the same quantity as the original algorithm. The presented algorithm can also be used to construct randomly shifted lattice rules in weighted Sobolev spaces.},
  keywords = {and phrases,component-by-component construction,fast algorithms,k,leuven,monte carlo,numerical integration,of a project financially,quasi,rank-1 lattice rules,research fund k,supported by the onderzoeksfonds,this research is part,u},
  file = {/home/wouter/Zotero/storage/A4AFM4ME/Nuyens, Cools - 2006 - Fast algorithms for component-by-component construction of rank-1 lattice rules in shift-invariant reproducing ke.pdf}
}

@article{nuyens2014,
  title = {The Construction of Good Lattice Rules and Polynomial Lattice Rules},
  author = {Nuyens, Dirk},
  year = {2014},
  journal = {Uniform Distribution and Quasi-Monte Carlo Methods},
  pages = {223--256},
  doi = {10.1515/9783110317930.223},
  abstract = {A comprehensive overview of lattice rules and polynomial lattice rules is given for function spaces based on \${\textbackslash}ell\_p\$ semi-norms. Good lattice rules and polynomial lattice rules are defined as those obtaining worst-case errors bounded by the optimal rate of convergence for the function space. The focus is on algebraic rates of convergence \$O(N{\textasciicircum}\{-{\textbackslash}alpha+{\textbackslash}epsilon\})\$ for \${\textbackslash}alpha {\textbackslash}ge 1\$ and any \${\textbackslash}epsilon {$>$} 0\$, where \${\textbackslash}alpha\$ is the decay of a series representation of the integrand function. The dependence of the implied constant on the dimension can be controlled by weights which determine the influence of the different dimensions. Different types of weights are discussed. The construction of good lattice rules, and polynomial lattice rules, can be done using the same method for all \$1 {$<$} p {\textbackslash}le {\textbackslash}infty\$; but the case \$p=1\$ is special from the construction point of view. For \$1 {$<$} p {\textbackslash}le {\textbackslash}infty\$ the component-by-component construction and its fast algorithm for different weighted function spaces is then discussed.},
  file = {/home/wouter/Zotero/storage/RZVQ263Z/Nuyens - 2014 - The construction of good lattice rules and polynomial lattice rules.pdf}
}

@article{nychka2018,
  title = {Modeling and Emulation of Nonstationary {{Gaussian}} Fields},
  author = {Nychka, Douglas and Hammerling, Dorit and Krock, Mitchell and Wiens, Ashton},
  year = {2018},
  month = dec,
  journal = {Spatial Statistics},
  volume = {28},
  pages = {21--38},
  issn = {22116753},
  doi = {10.1016/j.spasta.2018.08.006},
  urldate = {2024-10-29},
  langid = {english},
  file = {/home/wouter/Zotero/storage/4SKZA4E4/Nychka et al. - 2018 - Modeling and emulation of nonstationary Gaussian fields.pdf}
}

@article{oberai1998,
  title = {On the Implementation of the {{Dirichlet-to-Neumann}} Radiation Condition for Iterative Solution of the {{Helmholtz}} Equation},
  author = {Oberai, Assad A. and Malhotra, Manish and Pinsky, Peter M.},
  year = {1998},
  journal = {Applied Numerical Mathematics},
  volume = {27},
  number = {4},
  pages = {443--464},
  doi = {10.1016/S0168-9274(98)00024-5},
  abstract = {The Helmholtz equation posed on an unbounded domain with the Sommerfeld condition prescribed at infinity is considered. The unbounded domain is eliminated by imposing a Dirichlet-to-Neumann (DtN) map or a modified DtN map on a truncating surface and the resulting bounded domain problem is modeled using the finite element method. The resulting system of linear equations is then solved using a Krylov subspace iterative method. New, efficient algorithms to compute matrix-vector products that are based on the structure of the DtN and the modified DtN map are presented. Connections between the DtN map and the discrete Fourier transform in two dimensions and discrete spherical transform in three dimensions are established, and are utilized to develop fast implementations of matrix-vector product algorithms. Also, an SSOR-type preconditioner that is based on a local radiation condition is considered for the modified DtN formulation. An efficient implementation is proposed by extending Eisenstat's trick for the standard SSOR preconditioner. Finally, numerical examples which illustrate the efficacy of the proposed algorithms are presented. {\copyright} 1998 Elsevier Science B.V. and IMACS. All rights reserved.},
  file = {/home/wouter/Zotero/storage/UNW4IUL6/Oberai, Malhotra, Pinsky - 1998 - On the implementation of the Dirichlet-to-Neumann radiation condition for iterative solution of the He.pdf}
}

@misc{oh2019,
  title = {{{BOCK}} : {{Bayesian Optimization}} with {{Cylindrical Kernels}}},
  shorttitle = {{{BOCK}}},
  author = {Oh, ChangYong and Gavves, Efstratios and Welling, Max},
  year = {2019},
  month = oct,
  number = {arXiv:1806.01619},
  eprint = {1806.01619},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2024-10-25},
  abstract = {A major challenge in Bayesian Optimization is the boundary issue (Swersky, 2017) where an algorithm spends too many evaluations near the boundary of its search space. In this paper, we propose BOCK, Bayesian Optimization with Cylindrical Kernels, whose basic idea is to transform the ball geometry of the search space using a cylindrical transformation. Because of the transformed geometry, the Gaussian Process-based surrogate model spends less budget searching near the boundary, while concentrating its efforts relatively more near the center of the search region, where we expect the solution to be located. We evaluate BOCK extensively, showing that it is not only more accurate and efficient, but it also scales successfully to problems with a dimensionality as high as 500. We show that the better accuracy and scalability of BOCK even allows optimizing modestly sized neural network layers, as well as neural network hyperparameters.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/E539T342/Oh et al. - 2019 - BOCK  Bayesian Optimization with Cylindrical Kernels.pdf;/home/wouter/Zotero/storage/Z5EITZSF/1806.html}
}

@article{olofsson2020,
  title = {Lipschitz Continuity for Weighted Harmonic Functions in the Unit Disc},
  author = {Olofsson, Anders},
  year = {2020},
  journal = {Complex Variables and Elliptic Equations},
  volume = {65},
  number = {10},
  pages = {1630--1660},
  publisher = {Taylor \& Francis},
  doi = {10.1080/17476933.2019.1669572},
  abstract = {We study membership in Lipschitz classes (Formula presented.) for a class of {$\alpha$}-harmonic functions in the open unit disc (Formula presented.) in the complex plane. From earlier work by Olofsson and Wittsten we know that such an {$\alpha$}-harmonic function u is the {$\alpha$}-harmonic Poisson integral (Formula presented.) of its boundary value function f on the unit circle (Formula presented.). We determine when the Poisson integral (Formula presented.) belongs to a Lipschitz class (Formula presented.) for the unit disc.},
  keywords = {Fourier multiplier,harmonic function,Lipschitz continuity,Poisson integral,Primary: 31A05,Secondary: 35J25},
  file = {/home/wouter/Zotero/storage/VSV77CFK/Olofsson - 2020 - Lipschitz continuity for weighted harmonic functions in the unit disc.pdf}
}

@article{onyshkevych2021,
  title = {Mesh {{Quality Preserving Shape Optimization Using Nonlinear Extension Operators}}},
  author = {Onyshkevych, Sofiya and Siebenborn, Martin},
  year = {2021},
  month = apr,
  journal = {Journal of Optimization Theory and Applications},
  volume = {189},
  number = {1},
  pages = {291--316},
  doi = {10.1007/s10957-021-01837-8},
  abstract = {In this article, we propose a shape optimization algorithm which is able to handle large deformations while maintaining a high level of mesh quality. Based on the method of mappings, we introduce a nonlinear extension operator, which links a boundary control to domain deformations, ensuring admissibility of resulting shapes. The major focus is on comparisons between well-established approaches involving linear-elliptic operators for the extension and the effect of additional nonlinear advection on the set of reachable shapes. It is moreover discussed how the computational complexity of the proposed algorithm can be reduced. The benefit of the nonlinearity in the extension operator is substantiated by several numerical test cases of stationary, incompressible Navier--Stokes flows in 2d and 3d.},
  file = {/home/wouter/Zotero/storage/W959Z79Q/Haubner, Siebenborn, Ulbrich - 2021 - A Continuous Perspective on Shape Optimization via Domain Transformations.pdf}
}

@article{oosterlee2010,
  title = {Shifted-Laplacian Preconditioners for Heterogeneous Helmholtz Problems},
  author = {Oosterlee, C. W. and Vuik, C. and Mulder, W. A. and Plessix, R. E.},
  year = {2010},
  journal = {Lecture Notes in Electrical Engineering},
  volume = {71 LNCSE},
  pages = {21--46},
  issn = {9783642033438},
  doi = {10.1007/978-3-642-03344-5-2},
  abstract = {We present an iterative solution method for the discrete high wavenumber Helmholtz equation. The basic idea of the solution method, already presented in [18], is to develop a preconditioner which is based on a Helmholtz operator with a complex-valued shift, for a Krylov subspace iterative method. The preconditioner, which can be seen as a strongly damped wave equation in Fourier space, can be approximately inverted by a multigrid method. {\copyright} 2010 Springer-Verlag Berlin Heidelberg.},
  file = {/home/wouter/Zotero/storage/RPUUA7RQ/Oosterlee et al. - 2010 - Shifted-laplacian preconditioners for heterogeneous helmholtz problems.pdf}
}

@article{opper2009,
  title = {The {{Variational Gaussian Approximation Revisited}}},
  author = {Opper, Manfred and Archambeau, C{\'e}dric},
  year = {2009},
  month = mar,
  journal = {Neural Computation},
  volume = {21},
  number = {3},
  pages = {786--792},
  doi = {10.1162/neco.2008.08-07-592},
  abstract = {The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions. This is for a good reason: the gaussian approximation is in general plagued by an [Formula: see text] number of variational parameters to be optimized, N being the number of random variables. In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually [Formula: see text]. The approach is applied to gaussian process regression with nongaussian likelihoods.},
  file = {/home/wouter/Zotero/storage/55FAYE26/Opper, Archambeau - 2009 - The Variational Gaussian Approximation Revisited.pdf}
}

@article{opschoor2020,
  title = {Deep {{ReLU}} Networks and High-Order Finite Element Methods},
  author = {Opschoor, Joost A.A. and Petersen, Philipp C. and Schwab, Christoph},
  year = {2020},
  journal = {Analysis and Applications},
  volume = {18},
  number = {5},
  pages = {715--770},
  doi = {10.1142/S0219530519410136},
  abstract = {Approximation rate bounds for emulations of real-valued functions on intervals by deep neural networks (DNNs) are established. The approximation results are given for DNNs based on ReLU activation functions. The approximation error is measured with respect to Sobolev norms. It is shown that ReLU DNNs allow for essentially the same approximation rates as nonlinear, variable-order, free-knot (or so-called "hp-adaptive") spline approximations and spectral approximations, for a wide range of Sobolev and Besov spaces. In particular, exponential convergence rates in terms of the DNN size for univariate, piecewise Gevrey functions with point singularities are established. Combined with recent results on ReLU DNN approximation of rational, oscillatory, and high-dimensional functions, this corroborates that continuous, piecewise affine ReLU DNNs afford algebraic and exponential convergence rate bounds which are comparable to "best in class"schemes for several important function classes of high and infinite smoothness. Using composition of DNNs, we also prove that radial-like functions obtained as compositions of the above with the Euclidean norm and, possibly, anisotropic affine changes of co-ordinates can be emulated at exponential rate in terms of the DNN size and depth without the curse of dimensionality.},
  keywords = {Deep neural networks,exponential covergence,finite element methods,Gevrey regularity,singularities},
  file = {/home/wouter/Zotero/storage/WN5U2YLP/Opschoor, Petersen, Schwab - 2020 - Deep ReLU networks and high-order finite element methods.pdf}
}

@article{opschoor2022,
  title = {Exponential {{ReLU DNN}} Expression of Holomorphic Maps in High Dimension},
  author = {Opschoor, Joost A.A. and Schwab, Christoph and Zech, Jakob},
  year = {2022},
  journal = {Constructive Approximation},
  volume = {55},
  number = {1},
  pages = {537--582},
  publisher = {Springer}
}

@article{osher2001,
  title = {Level {{Set Methods}}: {{An Overview}} and {{Some Recent Results}}},
  author = {Osher, Stanley and Fedkiw, Ronald P.},
  year = {2001},
  journal = {Journal of Computational Physics},
  volume = {169},
  number = {2},
  pages = {463--502},
  doi = {10.1006/jcph.2000.6636},
  abstract = {The level set method was devised by S. Osher and J. A. Sethian (1988, J. Comput. Phys.79, 12-49) as a simple and versatile method for computing and analyzing the motion of an interface {$\Gamma$} in two or three dimensions. {$\Gamma$} bounds a (possibly multiply connected) region {\textohm}. The goal is to compute and analyze the subsequent motion of {$\Gamma$} under a velocity field v. This velocity can depend on position, time, the geometry of the interface, and the external physics. The interface is captured for later time as the zero level set of a smooth (at least Lipschitz continuous) function {$\varphi$} (x, t); i.e., {$\Gamma$}(t)=\{x{$\varphi$}(x, t)=0\}. {$\varphi$} is positive inside {\textohm}, negative outside {\textohm}, and is zero on {$\Gamma$}(t). Topological merging and breaking are well defined and easily performed. In this review article we discuss recent variants and extensions, including the motion of curves in three dimensions, the dynamic surface extension method, fast methods for steady state problems, diffusion generated motion, and the variational level set approach. We also give a user's guide to the level set dictionary and technology and couple the method to a wide variety of problems involving external physics, such as compressible and incompressible (possibly reacting) flow, Stefan problems, kinetic crystal growth, epitaxial growth of thin films, vortex-dominated flows, and extensions to multiphase motion. We conclude with a discussion of applications to computer vision and image processing. {\copyright} 2001 Academic Press.},
  file = {/home/wouter/Zotero/storage/UMZN6KQD/Osher, Fedkiw - 2001 - Level Set Methods An Overview and Some Recent Results.pdf}
}

@article{ososkov2000,
  title = {Gaussian Wavelet Features and Their Applications for Analysis of Discretized Signals},
  author = {Ososkov, G. and Shitov, A.},
  year = {2000},
  month = apr,
  journal = {Computer Physics Communications},
  volume = {126},
  number = {1-2},
  pages = {149--157},
  doi = {10.1016/S0010-4655(99)00227-1},
  abstract = {Problems of analysis of symmetric, bell-shaped signals registered in a discrete form are considered. Fast and direct methods for their processing are proposed on the basis of vanishing momentum wavelets. Unlike previous works, wavelets of higher order are used extensively in these methods. A new wavelet feature is observed: the permanence of their relative square. It makes possible to choose an optimal scale coefficient that is common for several wavelet-transforms. Numerical simulations show the high accuracy of proposed algorithms comparable with the more laborious methods of a Gaussian fitting to discrete measurements.},
  keywords = {contamination,discretization,shift and dilation,superposed signals,vanishing momentum wavelet,wavelet spectrum,wavelets},
  file = {/home/wouter/Zotero/storage/CC4K7QIV/Ososkov, Shitov - 2000 - Gaussian wavelet features and their applications for analysis of discretized signals.pdf}
}

@article{padonou2016,
  title = {Polar {{Gaussian Processes}} and {{Experimental Designs}} in {{Circular Domains}}},
  author = {Padonou, Esperan and Roustant, Olivier},
  year = {2016},
  month = jan,
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  volume = {4},
  number = {1},
  pages = {1014--1033},
  issn = {2166-2525},
  doi = {10.1137/15M1032740},
  urldate = {2024-10-25},
  langid = {english},
  file = {/home/wouter/Zotero/storage/XBXTCJWF/Padonou and Roustant - 2016 - Polar Gaussian Processes and Experimental Designs in Circular Domains.pdf}
}

@article{pang2023,
  title = {Enhanced {{Kriging}} Leave-One-out Cross-Validation in Improving Model Estimation and Optimization},
  author = {Pang, Yong and Wang, Yitang and Lai, Xiaonan and Zhang, Shuai and Liang, Pengwei and Song, Xueguan},
  year = {2023},
  month = sep,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {414},
  pages = {116194},
  issn = {00457825},
  doi = {10.1016/j.cma.2023.116194},
  urldate = {2025-01-20},
  langid = {english},
  file = {/home/wouter/Zotero/storage/6JC6UVIL/Pang et al. - 2023 - Enhanced Kriging leave-one-out cross-validation in improving model estimation and optimization.pdf}
}

@article{papadimitriou2017,
  title = {Bayesian Optimal Experimental Design for Parameter Estimation and Response Predictions in Complex Dynamical Systems},
  author = {Papadimitriou, Costas and Argyris, Costas},
  year = {2017},
  journal = {Procedia Engineering},
  volume = {199},
  pages = {972--977},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.proeng.2017.09.205},
  abstract = {A Bayesian optimal experimental design (OED) framework is revisited and applied to a number of structural dynamics problems. The objective is to optimize the design of the experiment such that the most informative data are obtained for either for parameter estimation or response predictions. The Bayesian OED is based on maximizing the expected utility function taken as the Kullback-Leibler divergence between the prior and posterior distribution of the model parameters. Asymptotic approximations for the multi-dimensional integrals arising in the formulation of the expected utility function are proposed, valid for large number of data and small prediction errors. The OED based on these approximations are shown to be equivalent to the OED based on the robust information entropy introduced in the past for structural dynamics applications. Analytical expressions are developed to point out the effect of the variances of Bayesian Gaussian priors on the optimal design. The design variables may include the location of sensors, location of actuators or characteristics of the excitation such as amplitude variation and frequency content characteristics. A stochastic optimization algorithm is conveniently used to solve the optimization problem in the continuous physical domain of variation of the design variables. The proposed framework is applicable to complex linear and nonlinear dynamical systems. The asymptotic results are compared to the results obtained from accurate but computationally expensive sampling algorithms and are shown to be adequate for experimental design purposes. Two optimal experimental design problems illustrate the proposed methodology: 1) optimal sensor placement for load identification in nonlinear beam models, 2) optimal sensor placement for modal identification of bridges using complex FE models.},
  keywords = {asymptotic approximations,dynamical systems,information entropy,Kullback-Leibler divergence,Utility functions},
  file = {/home/wouter/Zotero/storage/PESVK9C3/Papadimitriou, Argyris - 2017 - Bayesian optimal experimental design for parameter estimation and response predictions in complex dynami.pdf}
}

@book{parhami1999,
  title = {Introduction to Parallel Processing: Algorithms and Architectures},
  author = {Parhami, Behrooz},
  year = {1999},
  pages = {282},
  publisher = {Kluwer Academic/Plenum},
  isbn = {978-0-306-45970-2},
  file = {/home/wouter/Zotero/storage/SXXGG8SD/Parhami - 1999 - Introduction to parallel processing algorithms and architectures.pdf}
}

@article{parks2006,
  title = {Recycling {{Krylov Subspaces}} for {{Sequences}} of {{Linear Systems}}},
  author = {Parks, Michael L. and {de Sturler}, Eric and Mackey, Greg and Johnson, Duane D. and Maiti, Spandan},
  year = {2006},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {28},
  number = {5},
  pages = {1651--1674},
  doi = {10.1137/040607277},
  file = {/home/wouter/Zotero/storage/ZVYVCLQA/Parks et al. - 2006 - Recycling Krylov Subspaces for Sequences of Linear Systems.pdf}
}

@article{pasini2019,
  title = {Imperfect Architected Materials: {{Mechanics}} and Topology Optimization},
  author = {Pasini, Damiano and Guest, James K},
  year = {2019},
  journal = {MRS Bulletin},
  volume = {44},
  number = {10},
  pages = {766--772},
  publisher = {Cambridge University Press}
}

@article{pavlovic2007,
  title = {Lipschitz Conditions on the Modulus of a Harmonic Function},
  author = {Pavlovi{\'c}, Miroslav},
  year = {2007},
  journal = {Revista Matematica Iberoamericana},
  volume = {23},
  number = {3},
  pages = {831--845},
  doi = {10.4171/RMI/515},
  abstract = {It is proved that if u is a real valued function harmonic in the open unit ball double script B signN {$\subset$} {$\mathbb{R}$}N and continuous on the closed ball, then the following conditions are equivalent, for 0 {$<$} {$\alpha$} {$<$} 1: {\textbar}u(x) - u(w){\textbar} {$\leq$} C{\textbar}x - w{\textbar}{$\alpha$}, x, w {$\in$} double script B signN; {\textbar}{\textbar}u(y){\textbar} - {\textbar}u({$\zeta$}){\textbar}{\textbar} {$<$} C{\textbar}y - {$\zeta\vert$} {$\alpha$}, y, {$\zeta$} {$\in$} {$\partial$}double script B signN; {\textbar}{\textbar}u(y){\textbar} - {\textbar}u(ry){\textbar}{\textbar} {$\leq$} C(1 - r){$\alpha$}, y {$\in$} {$\partial$}double script B signN, 0 {$<$} r {$<$} 1. The Lipschitz condition on {\textbar}u{\textbar}p is also considered.},
  keywords = {Harmonic functions,Lipschitz condition},
  file = {/home/wouter/Zotero/storage/G3Q58L8E/Pavlović - 2007 - Lipschitz conditions on the modulus of a harmonic function.pdf}
}

@article{pavlovic2009,
  title = {Green's Formula and the {{Hardy-Stein}} Identities},
  author = {Pavlovic, Miroslav},
  year = {2009},
  journal = {Filomat},
  volume = {23},
  number = {3},
  pages = {135--153},
  doi = {10.2298/fil0903135p},
  abstract = {This is a collection of some known and some new facts on the holomorphic and the harmonic version of the Hardy-Stein identity as well as on their extensions to the real and the complex ball. For example, we prove that if f is holomorphic on the unit disk D, then ??f ??Hp = ?f(0)?p + ?D?f'(z)? p-2 ?f'(z)?2(1-?z?) dA(z), (?) where Hp is the p-Hardy space, which improves a result of Yamashita [Proc. Amer. Math. Soc. 75 (1979), no. 1, 69-72]. An extension of (?) to the unit ball of Cn improves results of Beatrous an Burbea [Kodai Math. J. 8 (1985), 36-51], and of Stoll [J. London Math. Soc. (2) 48 (1993), no. 1, 126-136]. We also prove the analogous result for the harmonic Hardy spaces. The proofs of known results are shorter and more elementary then the existing ones, see Zhu [Spaces of holomorphic functions in the unit ball, Graduate Texts in Mathematics, vol. 226, Springer-Verlag, New York, 2005, Ch. IV]. We correct some constants in that book and in a paper of Jevtic and Pavlovic [Publ. Inst. Math. (Beograd) (N.S.) 64(78) (1998), 36-52].},
  file = {/home/wouter/Zotero/storage/3EGW8CD6/Pavlovic - 2009 - Green's formula and the Hardy-Stein identities.pdf}
}

@article{payne1958,
  title = {New Bounds for Solutions of Second Order Elliptic Partial Differential Equations},
  author = {Payne, Lawrence Edward and Weinberger, Hans F},
  year = {1958},
  volume = {8},
  number = {3},
  file = {/home/wouter/Zotero/storage/WXZEYQGY/Payne, Weinberger - 1958 - New bounds for solutions of second order elliptic partial differential equations.pdf}
}

@article{pearson2020,
  title = {Preconditioners for {{Krylov}} Subspace Methods: {{An}} Overview},
  author = {Pearson, John W. and Pestana, Jennifer},
  year = {2020},
  journal = {GAMM Mitteilungen},
  volume = {43},
  number = {4},
  pages = {1--35},
  doi = {10.1002/gamm.202000015},
  abstract = {When simulating a mechanism from science or engineering, or an industrial process, one is frequently required to construct a mathematical model, and then resolve this model numerically. If accurate numerical solutions are necessary or desirable, this can involve solving large-scale systems of equations. One major class of solution methods is that of preconditioned iterative methods, involving preconditioners which are computationally cheap to apply while also capturing information contained in the linear system. In this article, we give a short survey of the field of preconditioning. We introduce a range of preconditioners for partial differential equations, followed by optimization problems, before discussing preconditioners constructed with less standard objectives in mind.},
  keywords = {iterative method,Krylov subspace method,optimization,partial differential equations,preconditioning},
  file = {/home/wouter/Zotero/storage/ML6L2G4U/Pearson, Pestana - 2020 - Preconditioners for Krylov subspace methods An overview.pdf}
}

@article{peherstorfer2015,
  title = {A Multigrid Method for Adaptive Sparse Grids},
  author = {Peherstorfer, Benjamin and Zimmer, Stefan and Zenger, Christoph and Bungartz, Hans Joachim},
  year = {2015},
  journal = {SIAM Journal on Scientific Computing},
  volume = {37},
  number = {5},
  pages = {S51-S70},
  doi = {10.1137/140974985},
  abstract = {Sparse grids have become an important tool to reduce the number of degrees of freedom of discretizations of moderately high-dimensional partial differential equations; however, the reduction in degrees of freedom comes at the cost of an almost dense and unconventionally structured system of linear equations. To guarantee overall efficiency of the sparse grid approach, special linear solvers are required. We present a multigrid method that exploits the sparse grid structure to achieve an optimal runtime that scales linearly with the number of sparse grid points. Our approach is based on a novel decomposition of the right-hand sides of the coarse grid equations that leads to a reformulation in so-called auxiliary coefficients. With these auxiliary coefficients, the right-hand sides can be represented in a nodal point basis on low-dimensional full grids. Our proposed multigrid method directly operates in this auxiliary coefficient representation, circumventing most of the computationally cumbersome sparse grid structure. Numerical results on nonadaptive and spatially adaptive sparse grids confirm that the runtime of our method scales linearly with the number of sparse grid points and they indicate that the obtained convergence factors are bounded independently of the mesh width.},
  keywords = {Adaptive sparse grids,ANOVA,Multidimensional problems,Multigrid,Q-cycle},
  file = {/home/wouter/Zotero/storage/TFQWI4Y7/Peherstorfer et al. - 2015 - A multigrid method for adaptive sparse grids.pdf}
}

@article{peherstorfer2018,
  title = {Survey of Multifidelity Methods in Uncertainty Propagation, Inference, and Optimization},
  author = {Peherstorfer, Benjamin and Willcox, Karen and Gunzburger, Max},
  year = {2018},
  journal = {Siam Review},
  volume = {60},
  number = {3},
  pages = {550--591},
  publisher = {SIAM}
}

@article{pelaum1997,
  title = {Convergence of the Combination Technique for Second-Order Elliptic Differential Equations},
  author = {Pelaum, Christoph},
  year = {1997},
  month = dec,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {34},
  number = {6},
  pages = {2431--2455},
  doi = {10.1137/s0036142993260294},
  abstract = {The combination technique is an algorithm for the approximate solution of partial differential equations on sparse grids that has to be combined with a suitable standard discretization. The advantage of the combination technique compared to the standard discretization is that the same accuracy is achieved with many fewer grid points. In this paper, the combination technique is used with a bilinear finite element discretization. Depending on the smoothness of the solution and the coefficients, it is proved for general second-order elliptic differential equations on the unit square that the combined solution converges with order O(h] or O(h log h-1) in the energy norm and with order O(h2 log h-1) or O(h3/2) in the L2norm, respectively. This holds even if the bilinear form corresponding to the elliptic equation is not symmetric positive definite. The proof does not use an asymptotic error expansion, but Sobolev space techniques.},
  keywords = {Combination technique,Finite elements,Order of the discretization error,Sparse grid},
  file = {/home/wouter/Zotero/storage/9MJZ2T5C/Pelaum - 1997 - Convergence of the combination technique for second-order elliptic differential equations.pdf}
}

@article{pellissetti2000,
  title = {Iterative Solution of Systems of Linear Equations Arising in the Context of Stochastic Finite Elements},
  author = {Pellissetti, Manuel F and Ghanem, Roger},
  year = {2000},
  month = aug,
  journal = {Advances in Engineering Software},
  volume = {31},
  number = {8-9},
  pages = {607--616},
  issn = {09659978},
  doi = {10.1016/S0965-9978(00)00034-X},
  urldate = {2025-02-13},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/E2JS9H3I/Pellissetti and Ghanem - 2000 - Iterative solution of systems of linear equations arising in the context of stochastic finite elemen.pdf}
}

@phdthesis{pembery2020,
  title = {The {{Helmholtz Equation}} in {{Heterogeneous}} and {{Random Media}}: {{Analysis}} and {{Numerics}}},
  author = {Pembery, Owen R.},
  year = {2020},
  school = {University of Bath},
  file = {/home/wouter/Zotero/storage/6H7RK3VB/Pembery - 2020 - The Helmholtz Equation in Heterogeneous and Random Media Analysis and Numerics.pdf}
}

@article{perthame2008,
  title = {Energy Concentration and Sommerfeld Condition for Helmholtz Equation with Variable Index at Infinity},
  author = {Perthame, Benoit and Vega, Luis},
  year = {2008},
  journal = {Geometric and Functional Analysis},
  volume = {17},
  number = {5},
  pages = {1685--1707},
  doi = {10.1007/s00039-007-0635-6},
  abstract = {We consider the Helmholtz equation with a variable index of refraction n(x), which is not necessarily constant at infinity but can have an angular dependency like n(x) {$\rightarrow$} n{$\infty$}\vphantom\{\} (x/{\textbar}x{\textbar}) as {\textbar}x{\textbar} {$\rightarrow$} {$\infty$}. Under some appropriate assumptions on this convergence and on n {$\infty$} we prove that the Sommerfeld condition at infinity still holds true under the explicit form {$\int\mathbb{R}$}d {\textbar} u-in\{1/2\}{$\infty$}\vphantom\{\}u \{x\}/{\textbar}x{\textbar}2 (dx\vphantom\{\}/{\textbar}x{\textbar} {$<$}+{$\infty$}. It is a very striking and unexpected feature that the index n {$\infty$} appears in this formula and not the gradient of the phase as established by Saito in [S] and broadly used numerically. This apparent contradiction is clarified by the existence of some extra estimates on the energy decay. In particular we prove that {$\int\mathbb{R}$}d{$\omega$} n{$\infty$} \{x\}/{\textbar}x{\textbar} 2\vphantom\{\} u2\vphantom\{\} {\textbar}x {\textbar} dx{$<$}+{$\infty$}. In fact our main contribution is to show that this can be interpreted as a concentration of the energy along the critical lines of n {$\infty$}. In other words, the Sommerfeld condition hides the main physical effect arising for a variable n at infinity; energy concentration on lines rather than dispersion in all directions. {\copyright} 2007 Birkhaeuser.},
  keywords = {Energy concentration,Helmholtz equation,Index of refraction,Sommerfeld condition},
  file = {/home/wouter/Zotero/storage/HF4P6SWP/Perthame, Vega - 2008 - Energy concentration and sommerfeld condition for helmholtz equation with variable index at infinity.pdf}
}

@article{piazzola2022,
  title = {The {{Sparse Grids Matlab}} Kit -- a {{Matlab}} Implementation of Sparse Grids for High-Dimensional Function Approximation and Uncertainty Quantification},
  author = {Piazzola, Chiara and Tamellini, Lorenzo},
  year = {2022},
  pages = {1--23},
  abstract = {The Sparse Grids Matlab Kit provides a Matlab implementation of sparse grids, and can be used for approximating high-dimensional functions and, in particular, for surrogate-model-based uncertainty quantification. It is lightweight, high-level and easy to use, good for quick prototyping and teaching; however, it is equipped with some features that allow its use also in realistic applications. The goal of this paper is to provide an overview of the data structure and of the mathematical aspects forming the basis of the software, as well as comparing the current release of our package to similar available software.},
  file = {/home/wouter/Zotero/storage/K4AQK5T2/Piazzola, Tamellini - 2022 - The Sparse Grids Matlab kit -- a Matlab implementation of sparse grids for high-dimensional function approx.pdf}
}

@article{piazzola2024,
  title = {Algorithm~1040: {{The Sparse Grids Matlab Kit}} - a {{Matlab}} Implementation of Sparse Grids for High-Dimensional Function Approximation and Uncertainty Quantification},
  author = {Piazzola, Chiara and Tamellini, Lorenzo},
  year = {2024},
  journal = {ACM Transactions on Mathematical Software},
  volume = {50},
  number = {1},
  pages = {1--22},
  doi = {10.1145/3630023},
  abstract = {The Sparse Grids Matlab Kit provides a Matlab implementation of sparse grids, and can be used for approximating high-dimensional functions and, in particular, for surrogate-model-based uncertainty quantification. It is lightweight, high-level and easy to use, good for quick prototyping and teaching; however, it is equipped with some features that allow its use also in realistic applications. The goal of this paper is to provide an overview of the data structure and of the mathematical aspects forming the basis of the software, as well as comparing the current release of our package to similar available software.},
  file = {/home/wouter/Zotero/storage/X9R79NC2/Piazzola, Tamellini - 2024 - Algorithm 1040 The Sparse Grids Matlab Kit - a Matlab implementation of sparse grids for high-dimensional f.pdf}
}

@article{pinto2023,
  title = {Shape {{Holomorphy}} of {{Boundary Integral Operators}} on {{Multiple Open Arcs}}},
  author = {Pinto, Jose and Henr{\'i}quez, Fernando and {Jerez-Hanckes}, Carlos},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.12202},
  eprint = {2305.12202},
  archiveprefix = {arXiv}
}

@article{plana1855,
  title = {M{\'e}moire Sur La {{Th{\'e}orie}} Du {{Magn{\'e}tisme}}. {{Par Mr}}. {{{\emph{Jean Plana}}}}},
  author = {Plana, Jean},
  year = {1855},
  month = jan,
  journal = {Astronomische Nachrichten},
  volume = {42},
  number = {1-3},
  pages = {1--44},
  issn = {0004-6337, 1521-3994},
  doi = {10.1002/asna.18550420101},
  urldate = {2025-04-15},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@article{plum1992,
  title = {Explicit {{H2-estimates}} and Pointwise Bounds for Solutions of Second-Order Elliptic Boundary Value Problems},
  author = {Plum, Michael},
  year = {1992},
  journal = {Journal of Mathematical Analysis and Applications},
  volume = {165},
  number = {1},
  pages = {36--61},
  doi = {10.1016/0022-247X(92)90067-N},
  abstract = {It is well known that the H2-norm and the C0-norm of a function u {$\in$} H2({\textohm}) (where {\textohm} {$\subset$} Rn is a bounded domain, n {$\leq$} 3) can be estimated in terms of a given uniformly elliptic second-order differential operator L and some boundary operator B applied to u, if certain regularity assumptions are satisfied. If these bounds shall be used for numerical purposes, the constants occurring in the estimates must be known explicitly. The main goal of the present article is the computation of such explicit constants. For simplicity of presentation, we restrict ourselves to the case where L[u] = -{$\Delta$}u + c(x)u. As an application, we prove an existence and inclusion result for nonlinear boundary value problems. {\copyright} 1992.},
  file = {/home/wouter/Zotero/storage/7S2GZKAJ/Plum - 1992 - Explicit H2-estimates and pointwise bounds for solutions of second-order elliptic boundary value problems.pdf}
}

@article{polson2008,
  title = {Practical Filtering with Sequential Parameter Learning},
  author = {Polson, Nicholas G. and Stroud, Jonathan R. and M{\"u}ller, Peter},
  year = {2008},
  journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  volume = {70},
  number = {2},
  pages = {413--428},
  doi = {10.1111/j.1467-9868.2007.00642.x},
  abstract = {The paper develops a simulation-based approach to sequential parameter learning and filtering in general state space models. Our approach is based on approximating the target posterior by a mixture of fixed lag smoothing distributions. Parameter inference exploits a sufficient statistic structure and the methodology can be easily implemented by modifying state space smoothing algorithms. We avoid reweighting particles and hence sample degeneracy problems that plague particle filters that use sequential importance sampling. The method is illustrated by using two examples: a benchmark auto-regressive model with observation error and a high dimensional dynamic spatiotemporal model. We show that the method provides accurate inference in the presence of outliers, model misspecification and high dimensionality. {\copyright} 2008 Royal Statistical Society.},
  keywords = {Filtering,Markov chain Monte Carlo methods,Particle filtering,Sequential parameter learning,Spatiotemporal models,State space models},
  file = {/home/wouter/Zotero/storage/SE93CGDM/Polson, Stroud, Müller - 2008 - Practical filtering with sequential parameter learning.pdf}
}

@article{polterovich2015,
  title = {Heat {{Invariants}} of the {{Steklov Problem}}},
  author = {Polterovich, Iosif and Sher, David A.},
  year = {2015},
  month = apr,
  journal = {The Journal of Geometric Analysis},
  volume = {25},
  number = {2},
  pages = {924--950},
  doi = {10.1007/s12220-013-9451-4},
  abstract = {We study the heat trace asymptotics associated with the Steklov eigenvalue problem on a Riemannian manifold with boundary. In particular, we describe the structure of the Steklov heat invariants and compute the first few of them explicitly in terms of the scalar and mean curvatures. This is done by applying the Seeley calculus to the Dirichlet-to-Neumann operator, whose spectrum coincides with the Steklov eigenvalues. As an application, it is proved that a three-dimensional ball is uniquely defined by its Steklov spectrum among all Euclidean domains with smooth connected boundary.},
  keywords = {Dirichlet-to-Neumann operator,Heat trace,Riemannian manifold,Spectral rigidity,Steklov problem},
  file = {/home/wouter/Zotero/storage/ZZ7PJXPU/Polterovich, Sher - 2015 - Heat Invariants of the Steklov Problem.pdf}
}

@article{powell2003,
  title = {Optimal {{Preconditioning}} for {{Raviart--Thomas Mixed Formulation}} of {{Second-Order Elliptic Problems}}},
  author = {Powell, Catherine Elizabeth and Silvester, David},
  year = {2003},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {25},
  number = {3},
  pages = {718--738},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/S0895479802404428},
  urldate = {2025-02-13},
  langid = {english},
  file = {/home/wouter/Zotero/storage/T3LEDMTP/narep399.ps}
}

@article{powell2009,
  title = {Block-Diagonal Preconditioning for Spectral Stochastic Finite-Element Systems},
  author = {Powell, Catherine E. and Elman, Howard C.},
  year = {2009},
  journal = {IMA Journal of Numerical Analysis},
  volume = {29},
  number = {2},
  pages = {350--375},
  doi = {10.1093/imanum/drn014},
  abstract = {Deterministic models of fluid flow and the transport of chemicals in flows in heterogeneous porous media incorporate partial differential equations (PDEs) whose material parameters are assumed to be known exactly. To tackle more realistic stochastic flow problems, it is fitting to represent the permeability coefficients as random fields with prescribed statistics. Traditionally, large numbers of deterministic problems are solved in a Monte Carlo framework and the solutions are averaged to obtain statistical properties of the solution variables. Alternatively, so-called stochastic finite-element methods (SFEMs) discretize the probabilistic dimension of the PDE directly leading to a single structured linear system. The latter approach is becoming extremely popular but its computational cost is still perceived to be problematic as this system is orders of magnitude larger than for the corresponding deterministic problem. A simple block-diagonal preconditioning strategy incorporating only the mean component of the random field coefficient and based on incomplete factorizations has been employed in the literature and observed to be robust, for problems of moderate variance, but without theoretical analysis. We solve the stochastic Darcy flow problem in primal formulation via the spectral SFEM and focus on its efficient iterative solution. To achieve optimal computational complexity, we base our block-diagonal preconditioner on algebraic multigrid. In addition, we provide new theoretical eigenvalue bounds for the preconditioned system matrix. By highlighting the dependence of these bounds on all the SFEM parameters, we illustrate, in particular, why enriching the stochastic approximation space leads to indefinite system matrices when unbounded random variables are employed.},
  keywords = {Fast solvers,Finite elements,Multigrid,Preconditioning,Stochastic finite elements},
  file = {/home/wouter/Zotero/storage/XPGTPNBI/Powell, Elman - 2009 - Block-diagonal preconditioning for spectral stochastic finite-element systems.pdf}
}

@article{powell2012,
  title = {Preconditioning {{Steady-State Navier--Stokes Equations}} with {{Random Data}}},
  author = {Powell, Catherine E. and Silvester, David J.},
  year = {2012},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {34},
  number = {5},
  pages = {A2482-A2506},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/120870578},
  urldate = {2025-02-24},
  langid = {english},
  file = {/home/wouter/Zotero/storage/MUPNAVLH/Powell and Silvester - 2012 - Preconditioning Steady-State Navier--Stokes Equations with Random Data.pdf}
}

@article{prangle2023,
  title = {Bayesian {{Experimental Design Without Posterior Calculations}}: {{An Adversarial Approach}}},
  shorttitle = {Bayesian {{Experimental Design Without Posterior Calculations}}},
  author = {Prangle, Dennis and Harbisher, Sophie and Gillespie, Colin S.},
  year = {2023},
  month = mar,
  journal = {Bayesian Analysis},
  volume = {18},
  number = {1},
  issn = {1936-0975},
  doi = {10.1214/22-BA1306},
  urldate = {2024-08-19},
  file = {/home/wouter/Zotero/storage/QE27L4ZF/Prangle et al. - 2023 - Bayesian Experimental Design Without Posterior Calculations An Adversarial Approach.pdf}
}

@article{prestin2005,
  title = {Periodic and {{Spline Multiresolution Analysis}} and the {{Lifting Scheme}}},
  author = {Prestin, J{\"u}rgen and Quak, Ewald},
  year = {2005},
  journal = {Advances in Multiresolution for Geometric Modelling},
  number = {May},
  pages = {369--390},
  issn = {3540268081},
  doi = {10.1007/3-540-26808-1_21},
  abstract = {Summary: The lifting scheme is a well-known general framework for the{\textbackslash}nconstruction of wavelets, especially in finite-dimensional settings. After a{\textbackslash}nshort introduction about the basics of lifting, we discuss how wavelet{\textbackslash}nconstructions, in two specific finite settings, can be related to the{\textbackslash}nlifting approach. These examples concern, on the one hand, polynomial{\textbackslash}nsplines and, on the other, the Fourier approach for translation-invariant{\textbackslash}nspaces of periodic functions.},
  file = {/home/wouter/Zotero/storage/Q3VN9CPE/Prestin, Quak - 2005 - Periodic and Spline Multiresolution Analysis and the Lifting Scheme.pdf}
}

@book{programming2010,
  title = {50 {{Years}} of {{Integer Programming}} 1958-2008},
  author = {Programming, Integer},
  editor = {J{\"u}nger, Michael and Liebling, Thomas M. and Naddef, Denis and Nemhauser, George L. and Pulleyblank, William R. and Reinelt, Gerhard and Rinaldi, Giovanni and Wolsey, Laurence A.},
  year = {2010},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-68279-0},
  isbn = {978-3-540-68274-5},
  file = {/home/wouter/Zotero/storage/N4T4FR9U/Programming - 2010 - 50 Years of Integer Programming 1958-2008.pdf}
}

@article{pucci2004,
  title = {The Strong Maximum Principle Revisited},
  author = {Pucci, Patrizia and Serrin, James},
  year = {2004},
  journal = {Journal of Differential Equations},
  volume = {196},
  number = {1},
  pages = {1--66},
  doi = {10.1016/j.jde.2003.05.001},
  abstract = {In this paper we first present the classical maximum principle due to E. Hopf, together with an extended commentary and discussion of Hopf's paper. We emphasize the comparison technique invented by Hopf to prove this principle, which has since become a main mathematical tool for the study of second order elliptic partial differential equations and has generated an enormous number of important applications. While Hopf's principle is generally understood to apply to linear equations, it is in fact also crucial in nonlinear theories, such as those under consideration here. In particular, we shall treat and discuss recent generalizations of the strong maximum principle, and also the compact support principle, for the case of singular quasilinear elliptic differential inequalities, under generally weak assumptions on the quasilinear operators and the nonlinearities involved. Our principal interest is in necessary and sufficient conditions for the validity of both principles; in exposing and simplifying earlier proofs of corresponding results; and in extending the conclusions to wider classes of singular operators than previously considered. The results have unexpected ramifications for other problems, as will develop from the exposition, e.g. (i) two point boundary value problems for singular quasilinear ordinary differential equations (Sections 3 and 4); (ii) the exterior Dirichlet boundary value problem (Section 5); (iii) the existence of dead cores and compact support solutions, i.e. dead cores at infinity (Section 7); (iv) Euler-Lagrange inequalities on a Riemannian manifold (Section 9); (v) comparison and uniqueness theorems for solutions of singular quasilinear differential inequalities (Section 10). The case of p-regular elliptic inequalities is briefly considered in Section 11. {\copyright} 2003 Elsevier Inc. All rights reserved.},
  keywords = {Quasilinear singular elliptic inequalities,Strong maximum and compact support principles},
  file = {/home/wouter/Zotero/storage/D82ZZ8HW/Pucci, Serrin - 2004 - The strong maximum principle revisited.pdf}
}

@article{pulch2024,
  title = {The {{Helmholtz Equation}} with {{Uncertainties}} in the {{Wavenumber}}},
  author = {Pulch, Roland and S{\`e}te, Olivier},
  year = {2024},
  month = mar,
  journal = {Journal of Scientific Computing},
  volume = {98},
  number = {3},
  pages = {60},
  issn = {0885-7474, 1573-7691},
  doi = {10.1007/s10915-024-02450-3},
  urldate = {2025-03-24},
  abstract = {Abstract             We investigate the Helmholtz equation with suitable boundary conditions and uncertainties in the wavenumber. Thus the wavenumber is modeled as a random variable or a random field. We discretize the Helmholtz equation using finite differences in space, which leads to a linear system of algebraic equations including random variables. A stochastic Galerkin method yields a deterministic linear system of algebraic equations. This linear system is high-dimensional, sparse and complex symmetric but, in general, not hermitian. We therefore solve this system iteratively with GMRES and propose two preconditioners: a complex shifted Laplace preconditioner and a mean value preconditioner. Both preconditioners reduce the number of iteration steps as well as the computation time in our numerical experiments.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/4SCC3SZY/Pulch and Sète - 2024 - The Helmholtz Equation with Uncertainties in the Wavenumber.pdf}
}

@article{pullar-strecker2024,
  title = {Hitting the Target: Stopping Active Learning at the Cost-Based Optimum},
  shorttitle = {Hitting the Target},
  author = {{Pullar-Strecker}, Zac and Dost, Katharina and Frank, Eibe and Wicker, J{\"o}rg},
  year = {2024},
  month = apr,
  journal = {Machine Learning},
  volume = {113},
  number = {4},
  pages = {1529--1547},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-022-06253-1},
  urldate = {2025-03-05},
  abstract = {Abstract             Active learning allows machine learning models to be trained using fewer labels while retaining similar performance to traditional supervised learning. An active learner selects the most informative data points, requests their labels, and retrains itself. While this approach is promising, it raises the question of how to determine when the model is `good enough' without the additional labels required for traditional evaluation. Previously, different stopping criteria have been proposed aiming to identify the optimal stopping point. Yet, optimality can only be expressed as a domain-dependent trade-off between accuracy and the number of labels, and no criterion is superior in all applications. As a further complication, a comparison of criteria for a particular real-world application would require practitioners to collect additional labelled data they are aiming to avoid by using active learning in the first place. This work enables practitioners to employ active learning by providing actionable recommendations for which stopping criteria are best for a given real-world scenario. We contribute the first large-scale comparison of stopping criteria for pool-based active learning, using a cost measure to quantify the accuracy/label trade-off, public implementations of all stopping criteria we evaluate, and an open-source framework for evaluating stopping criteria. Our research enables practitioners to substantially reduce labelling costs by utilizing the stopping criterion which best suits their domain.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/WWTCAGA9/Pullar-Strecker et al. - 2024 - Hitting the target stopping active learning at the cost-based optimum.pdf}
}

@article{purser2008,
  title = {Generalized {{Fibonacci Grids}}; {{A New Class Of Structured Smoothly Adaptive Multi-dimensional Computational Lattices Interpolation}} and Filtering {{View}} Project {{Polyhedral}} Gridding {{View}} Project},
  author = {Purser, R J},
  year = {2008},
  number = {January 2008},
  doi = {10.13140/RG.2.1.4294.8000},
  file = {/home/wouter/Zotero/storage/C63BJ9DX/Purser - 2008 - Generalized Fibonacci Grids A New Class Of Structured Smoothly Adaptive Multi-dimensional Computational Lattices Interpo.pdf}
}

@book{quarteroni1994,
  title = {Numerical {{Approximation}} of {{Partial Differential Equations}}},
  author = {Quarteroni, Alfio and Valli, Alberto},
  year = {1994},
  series = {Springer {{Series}} in {{Computational Mathematics}}},
  volume = {23},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-85268-1},
  isbn = {978-3-540-85267-4},
  file = {/home/wouter/Zotero/storage/3BYDM9KF/Quarteroni, Valli - 1994 - Numerical Approximation of Partial Differential Equations.pdf}
}

@book{quarteroni2007,
  title = {Numerical {{Mathematics Texts}} in {{Applied Mathematics}}},
  author = {Quarteroni, A and Sacco, R and Saleri, F},
  year = {2007},
  journal = {Sistemas.Fciencias.Unam.Mx},
  pages = {655},
  abstract = {Numerical mathematics is the branch of mathematics that proposes, develops, analyzes and applies methods from scientific computing to several fields including analysis, linear algebra, geometry, approximation theory, functional equations, optimization and differential equations. Other disciplines, such as physics, the natural and biological sciences, engineering, and economics and the financial sciences frequently give rise to problems that need scientific computing for their solutions. As such, numerical mathematics is the crossroad of several disciplines of great relevance in modern applied sciences, and can become a crucial tool for their qualitative and quantitative analysis. One of the purposes of this book is to provide the mathematical foundations of numerical methods, to analyze their basic theoretical properties (stability, accuracy, computational complexity) and demonstrate their performance on examples and counterexamples which outline their pros and cons. This is done using the MATLABTM software environment which is user-friendly and widely adopted. Within any specific class of problems, the most appropriate scientific computing algorithms are reviewed, their theoretical analyses are carried out and the expected results are verified on a MATLABTM computer implementation. Every chapter is supplied with examples, exercises and applications of the discussed theory to the solution of real-life problems. This book is addressed to senior undergraduate and graduate students with particular focus on degree courses in engineering, mathematics, physics and computer sciences. The attention which is paid to the applications and the related development of software makes it valuable also for researchers and users of scientific computing in a large variety of professional fields. In this second edition, the readability of pictures, tables and program headings has been improved. Several changes in the chapters on iterative methods and on polynomial approximation have also been added. From the reviews of the first edition: "This is an excellent and modern textbook in numerical mathematics! It is primarily addressed to undergraduate students in mathematics, physics, computer science and engineering. But you will need a weekly 4 hour lecture for 3 terms lecture to teach all topics treated in this book! Well known methods as well as very new algorithms are given. The methods and their performances are demonstrated by illustrative examples and computer examples. Exercises shall help the reader to understand the theory and to apply it. MATLAB-software satisfies the need of user-friendliness. [....] In the reviewers opinion, the presented book is the best textbook in numerical mathematics edited in the last ten years." Zentralblatt f{\"u}r Mathematik 2001, 991.38387},
  isbn = {978-3-540-34658-6},
  file = {/home/wouter/Zotero/storage/HABJY95D/Quarteroni, Sacco, Saleri - 2007 - Numerical Mathematics Texts in Applied Mathematics.pdf}
}

@article{raissi2018,
  title = {Hidden Physics Models: {{Machine}} Learning of Nonlinear Partial Differential Equations},
  shorttitle = {Hidden Physics Models},
  author = {Raissi, Maziar and Karniadakis, George Em},
  year = {2018},
  month = mar,
  journal = {Journal of Computational Physics},
  volume = {357},
  pages = {125--141},
  issn = {00219991},
  doi = {10.1016/j.jcp.2017.11.039},
  urldate = {2025-05-12},
  langid = {english},
  file = {/home/wouter/Zotero/storage/9ZIHKBKA/Raissi and Karniadakis - 2018 - Hidden physics models Machine learning of nonlinear partial differential equations.pdf}
}

@article{rana2017,
  title = {High {{Dimensional}} \{\vphantom\}{{B}}\vphantom\{\}ayesian {{Optimization}} with {{Elastic}} \{\vphantom\}{{G}}\vphantom\{\}aussian {{Process}}},
  author = {Rana, Santu and Li, Chen and Gupta, Sunil and Nguyen, Vu and Venkatesh, Svetha},
  year = {2017},
  journal = {Proceedings of Machine Learning Research},
  volume = {70},
  pages = {2883--2891},
  file = {/home/wouter/Zotero/storage/AI3R3S4R/rana17a.pdf}
}

@book{rasmussen2000,
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  author = {Rasmussen, Carl E. and Williams, Christopher K. I.},
  year = {2000},
  journal = {Journal fur Urologie und Urogynakologie},
  volume = {7},
  pages = {46},
  publisher = {The MIT Press},
  abstract = {The goal of building systems that can adapt to their environments and learn from their experience has attracted researchers from many fields, including com- puter science, engineering, mathematics, physics, neuroscience, and cognitive science. Out of this research has come a wide variety of learning techniques that have the potential to transform many scientific and industrial fields. Recently, several research communities have converged on a common set of issues sur- rounding supervised, unsupervised, and reinforcement learning problems. The MIT Press series on Adaptive Computation and Machine Learning seeks to unify the many diverse strands of machine learning research and to foster high quality research and innovative applications. One of the most active directions in machine learning has been the de- velopment of practical Bayesian methods for challenging learning problems. Gaussian Processes for Machine Learning presents one of the most important Bayesian machine learning approaches based on a particularly effective method for placing a prior distribution over the space of functions. Carl Edward Ras- mussen and Chris Williams are two of the pioneers in this area, and their book describes the mathematical foundations and practical application of Gaussian processes in regression and classification tasks. They also show how Gaussian processes can be interpreted as a Bayesian version of the well-known support vector machine methods. Students and researchers who study this book will be able to apply Gaussian process methods in creative ways to solve a wide range of problems in science and engineering},
  isbn = {0-262-18253-X},
  file = {/home/wouter/Zotero/storage/5PRPM565/Rasmussen and Williams - 2008 - Gaussian processes for machine learning.pdf;/home/wouter/Zotero/storage/ADWZIGPV/Rasmussen and Williams - 2008 - Gaussian processes for machine learning.pdf;/home/wouter/Zotero/storage/BBUI6GAB/Rasmussen, Williams - 2000 - Gaussian Processes for Machine Learning.pdf;/home/wouter/Zotero/storage/TKU536P3/RW5.pdf}
}

@article{raziman2013,
  title = {Polarisation Charges and Scattering Behaviour of Realistically Rounded Plasmonic Nanostructures},
  author = {Raziman, T V and Martin, Olivier J F},
  year = {2013},
  journal = {Optics express},
  volume = {21},
  number = {18},
  pages = {21500--21507},
  publisher = {Optica Publishing Group}
}

@article{reis2021,
  title = {Stochastic Preconditioning of Domain Decomposition Methods for Elliptic Equations with Random Coefficients},
  author = {Reis, Jo{\~a}o F. and Le Ma{\^i}tre, Olivier P. and Congedo, Pietro M. and Mycek, Paul},
  year = {2021},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {381},
  pages = {113845--113845},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.cma.2021.113845},
  abstract = {This paper aims at developing an efficient preconditioned iterative domain decomposition (DD) method for the sampling of linear stochastic elliptic equations. To this end, we consider a non-overlapping DD method resulting in a Symmetric Positive Definite (SPD) Schur system for almost every sampled problem. To accelerate the iterative solution of the Schur system, we propose a new stochastic preconditioning strategy that produces a preconditioner adapted to each sampled problem and converges toward the ideal preconditioner (i.e., the Schur operator itself) when the numerical parameters increase. The construction of the stochastic preconditioner is trivially parallel and takes place in an off-line stage, while the evaluation of the sample's preconditioner during the sampling stage has a low and fixed cost. One key feature of the proposed construction is a factorized form combined with Polynomial Chaos expansions of local operators. The factorized form guarantees the SPD character of the sampled preconditioners while the local character of the PC expansions ensures a low computational complexity. The stochastic preconditioner is tested on a model problem in 2 space dimensions. In these tests, the preconditioner is very robust and significantly more efficient than the deterministic median-based preconditioner, requiring, on average, up to 7 times fewer iterations to converge. Complexity analysis suggests the scalability of the preconditioner with the number of subdomains.},
  keywords = {Domain decomposition,Parallel computation,Preconditioned conjugate gradient method,Sampling method,Stochastic preconditioner},
  file = {/home/wouter/Zotero/storage/48WU6N5V/Reis et al. - 2021 - Stochastic preconditioning of domain decomposition methods for elliptic equations with random coefficients(2).pdf;/home/wouter/Zotero/storage/6U7ZBY6J/Reis et al. - 2021 - Stochastic preconditioning of domain decomposition methods for elliptic equations with random coefficients.pdf}
}

@article{reissell1996,
  title = {Wavelet Multiresolution Representation of Curves and Surfaces},
  author = {Reissell, L. M.},
  year = {1996},
  journal = {Graphical Models and Image Processing},
  volume = {58},
  number = {3},
  pages = {198--217},
  doi = {10.1006/gmip.1996.0017},
  abstract = {We develop wavelet methods for the multiresolution representation of parametric curves and surfaces. To support the representation, we construct a new family of compactly supported symmetric biorthogonal wavelets with interpolating scaling functions. The wavelets in these biorthogonal pairs have properties better suited for curves and surfaces than many commonly used filters. We also give examples of the applications of the wavelet approach: these include the derivation of compact hierarchical curve and surface representations using modified wavelet compression, the identification of smooth sections of surfaces, and a subdivision-like intersection algorithm for discrete plane curves. {\copyright} 1996 Academic Press, Inc.},
  file = {/home/wouter/Zotero/storage/D7I2ZWEU/Reissell - 1996 - Wavelet multiresolution representation of curves and surfaces.pdf}
}

@article{rieken2022,
  title = {A {{Scalable Approach Towards Real-Time Cable Ratings}} for {{Underground Medium Voltage Cables}}},
  author = {Rieken, Sander and Weelinck, Tim and Ressing, Joan and {van der Gun}, Daan and Gu, Tongyou},
  year = {2022},
  number = {September},
  pages = {109--113},
  doi = {10.1049/icp.2021.1959},
  abstract = {In this paper we describe an implementation of a scalable numerical model to calculate real-time cable ratings for underground medium voltage cables. Input data such as dynamic soil and weather data are automatically retrieved. The model can accommodate different cable types (both single-core and three-core cables) and realistic scenarios such as soil drying and mutual heating of cables. We found agreement within 3 {$\bullet$} C between model and measured temperatures on a cable circuit connecting a wind park, and agreement within 0.5 {$\bullet$} C for steady state temperatures calculated according to IEC standard 60287 and our model.},
  keywords = {dynamic cable rating,dynamic soil data,thermal bottleneck,wind park},
  file = {/home/wouter/Zotero/storage/NYTHL3WT/Rieken et al. - 2022 - a Scalable Approach Towards Real-Time Cable Ratings for Underground Medium Voltage Cables.pdf}
}

@incollection{riemenschneider2005,
  title = {B-Spline Based Empirical Mode Decomposition},
  booktitle = {Hilbert-Huang {{Transform And Its Applications}}},
  author = {Riemenschneider, Sherman and Liu, Bao and Xu, Yuesheng and Huang, Norden E.},
  year = {2005},
  month = sep,
  volume = {m},
  pages = {27--55},
  doi = {10.1142/9789812703347_0002},
  abstract = {This paper discusses some mathematical issues related to empirical mode decomposition (EMD). A B-spline EMD algorithm is introduced and developed for the convenience of mathematical studies. The numerical analysis using both simulated and practical signals and application examples from vibration analysis indicate that the B-spline algorithm has a comparable performance to that of the original EMD algorithm. It is also demonstrated that for white noise, the B-spline algorithm acts as a dyadic filter bank. Our mathematical results on EMD include Euler splines as intrinsic mode functions, the Hilbert transform of B-splines, and the necessary and sufficient conditions which ensure the validity of the Bedrosian identity of the Hilbert transform of product functions.},
  isbn = {978-981-270-334-7},
  file = {/home/wouter/Zotero/storage/CGHYG7L2/Riemenschneider et al. - 2005 - B-spline based empirical mode decomposition.pdf}
}

@article{robbins1955,
  title = {A {{Remark}} on {{Stirling}} ' s {{Formula}}},
  author = {Robbins, Herbert},
  year = {1955},
  journal = {Mathematical Association of America},
  volume = {62},
  number = {1},
  pages = {26--29},
  doi = {10.2307/2308012},
  file = {/home/wouter/Zotero/storage/RX37UJ4W/Robbins - 1955 - A Remark on Stirling ' s Formula.pdf}
}

@book{robert2004,
  title = {Monte {{Carlo}} Statistical Methods},
  author = {Robert, Christian P and Casella, George and Casella, George},
  year = {2004},
  volume = {2},
  publisher = {Springer}
}

@article{rousseeuw1987,
  title = {Silhouettes: {{A}} Graphical Aid to the Interpretation and Validation of Cluster Analysis},
  shorttitle = {Silhouettes},
  author = {Rousseeuw, Peter J.},
  year = {1987},
  month = nov,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {20},
  pages = {53--65},
  issn = {03770427},
  doi = {10.1016/0377-0427(87)90125-7},
  urldate = {2024-10-07},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/MZSK3HQD/Rousseeuw - 1987 - Silhouettes A graphical aid to the interpretation and validation of cluster analysis.pdf;/home/wouter/Zotero/storage/X4N8SQ9E/Rousseeuw - 1987 - Silhouettes A graphical aid to the interpretation and validation of cluster analysis.pdf}
}

@article{rozza2008,
  title = {Reduced Basis Approximation and a Posteriori Error Estimation for Affinely Parametrized Elliptic Coercive Partial Differential Equations: Application to Transport and Continuum Mechanics},
  author = {Rozza, Gianluigi and Huynh, Dinh Bao Phuong and Patera, Anthony T},
  year = {2008},
  journal = {Archives of Computational Methods in Engineering},
  volume = {15},
  number = {3},
  pages = {229--275},
  publisher = {Springer}
}

@book{saad2003,
  title = {Iterative {{Methods}} for {{Sparse Linear Systems}}},
  author = {Saad, Yousef},
  year = {2003},
  month = jan,
  journal = {Iterative Methods for Sparse Linear Systems},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898718003},
  abstract = {This paper presents an overview of parallel algorithms and their implementations forsolving large sparse linear systems which arise in scientific and engineering applications. Preconditioners constitute the most important ingredient in solving such systems. As will be seen, the most common preconditioners used for sparse linear systems adapt domain decomposition concepts to the more general framework of "distributed sparse linear systems". Variants of Schwarz procedures and Schur complement techniques will be discussed. We will also report on our own experience in the parallel implementation of a fairly complex simulation of solid-liquid flows. ?? 2001 Elsevier B.V. All rights reserved.},
  isbn = {978-0-89871-534-7},
  file = {/home/wouter/Zotero/storage/2G5WWAWZ/Saad - 2003 - Iterative Methods for Sparse Linear Systems.pdf}
}

@article{saito1987,
  title = {Schrodinger {{Operators With}} a},
  author = {Saito, Yoshimi},
  year = {1987},
  volume = {126},
  number = {2},
  file = {/home/wouter/Zotero/storage/CDWCK5L2/Saito - 1987 - Schrodinger Operators With a.pdf}
}

@article{salem2020,
  title = {An {{Experimental Study}} on {{Symmetry Breaking Constraints Impact}} for the {{One Dimensional Bin-Packing Problem}}},
  author = {Salem, Khadija Hadj and Kieffer, Yann},
  year = {2020},
  journal = {Proceedings of the 2020 Federated Conference on Computer Science and Information Systems, FedCSIS 2020},
  pages = {317--326},
  issn = {9788395541674},
  doi = {10.15439/2020F19},
  abstract = {We consider the classical One-Dimensional Bin Packing Problem (1D-BPP), an NP-hard optimization problem, where, a set of weighted items has to be packed into one or more identical capacitated bins. We give an experimental study on using symmetry breaking constraints for strengthening the classical integer linear programming proposed to optimally solve this problem. Our computational experiments are conducted on the data-sets found in BPPLib and the results have confirmed the theoretical results.},
  file = {/home/wouter/Zotero/storage/QNBKFC6U/Salem, Kieffer - 2020 - An Experimental Study on Symmetry Breaking Constraints Impact for the One Dimensional Bin-Packing Problem.pdf}
}

@misc{sauer2023,
  title = {Non-Stationary {{Gaussian Process Surrogates}}},
  author = {Sauer, Annie and Cooper, Andrew and Gramacy, Robert B.},
  year = {2023},
  month = may,
  number = {arXiv:2305.19242},
  eprint = {2305.19242},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2024-10-29},
  abstract = {We provide a survey of non-stationary surrogate models which utilize Gaussian processes (GPs) or variations thereof, including non-stationary kernel adaptations, partition and local GPs, and spatial warpings through deep Gaussian processes. We also overview publicly available software implementations and conclude with a bake-off involving an 8-dimensional satellite drag computer experiment. Code for this example is provided in a public git repository.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {/home/wouter/Zotero/storage/NSYZY2GD/Sauer et al. - 2023 - Non-stationary Gaussian Process Surrogates.pdf;/home/wouter/Zotero/storage/AE84HYCZ/2305.html}
}

@phdthesis{scarabosio2016,
  title = {Shape {{Uncertainty Quantification}} for {{Scattering Transmission Problems}}},
  author = {Scarabosio, Laura},
  year = {2016},
  abstract = {Permanent Link: https://doi.org/10.3929/ethz-a-010703504},
  isbn = {9783906327518},
  file = {/home/wouter/Zotero/storage/3E29QL5M/Scarabosio - 2016 - Shape Uncertainty Quantification for Scattering Transmission Problems.pdf}
}

@article{scarabosio2017,
  title = {Multilevel {{Monte Carlo}} on a High-Dimensional Parameter Space for Transmission Problems with Geometric Uncertainties},
  author = {Scarabosio, Laura},
  year = {2017},
  journal = {International Journal for Uncertainty Quantification},
  volume = {9},
  number = {6},
  pages = {515--541},
  doi = {10.1615/Int.J.UncertaintyQuantification.2019025335},
  abstract = {In the framework of uncertainty quantification, we consider a quantity of interest that depends nonsmoothly on the high-dimensional parameter representing the uncertainty. We show that, in this situation, the multilevel Monte Carlo algorithm is a valid option to compute moments of the quantity of interest (here we focus on the expectation), as it allows one to bypass the precise location of discontinuities in the parameter space. We illustrate how such lack of smoothness occurs for the point evaluation of the solution to a (Helmholtz) transmission problem with uncertain interface, if the point can be crossed by the interface for some realizations. For this case, we provide a space regularity analysis for the solution, in order to state convergence results in the L{$\infty$}-norm for the finite element discretization. The latter are then used to determine the optimal distribution of samples among the Monte Carlo levels. Particular emphasis is given on robustness of the estimates with respect to the dimension of the parameter space.},
  keywords = {Discontinuities,Interface problem,L-estimates,Multilevel Monte Carlo,Shape uncertainty},
  file = {/home/wouter/Zotero/storage/6TNT5FAG/Scarabosio - 2017 - Multilevel Monte Carlo on a high-dimensional parameter space for transmission problems with geometric uncertainties.pdf}
}

@article{scarabosio2022,
  title = {Deep {{Neural Network Surrogates}} for {{Nonsmooth Quantities}} of {{Interest}} in {{Shape Uncertainty Quantification}}},
  author = {Scarabosio, Laura},
  year = {2022},
  journal = {SIAM-ASA Journal on Uncertainty Quantification},
  volume = {10},
  number = {3},
  pages = {975--1011},
  doi = {10.1137/21M1393078},
  abstract = {We consider the point evaluation of the solution to interface problems with geometric uncertainties, where the uncertainty in the obstacle is described by a high-dimensional parameter y {$\in$} [-1, 1]d, d {$\in$} N. We focus in particular on an elliptic interface problem and a Helmholtz transmission problem. Point values of the solution in the physical domain depend in general nonsmoothly on the high-dimensional parameter, posing a challenge when one is interested in building surrogates. Indeed, high-order methods show poor convergence rates, while methods which are able to track discontinuities usually suffer from the so-called curse of dimensionality. For this reason, in this work we propose to build surrogates for point evaluation using deep neural networks. We provide a theoretical justification for why we expect neural networks to provide good surrogates. Furthermore, we present extensive numerical experiments showing their good performance in practice. We observe in particular that neural networks do not suffer from the curse of dimensionality, and we study the dependence of the error on the number of point evaluations (that is, the number of discontinuities in the parameter space), as well as on several modeling parameters, such as the contrast between the two materials and, for the Helmholtz transmission problem, the wavenumber.},
  keywords = {deep neural networks,Helmholtz,machine learning,random interface},
  file = {/home/wouter/Zotero/storage/LU4JF32Y/Scarabosio - 2022 - Deep Neural Network Surrogates for Nonsmooth Quantities of Interest in Shape Uncertainty Quantification.pdf}
}

@article{schatz1998,
  title = {Pointwise Error Estimates and Asymptotic Error Expansion Inequalities for the Finite Element Method on Irregular Grids: {{Part I}}. {{Global}} Estimates},
  author = {Schatz, Alfred},
  year = {1998},
  journal = {Mathematics of Computation},
  volume = {67},
  number = {223},
  pages = {877--899},
  doi = {10.1090/S0025-5718-98-00959-4},
  abstract = {This part contains new pointwise error estimates for the finite element method for second order elliptic boundary value problems on smooth bounded domains in R N {\textbackslash}mathbb \{R\}{\textasciicircum}\{N\} . In a sense to be discussed below these sharpen known quasi--optimal L {$\infty$} L\_\{{\textbackslash}infty \} and W {$\infty$} 1 W{\textasciicircum}\{1\}\_\{{\textbackslash}infty \} estimates for the error on irregular quasi--uniform meshes in that they indicate a more local dependence of the error at a point on the derivatives of the solution u u . We note that in general the higher order finite element spaces exhibit more local behavior than lower order spaces. As a consequence of these estimates new types of error expansions will be derived which are in the form of inequalities. These expansion inequalities are valid for large classes of finite elements defined on irregular grids in R N {\textbackslash}mathbb \{R\}{\textasciicircum}\{N\} and have applications to superconvergence and extrapolation and a posteriori estimates. Part II of this series will contain local estimates applicable to non--smooth problems.},
  file = {/home/wouter/Zotero/storage/RQ49AQUZ/Schatz - 1998 - Pointwise error estimates and asymptotic error expansion inequalities for the finite element method on irregular grids P.pdf}
}

@article{schillings2013,
  title = {Sparse, Adaptive {{Smolyak}} Quadratures for {{Bayesian}} Inverse Problems},
  author = {Schillings, Claudia and Schwab, Christoph},
  year = {2013},
  journal = {Inverse Problems},
  volume = {29},
  number = {6},
  doi = {10.1088/0266-5611/29/6/065011},
  abstract = {Based on the parametric deterministic formulation of Bayesian inverse problems with unknown input parameter from infinite-dimensional, separable Banach spaces proposed in Schwab and Stuart (2012 Inverse Problems 28 045003), we develop a practical computational algorithm whose convergence rates are provably higher than those of Monte Carlo (MC) and Markov chain Monte Carlo methods, in terms of the number of solutions of the forward problem. In the formulation of Schwab and Stuart, the forward problems are parametric, deterministic elliptic partial differential equations, and the inverse problem is to determine the unknown diffusion coefficients from noisy observations comprising linear functionals of the system's response. The sparsity of the generalized polynomial chaos representation of the posterior density being implied by sparsity assumptions on the class of the prior (Schwab and Stuart 2012), we design, analyze and implement a class of adaptive, deterministic sparse tensor Smolyak quadrature schemes for the efficient approximate numerical evaluation of expectations under the posterior, given data. The proposed, deterministic quadrature algorithm is based on a greedy, iterative identification of finite sets of most significant, 'active' chaos polynomials in the posterior density analogous to recently proposed algorithms for adaptive interpolation (Chkifa et al 2012 Report 2012-NN, 2013 Math. Modelling Numer. Anal. 47 253-80). Convergence rates for the quadrature approximation are shown, both theoretically and computationally, to depend only on the sparsity class of the unknown, but are bounded independently of the number of random variables activated by the adaptive algorithm. Numerical results for a model problem of coefficient identification with point measurements in a diffusion problem confirm the theoretical results. {\copyright} 2013 IOP Publishing Ltd.},
  file = {/home/wouter/Zotero/storage/XI9UJ92Z/Schillings, Schwab - 2013 - Sparse, adaptive Smolyak quadratures for Bayesian inverse problems.pdf}
}

@article{schneider2004,
  title = {Wavelets: {{Mathematical Theory}}},
  author = {Schneider, K. and Farge, M.},
  year = {2004},
  journal = {Encyclopedia of Mathematical Physics: Five-Volume Set},
  pages = {426--438},
  issn = {9780125126601},
  doi = {10.1016/B0-12-512666-2/00153-X},
  file = {/home/wouter/Zotero/storage/R2IC9Z7K/Schneider, Farge - 2004 - Wavelets Mathematical Theory.pdf}
}

@article{schoenberg1946,
  title = {Contributions to the Problem of Approximation of Equidistant Data by Analytic Functions. {{Part A}}. on the Problem of Smoothing or Graduation. {{A}} First Class of Analytic Approximation Formulae},
  author = {Schoenberg, Isaac Jacob},
  year = {1946},
  journal = {Quarterly of Applied Mathematics},
  volume = {4},
  number = {2},
  pages = {112--141},
  doi = {10.1090/qam/16705},
  abstract = {Introduction. Let there be given a sequence of ordinates \{yn\}(n=0,{\textpm}1{\textpm}2,{\dots}), \{ y n \} ( n = 0 , {\textpm} 1 {\textpm} 2 , {\dots} ) , corresponding to all integral values of the variable x = n. If these ordinates are the values of a known analytic function F(x), then the problem of interpolation between these ordinates has an obvious and precise meaning: we are required to compute intermediate values F(x) to the same accuracy to which the ordinates are known. Undoubtedly, the most convenient tool for the solution of this problem is the polynomial central interpolation method. It uses the polynomial of degree k --- 1, interpolating k successive ordinates, as an approximation to F(x) only within a unit interval in x, centrally located with respect to its k defining ordinates. Assuming k fixed, successive approximating arcs for F(x) are thus obtained which present discontinuities on passing from one arc to the next if k is odd, or discontinuities in their first derivatives if k is even (see section 2.121). Actually these discontinuities are irrelevant in our present case of an analytic function F(x). Indeed, if the interpolated values obtained are sufficiently accurate, these discontinuities will be apparent only if we force the computation beyond the intrinsic accuracy of the y n.},
  file = {/home/wouter/Zotero/storage/B37IJSLY/Schoenberg - 1946 - Contributions to the problem of approximation of equidistant data by analytic functions. Part A. on the problem of s.pdf}
}

@article{schonbek2014,
  title = {On a {{Helmholtz Style Decomposition}} for an {{Exterior Domain}}},
  author = {Schonbek, Tomas},
  year = {2014},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {46},
  number = {5},
  pages = {3497--3517},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/130940062},
  urldate = {2025-03-25},
  langid = {english}
}

@article{schwab2011,
  title = {Sparse Tensor Discretizations of High-Dimensional Parametric and Stochastic {{PDEs}}},
  author = {Schwab, Christoph and Gittelson, Claude Jeffrey},
  year = {2011},
  journal = {Acta Numerica},
  volume = {20},
  pages = {291--467},
  doi = {10.1017/S0962492911000055},
  abstract = {Partial differential equations (PDEs) with random input data, such as random loadings and coefficients, are reformulated as parametric, deterministic PDEs on parameter spaces of high, possibly infinite dimension. Tensorized operator equations for spatial and temporal k-point correlation functions of their random solutions are derived. Parametric, deterministic PDEs for the laws of the random solutions are derived. Representations of the random solutions' laws on infinite-dimensional parameter spaces in terms of 'generalized polynomial chaos' (GPC) series are established. Recent results on the regularity of solutions of these parametric PDEs are presented. Convergence rates of best N-term approximations, for adaptive stochastic Galerkin and collocation discretizations of the parametric, deterministic PDEs, are established. Sparse tensor products of hierarchical (multi-level) discretizations in physical space (and time), and GPC expansions in parameter space, are shown to converge at rates which are independent of the dimension of the parameter space. A convergence analysis of multi-level Monte Carlo (MLMC) discretizations of PDEs with random coefficients is presented. Sufficient conditions on the random inputs for superiority of sparse tensor discretizations over MLMC discretizations are established for linear elliptic, parabolic and hyperbolic PDEs with random coefficients. {\copyright} 2011 Cambridge University Press.},
  file = {/home/wouter/Zotero/storage/VS859VDD/Schwab, Gittelson - 2011 - Sparse tensor discretizations of high-dimensional parametric and stochastic PDEs.pdf}
}

@article{schwab2012,
  title = {Sparse Deterministic Approximation of {{Bayesian}} Inverse Problems},
  author = {Schwab, C. and Stuart, M. and Schwab, C. and Stuart, A. M.},
  year = {2012},
  journal = {Inverse Problems},
  volume = {28},
  number = {4},
  doi = {10.1088/0266-5611/28/4/045003},
  abstract = {We present a parametric deterministic formulation of Bayesian inverse problems with an input parameter from infinite-dimensional, separable Banach spaces. In this formulation, the forward problems are parametric, deterministic elliptic partial differential equations, and the inverse problem is to determine the unknown, parametric deterministic coefficients from noisy observations comprising linear functionals of the solution. We prove a generalized polynomial chaos representation of the posterior density with respect to the prior measure, given noisy observational data. We analyze the sparsity of the posterior density in terms of the summability of the input datas coefficient sequence. The first step in this process is to estimate the fluctuations in the prior. We exhibit sufficient conditions on the prior model in order for approximations of the posterior density to converge at a given algebraic rate, in terms of the number N of unknowns appearing in the parametric representation of the prior measure. Similar sparsity and approximation results are also exhibited for the solution and covariance of the elliptic partial differential equation under the posterior. These results then form the basis for efficient uncertainty quantification, in the presence of data with noise. {\copyright} 2012 IOP Publishing Ltd.},
  file = {/home/wouter/Zotero/storage/Y4RJ9BCY/Schwab et al. - 2012 - Sparse deterministic approximation of Bayesian inverse problems.pdf}
}

@article{schwab2019,
  title = {Deep Learning in High Dimension: {{Neural}} Network Expression Rates for Generalized Polynomial Chaos Expansions in {{UQ}}},
  author = {Schwab, Christoph and Zech, Jakob},
  year = {2019},
  month = jan,
  journal = {Analysis and Applications},
  volume = {17},
  number = {01},
  pages = {19--55},
  doi = {10.1142/S0219530518500203},
  abstract = {We estimate the expressive power of certain deep neural networks (DNNs for short) on a class of countably-parametric, holomorphic maps [Formula: see text] on the parameter domain [Formula: see text]. Dimension-independent rates of best [Formula: see text]-term truncations of generalized polynomial chaos (gpc for short) approximations depend only on the summability exponent of the sequence of their gpc expansion coefficients. So-called [Formula: see text]-holomorphic maps [Formula: see text], with [Formula: see text] for some [Formula: see text], are known to allow gpc expansions with coefficient sequences in [Formula: see text]. Such maps arise for example as response surfaces of parametric PDEs, with applications in PDE uncertainty quantification (UQ) for many mathematical models in engineering and the sciences. Up to logarithmic terms, we establish the dimension independent approximation rate [Formula: see text] for these functions in terms of the total number [Formula: see text] of units and weights in the DNN. It follows that certain DNN architectures can overcome the curse of dimensionality when expressing possibly countably-parametric, real-valued maps with a certain degree of sparsity in the sequences of their gpc expansion coefficients. We also obtain rates of expressive power of DNNs for countably-parametric maps [Formula: see text], where [Formula: see text] is the Hilbert space [Formula: see text].},
  keywords = {deep networks,Generalized polynomial chaos,sparse grids,uncertainty quantification},
  file = {/home/wouter/Zotero/storage/AH9GX9IL/Schwab, Zech - 2019 - Deep learning in high dimension Neural network expression rates for generalized polynomial chaos expansions in UQ.pdf}
}

@phdthesis{sciences2020,
  title = {Preconditioning Techniques for Elliptic Partial Differential Equations with Random Data},
  author = {Sciences, Physical},
  year = {2020},
  number = {August},
  file = {/home/wouter/Zotero/storage/BUWEUEGJ/Sciences - 2020 - Preconditioning techniques for elliptic partial differential equations with random data.pdf}
}

@article{scroggs2022,
  title = {Basix: A Runtime Finite Element Basis Evaluation Library},
  author = {Scroggs, Matthew W. and Baratta, Igor A. and Richardson, Chris N. and Wells, Garth N.},
  year = {2022},
  month = may,
  journal = {Journal of Open Source Software},
  volume = {7},
  number = {73},
  pages = {3982--3982},
  publisher = {Open Journals},
  doi = {10.21105/joss.03982},
  abstract = {{\dots} Basix is a C++ library that creates and tabulates a range of finite {\dots} library would use the information from FIAT to generate code that could be used by the C++ finite element library.},
  file = {/home/wouter/Zotero/storage/9UPAP97P/Scroggs et al. - 2022 - Basix a runtime finite element basis evaluation library.pdf}
}

@article{scroggs2022a,
  title = {Construction of {{Arbitrary Order Finite Element Degree-of-Freedom Maps}} on {{Polygonal}} and {{Polyhedral Cell Meshes}}},
  author = {Scroggs, Matthew W. and Dokken, J{\o}rgen S. and Richardson, Chris N. and Wells, Garth N.},
  year = {2022},
  month = jun,
  journal = {ACM Transactions on Mathematical Software},
  volume = {48},
  number = {2},
  pages = {1--23},
  doi = {10.1145/3524456},
  abstract = {We develop a method for generating degree-of-freedom maps for arbitrary order Ciarlet-type finite element spaces for any cell shape. The approach is based on the composition of permutations and transformations by cell sub-entity. Current approaches to generating degree-of-freedom maps for arbitrary order problems typically rely on a consistent orientation of cell entities that permits the definition of a common local coordinate system on shared edges and faces. However, while orientation of a mesh is straightforward for simplex cells and is a local operation, it is not a strictly local operation for quadrilateral cells and, in the case of hexahedral cells, not all meshes are orientable. The permutation and transformation approach is developed for a range of element types, including arbitrary degree Lagrange, serendipity, and divergence- and curl-conforming elements, and for a range of cell shapes. The approach is local and can be applied to cells of any shape, including general polytopes and meshes with mixed cell types. A number of examples are presented and the developed approach has been implemented in open-source libraries.},
  keywords = {degrees-of-freedom,Finite element methods,polyhedral cells},
  file = {/home/wouter/Zotero/storage/EAHKUT2Q/Scroggs et al. - 2022 - Construction of Arbitrary Order Finite Element Degree-of-Freedom Maps on Polygonal and Polyhedral Cell Meshes.pdf}
}

@article{scroggs2022b,
  title = {Construction of {{Arbitrary Order Finite Element Degree-of-Freedom Maps}} on {{Polygonal}} and {{Polyhedral Cell Meshes}}},
  author = {Scroggs, Matthew W. and Dokken, J{\o}rgen S. and Richardson, Chris N. and Wells, Garth N.},
  year = {2022},
  month = jun,
  journal = {ACM Transactions on Mathematical Software},
  volume = {48},
  number = {2},
  pages = {1--23},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3524456},
  urldate = {2024-09-30},
  abstract = {We develop a method for generating degree-of-freedom maps for arbitrary order Ciarlet-type finite element spaces for any cell shape. The approach is based on the composition of permutations and transformations by cell sub-entity. Current approaches to generating degree-of-freedom maps for arbitrary order problems typically rely on a consistent orientation of cell entities that permits the definition of a common local coordinate system on shared edges and faces. However, while orientation of a mesh is straightforward for simplex cells and is a local operation, it is not a strictly local operation for quadrilateral cells and, in the case of hexahedral cells, not all meshes are orientable. The permutation and transformation approach is developed for a range of element types, including arbitrary degree Lagrange, serendipity, and divergence- and curl-conforming elements, and for a range of cell shapes. The approach is local and can be applied to cells of any shape, including general polytopes and meshes with mixed cell types. A number of examples are presented and the developed approach has been implemented in open-source libraries.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/R5KNZVZC/Scroggs et al. - 2022 - Construction of Arbitrary Order Finite Element Degree-of-Freedom Maps on Polygonal and Polyhedral Ce.pdf}
}

@article{scroggs2022c,
  title = {Basix: A Runtime Finite Element Basis Evaluationlibrary},
  shorttitle = {Basix},
  author = {Scroggs, Matthew W. and Baratta, Igor A. and Richardson, Chris N. and Wells, Garth N.},
  year = {2022},
  month = may,
  journal = {Journal of Open Source Software},
  volume = {7},
  number = {73},
  pages = {3982},
  issn = {2475-9066},
  doi = {10.21105/joss.03982},
  urldate = {2024-09-30},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  file = {/home/wouter/Zotero/storage/LKGJWUDA/Scroggs et al. - 2022 - Basix a runtime finite element basis evaluationlibrary.pdf}
}

@article{selesnick2002,
  title = {The Design of Approximate {{Hilbert}} Transform Pairs of Wavelet Bases},
  author = {Selesnick, Ivan W.},
  year = {2002},
  journal = {IEEE Transactions on Signal Processing},
  volume = {50},
  number = {5},
  pages = {1144--1152},
  doi = {10.1109/78.995070},
  abstract = {Several authors have demonstrated that significant improvements can be obtained in wavelet-based signal processing by utilizing a pair of wavelet transforms where the wavelets form a Hilbert transform pair. This paper describes design procedures, based on spectral factorization, for the design of pairs of dyadic wavelet bases where the two wavelets form an approximate Hilbert transform pair. Both orthogonal and biorthogonal FIR solutions are presented, as well as IIR solutions. In each case, the solution depends on an allpass filter having a flat delay response. The design procedure allows for an arbitrary number of vanishing wavelet moments to be specified. A Matlab program for the procedure is given, and examples are also given to illustrate the results.},
  keywords = {Dual-tree complex wavelet transform,Hilbert transform,Wavelet transforms},
  file = {/home/wouter/Zotero/storage/J2RW3XQG/Selesnick - 2002 - The design of approximate Hilbert transform pairs of wavelet bases.pdf}
}

@article{serrano1996,
  title = {Some Remarks about Compactly Supported Spline Wavelets},
  author = {Serrano, E. P.},
  year = {1996},
  journal = {Applied and Computational Harmonic Analysis},
  volume = {3},
  number = {1},
  pages = {57--64},
  doi = {10.1006/acha.1996.0004},
  abstract = {In this paper we propose an extended family of almost orthogonal spline wavelets with compact support. These functions provide snug bases for L2 ({$R$}), preserving semiorthogonal properties. As it is well known, orthogonality is a desirable quality while finite support has attractive features for numerical applications. This work represents an effort to combine these conditions in the spline case and to enhance previous results of Chui and Unser et al. We start by reviewing the concept of semiorthogonal wavelets and we discuss their performance. Next, we give a brief description of the general technique for computing compactly supported spline wavelets. Finally we expose these functions. We also develop several formulas in accord with our purposes. {\copyright} 1996 Academic Press, Inc.},
  file = {/home/wouter/Zotero/storage/C5SAASAG/Serrano - 1996 - Some remarks about compactly supported spline wavelets.pdf}
}

@article{serrin1999,
  title = {Weakly {{Subharmonic Function}}},
  author = {Serrin, James},
  year = {1999},
  journal = {Bollettino dell'Unione Matematica Italiana},
  volume = {4},
  pages = {347--361},
  file = {/home/wouter/Zotero/storage/AWZ542U8/Serrin - 1999 - Weakly Subharmonic Function.pdf}
}

@article{serrin2011,
  title = {Weakly Subharmonic Function},
  author = {Serrin, James},
  year = {2011},
  journal = {Bollettino dell'Unione Matematica Italiana},
  volume = {4},
  number = {3},
  pages = {347--361}
}

@article{sharpio1999,
  title = {Harmonic Functions in the Unit Disk},
  author = {Sharpio, Victor L.},
  year = {1999},
  journal = {Journal of Mathematical Analysis and Applications},
  volume = {235},
  number = {2},
  pages = {470--477},
  doi = {10.1006/jmaa.1999.6377},
  abstract = {Complex-valued harmonic functions that are univalent and sense-preserving in the unit disk {$\Delta$} can be written in the form f=h+{\=g}, where h and g are analytic in {$\Delta$}. We give univalence criteria and sufficient coefficient conditions for normalized harmonic functions that are starlike of order {$\alpha$}, 0{$\leq\alpha<$}1. These coefficient conditions are also shown to be necessary when h has negative and g has positive coefficients. These lead to extreme points and distortion bounds. {\copyright} 1999 Academic Press.},
  keywords = {Harmonic,sense-preserving,starlike,univalent},
  file = {/home/wouter/Zotero/storage/PJF3LLGN/Sharpio - 1999 - Harmonic functions in the unit disk.pdf}
}

@article{shende2022,
  title = {Systematic Cost Analysis of Gradient- and Anisotropy-Enhanced {{Bayesian}} Design Optimization},
  author = {Shende, Sourabh and Gillman, Andrew and Buskohl, Philip and Vemaganti, Kumar},
  year = {2022},
  month = aug,
  journal = {Structural and Multidisciplinary Optimization},
  volume = {65},
  number = {8},
  pages = {235},
  issn = {1615-147X, 1615-1488},
  doi = {10.1007/s00158-022-03324-8},
  urldate = {2024-09-24},
  langid = {english},
  file = {/home/wouter/Zotero/storage/HSDZM8IK/Shende et al. - 2022 - Systematic cost analysis of gradient- and anisotropy-enhanced Bayesian design optimization.pdf}
}

@article{sherali1988,
  title = {{{NP-Hard}}, {{Capacitated}}, {{Balanced}} {\emph{p}} -{{Median Problems}} on a {{Chain Graph}} with a {{Continuum}} of {{Link Demands}}},
  author = {Sherali, Hanif D. and Nordai, Frederick L.},
  year = {1988},
  month = feb,
  journal = {Mathematics of Operations Research},
  volume = {13},
  number = {1},
  pages = {32--49},
  issn = {0364-765X, 1526-5471},
  doi = {10.1287/moor.13.1.32},
  urldate = {2024-09-13},
  abstract = {This paper introduces the analysis of capacitated p-median location-allocation problems on networks in which there may exist a continuum of demand on the links characterized by some demand distribution or density functions. We address the particular case of locating a given set of p capacitated facilities on a chain graph for which the total supply is equal to the total expected demand. This problem is demonstrated to be NP-hard, even when the demand is discrete and restricted to occur only at the nodes of the chain graph, or when the demand density function is symmetric and unimodal. However, the separate location and allocation subproblems are efficiently solvable, and provide a useful characterization for an optimal solution to the p-median problem. Based on this characterization, we analyze the monotone demand distribution case which admits a closed form greedy solution, and we also analyze problems having nonsymmetric or symmetric unimodal demand distributions. This analysis lays the groundwork for an enumerative type of algorithm for problems with more general demand distribution functions.},
  langid = {english},
  file = {/home/wouter/Zotero/storage/9AF7937E/Sherali and Nordai - 1988 - NP-Hard, Capacitated, Balanced p -Median Problems on a Chain Graph with a Continuum of Link D.pdf}
}

@article{shirron1998,
  title = {A Comparison of Approximate Boundary Conditions and Infinite Element Methods for Exterior {{Helmholtz}} Problems},
  author = {Shirron, Joseph J. and Babu{\v s}ka, Ivo},
  year = {1998},
  month = oct,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {164},
  number = {1-2},
  pages = {121--139},
  issn = {00457825},
  doi = {10.1016/S0045-7825(98)00050-4},
  urldate = {2025-03-19},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/XRC98PZB/Shirron and Babuška - 1998 - A comparison of approximate boundary conditions and infinite element methods for exterior Helmholtz.pdf}
}

@article{simpson2022,
  title = {Regularized {{Saddle-Free Newton}} : {{Saddle Avoidance}} and {{E}} Cient {{Implementation}} By},
  author = {Simpson, Cooper R},
  year = {2022},
  file = {/home/wouter/Zotero/storage/T838YK3J/Simpson - 2022 - Regularized Saddle-Free Newton Saddle Avoidance and E cient Implementation by.pdf}
}

@article{sloan1998,
  title = {When {{Are Quasi-Monte Carlo Algorithms Efficient}} for {{High Dimensional Integrals}}?},
  author = {Sloan, Ian H. and Wo{\'z}niakowski, Henryk},
  year = {1998},
  journal = {Journal of Complexity},
  volume = {14},
  number = {1},
  pages = {1--33},
  doi = {10.1006/jcom.1997.0463},
  abstract = {Recently, quasi-Monte Carlo algorithms have been successfully used for multivariate integration of high dimension d, and were significantly more efficient than Monte Carlo algorithms. The existing theory of the worst case error bounds of quasi-Monte Carlo algorithms does not explain this phenomenon. This paper presents a partial answer to why quasi-Monte Carlo algorithms can work well for arbitrarily large d. It is done by identifying classes of functions for which the effect of the dimension d is negligible. These are weighted classes in which the behavior in the successive dimensions is moderated by a sequence of weights. We prove that the minimal worst case error of quasi-Monte Carlo algorithms does not depend on the dimension d iff the sum of the weights is finite. We also prove that the minimal number of function values in the worst case setting needed to reduce the initial error by {$\varepsilon$} is bounded by C{$\varepsilon$}-p, where the exponent p {$\in$} [1, 2], and C depends exponentially on the sum of weights. Hence, the relatively small sum of the weights makes some quasi-Monte Carlo algorithms strongly tractable. We show in a nonconstructive way that many quasi-Monte Carlo algorithms are strongly tractable. Even random selection of sample points (done once for the whole weighted class of functions and then the worst case error is established for that particular selection, in contrast to Monte Carlo where random selection of sample points is carried out for a fixed function) leads to strong tractable quasi-Monte Carlo algorithms. In this case the minimal number of function values in the worst case setting is of order {$\varepsilon$}-p with the exponent p = 2. The deterministic construction of strongly tractable quasi-Monte Carlo algorithms as well as the minimal exponent p is open. {\copyright} 1998 Academic Press.},
  file = {/home/wouter/Zotero/storage/WK7RHJJ3/Sloan, Woźniakowski - 1998 - When Are Quasi-Monte Carlo Algorithms Efficient for High Dimensional Integrals.pdf}
}

@book{smith2024,
  title = {Uncertainty {{Quantification}}: {{Theory}}, {{Implementation}}, and {{Applications}}, {{Second Edition}}},
  shorttitle = {Uncertainty {{Quantification}}},
  author = {Smith, Ralph C.},
  year = {2024},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {Philadelphia, PA},
  doi = {10.1137/1.9781611977844},
  urldate = {2025-03-31},
  isbn = {978-1-61197-783-7 978-1-61197-784-4},
  langid = {english},
  file = {/home/wouter/Zotero/storage/FXSGSPDJ/Smith - 2024 - Uncertainty Quantification Theory, Implementation, and Applications, Second Edition.pdf;/home/wouter/Zotero/storage/XQCP7WUQ/output.pdf}
}

@inproceedings{snoek2012,
  title = {Practical {{Bayesian Optimization}} of {{Machine Learning Algorithms}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
  year = {2012},
  volume = {25},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-08-20},
  abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a "black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/4GPV5ZJV/Snoek et al. - 2012 - Practical Bayesian Optimization of Machine Learning Algorithms.pdf;/home/wouter/Zotero/storage/ZHQK2ILS/1206.html}
}

@article{soane2021,
  title = {Multigrid Preconditioners for Optimal Control Problems with Stochastic Elliptic {{PDE}} Constraints},
  author = {Soane, Ana Maria},
  year = {2021},
  journal = {International Journal of Computer Mathematics},
  volume = {98},
  number = {1},
  pages = {161--178},
  publisher = {Taylor \& Francis},
  doi = {10.1080/00207160.2020.1736575},
  abstract = {In this work, we construct multigrid preconditioners to be used in the solution process of pathwise optimal control problems constrained by elliptic partial differential equations with random coefficients. We use a sparse-grid collocation method to discretize in the stochastic space and multigrid techniques in the physical space. Numerical results show that the proposed preconditioners lead to significant computational savings, with the number of preconditioned conjugate gradient iterations decreasing as the resolution in the physical space increases.},
  keywords = {finite elements,multigrid methods,PDE-constrained optimization,stochastic collocation},
  file = {/home/wouter/Zotero/storage/ZBACTSRZ/Soane - 2021 - Multigrid preconditioners for optimal control problems with stochastic elliptic PDE constraints.pdf}
}

@article{sobol1990,
  title = {Quasi-{{Monte Carlo}} Methods},
  author = {Sobo{\'l}, Il'ya M.},
  year = {1990},
  month = jan,
  journal = {Progress in Nuclear Energy},
  volume = {24},
  number = {1-3},
  pages = {55--61},
  issn = {01491970},
  doi = {10.1016/0149-1970(90)90022-W},
  urldate = {2025-05-13},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@book{soize2017,
  title = {Uncertainty {{Quantification}}: {{An Accelerated Course}} with {{Advanced Applications}} in {{Computational Engineering}}},
  shorttitle = {Uncertainty {{Quantification}}},
  author = {Soize, Christian},
  year = {2017},
  series = {Interdisciplinary {{Applied Mathematics}}},
  volume = {47},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-54339-0},
  urldate = {2025-03-26},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-319-54338-3 978-3-319-54339-0},
  langid = {english},
  file = {/home/wouter/Zotero/storage/HU7NYM4V/UQ_Soize-09Jan2017.pdf;/home/wouter/Zotero/storage/XDAGIF2V/Soize - 2017 - Uncertainty Quantification An Accelerated Course with Advanced Applications in Computational Engine.pdf}
}

@article{solin2020,
  title = {Hilbert Space Methods for Reduced-Rank {{Gaussian}} Process Regression},
  author = {Solin, Arno and S{\"a}rkk{\"a}, Simo},
  year = {2020},
  month = mar,
  journal = {Statistics and Computing},
  volume = {30},
  number = {2},
  pages = {419--446},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-019-09886-w},
  urldate = {2025-04-30},
  langid = {english},
  file = {/home/wouter/Zotero/storage/9IZZY5TU/Solin and Särkkä - 2020 - Hilbert space methods for reduced-rank Gaussian process regression.pdf}
}

@article{sommerfeld1912,
  title = {Die {{Greensche Funktion}} Der {{Schwingungslgleichung}}.},
  author = {Sommerfeld, Arnold},
  year = {1912},
  journal = {Jahresbericht der Deutschen Mathematiker-Vereinigung}
}

@article{southworth2021,
  title = {Fast Solution of Fully Implicit {{Runge-Kutta}} and Discontinuous {{Galerkin}} in Time for Numerical {{PDEs}}, {{Part I}}: The Linear Setting},
  author = {Southworth, Ben S. and Krzysik, Oliver and Pazner, Will and De Sterck, Hans},
  year = {2021},
  month = jan,
  journal = {arXiv Computer Science},
  pages = {1--30},
  abstract = {Fully implicit Runge-Kutta (IRK) methods have many desirable properties as time integration schemes in terms of accuracy and stability, but high-order IRK methods are not commonly used in practice with numerical PDEs due to the difficulty of solving the stage equations. This paper introduces a theoretical and algorithmic preconditioning framework for solving the systems of equations that arise from IRK methods applied to linear numerical PDEs (without algebraic constraints). This framework also naturally applies to discontinuous Galerkin discretizations in time. Under quite general assumptions on the spatial discretization that yield stable time integration, the preconditioned operator is proven to have condition number bounded by a small, order-one constant, independent of the spatial mesh and time-step size, and with only weak dependence on number of stages/polynomial order; for example, the preconditioned operator for 10th-order Gauss IRK has condition number less than two, independent of the spatial discretization and time step. The new method can be used with arbitrary existing preconditioners for backward Euler-type time stepping schemes, and is amenable to the use of three-term recursion Krylov methods when the underlying spatial discretization is symmetric. The new method is demonstrated to be effective on various high-order finite-difference and finite-element discretizations of linear parabolic and hyperbolic problems, demonstrating fast, scalable solution of up to 10th order accuracy. The new method consistently outperforms existing block preconditioning approaches, and in several cases, the new method can achieve 4th-order accuracy using Gauss integration with roughly half the number of preconditioner applications and wallclock time as required using standard diagonally implicit RK methods.},
  file = {/home/wouter/Zotero/storage/P6YSBL3D/Southworth et al. - 2021 - Fast solution of fully implicit Runge-Kutta and discontinuous Galerkin in time for numerical PDEs, Part I the.pdf}
}

@article{spence2014,
  title = {Wavenumber-{{Explicit Bounds}} in {{Time-Harmonic Acoustic Scattering}}},
  author = {Spence, E. A.},
  year = {2014},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {46},
  number = {4},
  pages = {2987--3024},
  issn = {0036-1410, 1095-7154},
  doi = {10.1137/130932855},
  urldate = {2025-02-04},
  langid = {english},
  file = {/home/wouter/Zotero/storage/HIYMR7S3/Spence - 2014 - Wavenumber-Explicit Bounds in Time-Harmonic Acoustic Scattering.pdf}
}

@article{staff2006,
  title = {Preconditioning of Fully Implicit {{Runge-Kutta}} Schemes for Parabolic {{PDEs}}},
  author = {Staff, Gunnar A. and Mardal, Kent-Andre and Nilssen, Trygve K.},
  year = {2006},
  journal = {Modeling, Identification and Control: A Norwegian Research Bulletin},
  volume = {27},
  number = {2},
  pages = {109--123},
  doi = {10.4173/mic.2006.2.3},
  file = {/home/wouter/Zotero/storage/XHBF7UQ5/Staff, Mardal, Nilssen - 2006 - Preconditioning of fully implicit Runge-Kutta schemes for parabolic PDEs.pdf}
}

@article{stein2003,
  title = {Mesh {{Moving Techniques}} for {{Fluid-Structure Interactions With Large Displacements}}},
  author = {Stein, Keith and Tezduyar, Tayfun E. and Benney, Richard J.},
  year = {2003},
  month = jan,
  journal = {Journal of Applied Mechanics},
  volume = {70},
  number = {1},
  pages = {58--63},
  issn = {0021-8936, 1528-9036},
  doi = {10.1115/1.1530635},
  urldate = {2025-04-28},
  abstract = {In computation of fluid-structure interactions, we use mesh update methods consisting of mesh-moving and remeshing-as-needed. When the geometries are complex and the structural displacements are large, it becomes even more important that the mesh moving techniques are designed with the objective to reduce the frequency of remeshing. To that end, we present here mesh moving techniques where the motion of the nodes is governed by the equations of elasticity, with selective treatment of mesh deformation based on element sizes as well as deformation modes in terms of shape and volume changes. We also present results from application of these techniques to a set of two-dimensional test cases.},
  langid = {english}
}

@article{stevenson2014,
  title = {Adaptive {{Wavelet Methods}} for {{Linear}} and {{Nonlinear Least-Squares Problems}}},
  author = {Stevenson, Rob},
  year = {2014},
  journal = {Foundations of Computational Mathematics},
  volume = {14},
  number = {2},
  pages = {237--283},
  doi = {10.1007/s10208-013-9184-6},
  abstract = {The adaptive wavelet Galerkin method for solving linear, elliptic operator equations introduced by Cohen et al. (Math Comp 70:27-75, 2001) is extended to nonlinear equations and is shown to converge with optimal rates without coarsening. Moreover, when an appropriate scheme is available for the approximate evaluation of residuals, the method is shown to have asymptotically optimal computational complexity. The application of this method to solving least-squares formulations of operator equations G(u) = 0, where G: H {$\rightarrow$} K{$\prime$}, is studied. For formulations of partial differential equations as first-order least-squares systems, a valid approximate residual evaluation is developed that is easy to implement and quantitatively efficient. {\copyright} 2014 SFoCM.},
  keywords = {Adaptive wavelet methods,Asymptotically optimal computational complexity,Galerkin discretization,Least-squares formulations of boundary value probl,Optimal convergence rates},
  file = {/home/wouter/Zotero/storage/IRUK3FYQ/Stevenson - 2014 - Adaptive Wavelet Methods for Linear and Nonlinear Least-Squares Problems.pdf}
}

@article{stolk2017,
  title = {An Improved Sweeping Domain Decomposition Preconditioner for the {{Helmholtz}} Equation},
  author = {Stolk, Christiaan C.},
  year = {2017},
  journal = {Advances in Computational Mathematics},
  volume = {43},
  number = {1},
  pages = {45--76},
  publisher = {Advances in Computational Mathematics},
  doi = {10.1007/s10444-016-9475-y},
  abstract = {In this paper we generalize and improve a recently developed domain decomposition preconditioner for the iterative solution of discretized Helmholtz equations. We introduce an improved method for transmission at the internal boundaries using perfectly matched layers. Simultaneous forward and backward sweeps are introduced, thereby improving the possibilities for parallellization. Finally, the method is combined with an outer two-grid iteration. The method is studied theoretically and with numerical examples. It is shown that the modifications lead to substantial decreases in computation time and memory use, so that computation times become comparable to that of the fastests methods currently in the literature for problems with up to 108 degrees of freedom.},
  keywords = {Domain decomposition,Helmholtz equation,High-frequency waves,Multigrid method,Perfectly matched layers},
  file = {/home/wouter/Zotero/storage/U3YCE2RU/Stolk - 2017 - An improved sweeping domain decomposition preconditioner for the Helmholtz equation.pdf}
}

@article{stramer2001,
  title = {Monte {{Carlo Statistical Methods}}},
  author = {Stramer, Osnat},
  year = {2001},
  journal = {Journal of the American Statistical Association},
  volume = {96},
  number = {453},
  pages = {339--355},
  issn = {0387212396},
  doi = {10.1198/jasa.2001.s372},
  file = {/home/wouter/Zotero/storage/4WLPZ3TM/Stramer - 2001 - Monte Carlo Statistical Methods.pdf}
}

@article{sturm2018,
  title = {Shape Optimisation with Nearly Conformal Transformations {$\ast$} {\textasciiacute}},
  author = {Sturm, Kevin and Wechsung, Florian},
  year = {2018},
  pages = {1--28},
  keywords = {1,46e22,49q10,65dxx,93b40,ams subject classifications,cauchy-riemann equa-,conformal mappings,grid deformation,introduction,pde constrained shape optimisation,reproducing kernel hilbert spaces,shape optimisation is concerned,tions,with the minimisation of},
  file = {/home/wouter/Zotero/storage/G8Q8V682/Sturm, Wechsung - 2018 - Shape optimisation with nearly conformal transformations ∗ ´.pdf}
}

@inproceedings{sudret2017,
  title = {Surrogate Models for Uncertainty Quantification: {{An}} Overview},
  shorttitle = {Surrogate Models for Uncertainty Quantification},
  booktitle = {2017 11th {{European Conference}} on {{Antennas}} and {{Propagation}} ({{EUCAP}})},
  author = {Sudret, Bruno and Marelli, Stefano and Wiart, Joe},
  year = {2017},
  month = mar,
  pages = {793--797},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.23919/EuCAP.2017.7928679},
  urldate = {2025-04-10},
  isbn = {978-88-907018-7-0},
  file = {/home/wouter/Zotero/storage/ZMLZ4YVD/Sudret et al. - 2017 - Surrogate models for uncertainty quantification An overview.pdf}
}

@book{sullivan2015,
  title = {Introduction to {{Uncertainty Quantification}}},
  author = {Sullivan, Tim},
  year = {2015},
  series = {Texts in {{Applied Mathematics}}},
  number = {63},
  publisher = {Springer},
  address = {Cham Heidelberg New York Dordrecht London},
  doi = {10.1007/978-3-319-23395-6},
  isbn = {978-3-319-23394-9 978-3-319-23395-6},
  langid = {english},
  file = {/home/wouter/Zotero/storage/YERDK5VD/Sullivan - 2015 - Introduction to Uncertainty Quantification.pdf}
}

@misc{swersky2014,
  title = {Raiders of the {{Lost Architecture}}: {{Kernels}} for {{Bayesian Optimization}} in {{Conditional Parameter Spaces}}},
  shorttitle = {Raiders of the {{Lost Architecture}}},
  author = {Swersky, Kevin and Duvenaud, David and Snoek, Jasper and Hutter, Frank and Osborne, Michael A.},
  year = {2014},
  month = sep,
  number = {arXiv:1409.4011},
  eprint = {1409.4011},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2024-10-25},
  abstract = {In practical Bayesian optimization, we must often search over structures with differing numbers of parameters. For instance, we may wish to search over neural network architectures with an unknown number of layers. To relate performance data gathered for different architectures, we define a new kernel for conditional parameter spaces that explicitly includes information about which parameters are relevant in a given structure. We show that this kernel improves model quality and Bayesian optimization results over several simpler baseline kernels.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/XFKU9QF3/Swersky et al. - 2014 - Raiders of the Lost Architecture Kernels for Bayesian Optimization in Conditional Parameter Spaces.pdf;/home/wouter/Zotero/storage/F96AS9NZ/1409.html}
}

@article{sylvester1990,
  title = {The {{Dirichlet}} to {{Neumann}} Map and Applications},
  author = {Sylvester, J and Uhlmann, G},
  year = {1990},
  journal = {Proceedings of the Conference ``Inverse problems in partial differential equations (Arcata, 1989)'', SIAM, Philadelphia},
  number = {February},
  pages = {101--139},
  abstract = {0. Introduction The subject of electrical impedance tomography has been extensively studied in the past few years. Substantial progress has been made in both the theoretical and applied aspects of the problem. We survey in this paper mathematical results pertaining to the case where the full Dirichlet to Neumann map (or voltage to current map) is known. We also discuss connections with other inverse problems such as inverse scattering and inverse spectral problems. For other closely related issues we refer to the article by Isakov in these proceedings. 1. Electrical impedance tomography; the isotropic case. In this section we formulate the inverse conductivity problem and a similar problem for the Schr{\"o}dinger equation at zero energy. Let {\textohm} {$\subseteq$} n n {$\geq$} 2, be a smooth bounded domain. If the conductivity of {\textohm} is independent of direction (isotropic case) it is represented by a positive function, which we assume in C 1,1 ({\textohm}), with a positive lower bound. If we assume that there are no sources or sinks of current in {\textohm}, the conductivity equation for the potential u in {\textohm} is (1.1) L {$\gamma$} u = div ({$\gamma$}∇u) = 0 in {\textohm}. If f represents the induced potential on the boundary (assume f {$\in$} H 1 2 ({$\partial\Omega$})), u {$\in$} H 1 ({\textohm}) solves the Dirichlet problem L {$\gamma$} u = 0 in {\textohm} (1.2) u{\textbar} {$\partial\Omega$} = f. The Dirichlet to Neumann map is then defined by (1.3) {$\Lambda$} {$\gamma$} (f) = {$\gamma$} {$\partial$}u {$\partial\nu$}},
  file = {/home/wouter/Zotero/storage/3YKDMDEL/Sylvester, Uhlmann - 1990 - The Dirichlet to Neumann map and applications.pdf}
}

@article{tartakovsky2006,
  title = {Stochastic Analysis of Transport in Tubes with Rough Walls},
  author = {Tartakovsky, Daniel M. and Xiu, Dongbin},
  year = {2006},
  month = sep,
  journal = {Journal of Computational Physics},
  volume = {217},
  number = {1},
  pages = {248--259},
  doi = {10.1016/j.jcp.2006.02.029},
  abstract = {Flow and transport in tubes with rough surfaces play an important role in a variety of applications. Often the topology of such surfaces cannot be accurately described in all of its relevant details due to either insufficient data or measurement errors or both. In such cases, this topological uncertainty can be efficiently handled by treating rough boundaries as random fields, so that an underlying physical phenomenon is described by deterministic or stochastic differential equations in random domains. To deal with this class of problems, we use a computational framework, which is based on stochastic mappings to transform the original deterministic/stochastic problem in a random domain into a stochastic problem in a deterministic domain. The latter problem has been studied more extensively and existing analytical/numerical techniques can be readily applied. In this paper, we employ both a generalized polynomial chaos and Monte Carlo simulations to solve the transformed stochastic problem. We use our approach to describe transport of a passive scalar in Stokes' flow and to quantify the corresponding predictive uncertainty. {\copyright} 2006 Elsevier Inc. All rights reserved.},
  keywords = {Differential equations,Dispersion,Random domain,Stochastic inputs,Stokes' flow,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/3UIK3YA4/Tartakovsky, Xiu - 2006 - Stochastic analysis of transport in tubes with rough walls.pdf}
}

@article{tartakovsky2021,
  title = {Physics-Informed Machine Learning with Conditional {{Karhunen-Lo{\`e}ve}} Expansions},
  author = {Tartakovsky, A. M. and {Barajas-Solano}, D. A. and He, Q.},
  year = {2021},
  journal = {Journal of Computational Physics},
  volume = {426},
  doi = {10.1016/j.jcp.2020.109904},
  abstract = {We present a new physics-informed machine learning approach for the inversion of partial differential equation (PDE) models with heterogeneous parameters. In our approach, the space-dependent partially observed parameters and states are approximated via Karhunen-Lo{\`e}ve expansions (KLEs). Each of these KLEs is then conditioned on their corresponding measurements, resulting in low-dimensional models of the parameters and states that resolve observed data. Finally, the coefficients of the KLEs are estimated by minimizing the norm of the residual of the PDE model evaluated at a finite set of points in the computational domain, ensuring that the reconstructed parameters and states are consistent with both the observations and the PDE model to an arbitrary level of accuracy. In our approach, KLEs are constructed using the eigendecomposition of covariance models of spatial variability. For the model parameters, we employ a parameterized covariance model calibrated on parameter observations; for the model states, the covariance is estimated from a number of forward simulations of the PDE model corresponding to realizations of the parameters drawn from their KLE. We apply the proposed approach to identify heterogeneous diffusion coefficients in diffusion equations from sparse measurements of the diffusion coefficient and the solution of the diffusion equation. We find that the proposed approach compares favorably against state-of-the-art point estimates such as maximum a posteriori estimation and physics-informed neural networks.},
  keywords = {Conditional Karhunen-Loeve expansions,Machine learning,Model inversion,Parameter estimation},
  file = {/home/wouter/Zotero/storage/YLTTE5D6/Tartakovsky, Barajas-Solano, He - 2021 - Physics-informed machine learning with conditional Karhunen-Loève expansions.pdf}
}

@article{tay2008,
  title = {Daubechies Wavelets as Approximate {{Hilbert-pairs}}?},
  author = {Tay, David B.H.},
  year = {2008},
  journal = {IEEE Signal Processing Letters},
  volume = {15},
  pages = {57--60},
  doi = {10.1109/LSP.2007.910318},
  abstract = {A Hilbert-pair is a pair of wavelets that are Hilbert transforms of each other. A perfect reconstruction multirate filter bank defines a wavelet if the infinite product formula converges. If one chooses two filter banks arbitrarily, in general, the Hilbert transform relationship is not well approximated. This letter reports on an interesting discovery about the celebrated family of orthonormal Daubechies filters with maximum vanishing moments. It is found that if two filters whose lengths differ by four are chosen from this family, a Hilbert-pair of reasonable approximation quality is obtained. An explanation for this discovery is provided, and lessons that can be learned are discussed. {\copyright} 2007 IEEE.},
  keywords = {Complex wavelet,Dual-tree,Hilbert pair,Orthonormal filter banks},
  file = {/home/wouter/Zotero/storage/YKSRLXAR/Tay - 2008 - Daubechies wavelets as approximate Hilbert-pairs.pdf}
}

@article{teckentrup2013,
  title = {Further Analysis of Multilevel {{Monte Carlo}} Methods for Elliptic {{PDEs}} with Random Coefficients},
  author = {Teckentrup, Aretha L. and Scheichl, Robert and Giles, Michael B. and Ullmann, Elisabeth},
  year = {2013},
  month = nov,
  journal = {Numerische Mathematik},
  volume = {125},
  number = {3},
  pages = {569--600},
  issn = {0029-599X, 0945-3245},
  doi = {10.1007/s00211-013-0546-4},
  urldate = {2025-05-13},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@misc{teckentrup2020,
  title = {Convergence of {{Gaussian Process Regression}} with {{Estimated Hyper-parameters}} and {{Applications}} in {{Bayesian Inverse Problems}}},
  author = {Teckentrup, Aretha L.},
  year = {2020},
  month = jul,
  number = {arXiv:1909.00232},
  eprint = {1909.00232},
  primaryclass = {cs, math, stat},
  publisher = {arXiv},
  urldate = {2024-09-03},
  abstract = {This work is concerned with the convergence of Gaussian process regression. A particular focus is on hierarchical Gaussian process regression, where hyper-parameters appearing in the mean and covariance structure of the Gaussian process emulator are a-priori unknown, and are learnt from the data, along with the posterior mean and covariance. We work in the framework of empirical Bayes, where a point estimate of the hyper-parameters is computed, using the data, and then used within the standard Gaussian process prior to posterior update. We provide a convergence analysis that (i) holds for any continuous function \$f\$ to be emulated; and (ii) shows that convergence of Gaussian process regression is unaffected by the additional learning of hyper-parameters from data, and is guaranteed in a wide range of scenarios. As the primary motivation for the work is the use of Gaussian process regression to approximate the data likelihood in Bayesian inverse problems, we provide a bound on the error introduced in the Bayesian posterior distribution in this context.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Numerical Analysis,Mathematics - Statistics Theory},
  file = {/home/wouter/Zotero/storage/KPZUHG8D/Teckentrup - 2020 - Convergence of Gaussian Process Regression with Estimated Hyper-parameters and Applications in Bayes.pdf;/home/wouter/Zotero/storage/QMXF28CR/1909.html}
}

@article{teixeira1997,
  title = {Perfectly {{Matched Layer}} in {{Cylindrical Coordinates}}},
  author = {Teixeira, F.L. and Chew, W.C.},
  year = {1997},
  journal = {IEEE Antennas and Propagation Society, AP-S International Symposium (Digest)},
  volume = {3},
  pages = {1908--1911},
  issn = {0780341783},
  doi = {10.1109/APS.1997.631652},
  file = {/home/wouter/Zotero/storage/8DRZ7NDD/Teixeira, Chew - 1997 - Perfectly Matched Layer in Cylindrical Coordinates.pdf}
}

@article{tezduyar1992,
  title = {A New Strategy for Finite Element Computations Involving Moving Boundaries and Interfaces-{{The}} Deforming-Spatial-Domain/Space-Time Procedure: {{I}}. {{The}} Concept and the Preliminary Numerical Tests},
  author = {Tezduyar, T. E. and Behr, M. and Liou, J.},
  year = {1992},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {94},
  number = {3},
  pages = {339--351},
  doi = {10.1016/0045-7825(92)90059-S},
  abstract = {A new strategy based on the stabilized space-time finite element formulation is proposed for computations involving moving boundaries and interfaces. In the deforming-spatial-domain/space-time (DSD/ST) procedure the variational formulation of a problem is written over its space-time domain, and therefore the deformation of the spatial domain with respect to time is taken into account automatically. Because the space-time mesh is generated over the space-time domain of the problem, within each time step, the boundary (or interface) nodes move with the boundary (or interface). Whether the motion of the boundary is specified or not, the strategy is nearly the same. If the motion of the boundary is unknown, then the boundary nodes move as defined by the other unknowns at the boundary (such as the velocity or the displacement). At the end of each time step a new spatial mesh covers the new spatial domain. For computational feasibility, the finite element interpolation functions are chosen to be discontinuous in time, and the fully discretized equations are solved one space-time slab at a time. {\copyright} 1992.},
  file = {/home/wouter/Zotero/storage/6RTF8MM9/Tezduyar, Behr, Liou - 1992 - A new strategy for finite element computations involving moving boundaries and interfaces-The deforming-sp.pdf}
}

@article{thesis2021,
  title = {Shape {{Uncertainty Quantification}} in {{Acoustic Scattering}}},
  author = {Thesis, Doctoral},
  year = {2021},
  file = {/home/wouter/Zotero/storage/DCFGMBLN/Thesis - 2021 - Shape Uncertainty Quantification in Acoustic Scattering.pdf}
}

@book{thompson1985,
  title = {Numerical {{Grid Generation}}},
  author = {Thompson, J. and Warsi, Z. and Mastin, C.},
  year = {1985},
  publisher = {Elsevier Science},
  abstract = {{\dots} Akses terbuka (open access), memberi keleluasaan kepada siapapun yang membutuhkan informasi khususnya melalui sumber daya {\dots} Dalam akses terbuka (open access), informasi dengan teknologi digital ada kebebasan untuk mengakses bagi siapa saja yang membutuhkan {\dots}},
  isbn = {‎ 978-0444009852},
  file = {/home/wouter/Zotero/storage/ZTPWXGFP/Thompson, Warsi, Mastin - 1985 - Numerical Grid Generation.pdf}
}

@article{thorndike1953,
  title = {Who Belongs in the Family?},
  author = {Thorndike, Robert L.},
  year = {1953},
  month = dec,
  journal = {Psychometrika},
  volume = {18},
  number = {4},
  pages = {267--276},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02289263},
  urldate = {2024-10-07},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/home/wouter/Zotero/storage/C842NBI6/Thorndike - 1953 - Who belongs in the family.pdf}
}

@article{tibshirani2001,
  title = {Estimating the {{Number}} of {{Clusters}} in a {{Data Set Via}} the {{Gap Statistic}}},
  author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
  year = {2001},
  month = jul,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {63},
  number = {2},
  pages = {411--423},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00293},
  urldate = {2024-10-07},
  abstract = {Summary             We propose a method (the `gap statistic') for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K-means or hierarchical), comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature.},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english},
  file = {/home/wouter/Zotero/storage/E4SXVLJH/Tibshirani et al. - 2001 - Estimating the Number of Clusters in a Data Set Via the Gap Statistic.pdf}
}

@article{todor2007,
  title = {Convergence Rates for Sparse Chaos Approximations of Elliptic Problems with Stochastic Coefficients},
  author = {Todor, Radu A. and Schwab, Christoph},
  year = {2007},
  journal = {IMA Journal of Numerical Analysis},
  volume = {27},
  number = {2},
  pages = {232--261},
  publisher = {Oxford University Press}
}

@book{trefethen2019,
  title = {Approximation {{Theory}} and {{Approximation Practice}}, {{Extended Edition}}},
  author = {Trefethen, Lloyd N.},
  year = {2019},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {Philadelphia, PA},
  doi = {10.1137/1.9781611975949},
  urldate = {2025-04-29},
  isbn = {978-1-61197-593-2 978-1-61197-594-9},
  langid = {english}
}

@article{truong2023,
  title = {A {{Fast}} and {{Simple Modification}} of {{Newton}}'s {{Method Avoiding Saddle Points}}},
  author = {Truong, Tuyen Trung and To, Tat Dat and Nguyen, Hang Tuan and Nguyen, Thu Hang and Nguyen, Hoang Phuong and Helmy, Maged},
  year = {2023},
  journal = {Journal of Optimization Theory and Applications},
  volume = {199},
  number = {2},
  pages = {805--830},
  publisher = {Springer US},
  doi = {10.1007/s10957-023-02270-9},
  abstract = {We propose in this paper New Q-Newton's method. The update rule is conceptually very simple, using the projections to the vector subspaces generated by eigenvectors of positive (correspondingly negative) eigenvalues of the Hessian. The main result of this paper roughly says that if a sequence \{ xn\} constructed by the method from a random initial point x converges, then the limit point is a critical point and not a saddle point, and the convergence rate is the same as that of Newton's method. A subsequent work has recently been successful incorporating Backtracking line search to New Q-Newton's method, thus resolving the global convergence issue observed for some (non-smooth) functions. An application to quickly find zeros of a univariate meromorphic function is discussed, accompanied with an illustration on basins of attraction.},
  keywords = {Backtracking line search,Newton-type method,Rate of convergence,Roots of univariate meromorphic functions,Saddle points},
  file = {/home/wouter/Zotero/storage/TTKSZVRT/Truong et al. - 2023 - A Fast and Simple Modification of Newton’s Method Avoiding Saddle Points.pdf}
}

@article{turkel1998,
  title = {Absorbing {{PML}} Boundary Layers for Wave-like Equations},
  author = {Turkel, E. and Yefet, A.},
  year = {1998},
  journal = {Applied Numerical Mathematics},
  volume = {27},
  number = {4},
  pages = {533--557},
  doi = {10.1016/S0168-9274(98)00026-9},
  abstract = {We consider absorbing layers that are extensions of the PML of Berenger (1994). These will be constructed both for time problems and for Helmholtz-like equations. We shall consider applications to electricity and magnetism and acoustics (with a mean flow) in both physical space and in the time Fourier space (Helmholtz equation). Numerical results are presented showing the efficiency of this condition for the time dependent Maxwell equations. {\copyright} 1998 Elsevier Science B.V. and IMACS. All rights reserved.},
  keywords = {Artificial boundary conditions,Computational electromagnetics},
  file = {/home/wouter/Zotero/storage/MHKK4AN5/Turkel, Yefet - 1998 - Absorbing PML boundary layers for wave-like equations.pdf}
}

@book{ulam1991,
  title = {Adventures of a {{Mathematician}}},
  author = {Ulam, Stanislaw M},
  year = {1991},
  publisher = {Univ of California Press}
}

@book{unique2011,
  title = {Foundations of {{Location Analysis}}},
  author = {Unique, Aflii},
  editor = {Eiselt, H. A. and Marianov, Vladimir},
  year = {2011},
  series = {International {{Series}} in {{Operations Research}} \& {{Management Science}}},
  volume = {155},
  pages = {23},
  publisher = {Springer US},
  address = {New York, NY},
  doi = {10.1007/978-1-4419-7572-0},
  abstract = {Seiring dengan kemajuan ilmu pengetahuan dan teknologi yang menjadi pusat perhatian dunia. Maka manusia dituntut untuk menciptakan peralatan-peralatan canggih untuk teknologi muktahir. Baik itu dalam bidang bisnis, perdagangan, kesehatan, militer, pendidikan, komunikasi dan budaya maupun bidang-bidang lainnya. Maka teknologi ini membawa perubahan pada peralatan-peralatan yang dulunya bekerja secara analog mulai dikembangkan secara digital, dan bahkan yang bekerjanya secara manual sekarang banyak dikembangkan secara otomatis, seperti kamera digital, handycam, dan sebagainya, dalam pembacaan pengukuran juga sudah dikembangkan ke dalam teknik digital. Contohnya perangkat Load Cell. Dan keuntungan menggunakan Load Cell adalah untuk mempermudah dalam pembacaan data untuk meminimalkan kesalahan dalam pembacaan data yang disebabkan adanya human error.Pada pemilihan Load Cell bertujuan untuk memilih kecocokan dalam membuat rancang bangun alat uji tarik kapasitas 3 ton, dimana dalam pemilihan ini kami memilih jenis load cell ``S'' karna alat yang kita rancang adalah uji tarik bukan uji tekan. Dengan kapasitas load cell 5 ton. Untuk membuat jarak aman dalam pengujian specimen ST41. Load Cell menggunakan system perangkat elektronik pengolahan data yang menjadi sebuah kurva tegangan regangan. Data-data yang diperoleh tersebut berupa besarnya pembebanan hasil dari pengujian specimen ST41. Kata},
  isbn = {978-1-4419-7571-3},
  file = {/home/wouter/Zotero/storage/TMFWB8PU/Unique - 2011 - Foundations of Location Analysis.pdf}
}

@inproceedings{unser1997,
  title = {Ten Good Reasons for Using Spline Wavelets},
  booktitle = {Wavelet {{Applications}} in {{Signal}} and {{Image Processing V}}},
  author = {Unser, Michael},
  year = {1997},
  volume = {3169},
  pages = {422--431},
  publisher = {SPIE},
  abstract = {The purpose of this note is to highlight some of the unique properties of spline wavelets. These wavelets can be classified in four categories: othogonal (Battle-Lemari{\'e}), semi-orthogonal (e.g., B-spline), shift-orthogonal, and biorthogonal (Cohen-Daubechies-Feauveau). Unlike most other wavelet bases, splines have explicit formulae in both the time and frequency domain, which greatly facilitates their manipulation. They allow for a progressive transition between the two extreme cases of a multiresolution: Haar's piecewise constant representation (spline of degree zero) versus Shannon's bandlimited model (which corresponds to a spline of infinite order). Spline wavelets are extremely regular and usually symmetric or anti-symmetric. They can be designed to have compact support and to achieve optimal time-frequency localization (B-spline wavelets). The underlying scaling functions are the B-splines, which are the shortest and most regular scaling functions of order L. Finally, splines have the best approximation properties among all known wavelets of a given order L. In other words, they are the best for approximating smooth functions.},
  keywords = {approximation,biorthogonal wavelets,regularity,smoothness,splines,time-frequency localization,wavelet basis},
  file = {/home/wouter/Zotero/storage/84ZCSDRM/Unser - 1997 - Ten good reasons for using spline wavelets.pdf}
}

@article{uster2000,
  title = {The Convergence of the {{Weiszfeld}} Algorithm},
  author = {{\"U}ster, H. and Love, R.F.},
  year = {2000},
  month = aug,
  journal = {Computers \& Mathematics with Applications},
  volume = {40},
  number = {4-5},
  pages = {443--451},
  issn = {08981221},
  doi = {10.1016/S0898-1221(00)00172-3},
  urldate = {2024-10-04},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/wouter/Zotero/storage/KH9A2QC4/Üster and Love - 2000 - The convergence of the Weiszfeld algorithm.pdf}
}

@article{vandervorst1993,
  title = {The Superlinear Convergence Behaviour of {{GMRES}}},
  author = {{Van der Vorst}, H. A. and Vuik, C.},
  year = {1993},
  journal = {Journal of Computational and Applied Mathematics},
  volume = {48},
  number = {3},
  pages = {327--341},
  doi = {10.1016/0377-0427(93)90028-A},
  abstract = {GMRES is a rather popular iterative method for the solution of nonsingular nonsymmetric linear systems. It is well known that GMRES often has a so-called superlinear convergence behaviour, i.e., the rate of convergence seems to improve as the iteration proceeds. For the conjugate gradients method this phenomenon has been related to a (modest) degree of convergence of the Ritz values. It has been observed in experiments that for GMRES too, changes in the convergence behaviour seem to be related to the convergence of Ritz values. In this paper we prove that as soon as eigenvalues of the original operator are sufficiently well approximated by Ritz values, GMRES from then on converges at least as fast as for a related system in which these eigenvalues (and their eigenvector components) are missing. {\copyright} 1993.},
  keywords = {convergence behaviour,Full Orthogonalization Method,GMRES,Krylov subspace,Ritz values},
  file = {/home/wouter/Zotero/storage/99GFS9V2/Van der Vorst, Vuik - 1993 - The superlinear convergence behaviour of GMRES.pdf}
}

@article{vanharten2024,
  title = {Exploiting Locality in Sparse Polynomial Approximation of Parametric Elliptic {{PDEs}} and Application to Parameterized Domains},
  author = {Harten, Wouter G. van and Scarabosio, Laura},
  year = {2024},
  month = jun,
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  issn = {2822-7840, 2804-7214},
  doi = {10.1051/m2an/2024050},
  urldate = {2024-09-10},
  abstract = {This work studies how the choice of the representation for parametric, spatially distributed inputs to elliptic partial differential equations (PDEs) affects the efficiency of a polynomial surrogate, based on Taylor expansion, for the parameter-to-solution map. In particular, we show potential advantages of representations using functions with localized supports. As model problem, we consider the steady-state diffusion equation, where the diffusion coefficient and right-hand side depend smoothly but potentially in a highly nonlinear way on a parameter y {$\in$} [-1,1]N. Following previous work for affine parameter dependence and for the lognormal case, we use pointwise instead of norm-wise bounds to prove lp-summability of the Taylor coefficients of the solution. As application, we consider surrogates for solutions to elliptic PDEs on parametric domains. Using a mapping to a nominal configuration, this case fits in the general framework, and higher convergence rates can be attained when modeling the parametric boundary via spatially localized functions. The theoretical results are supported by numerical experiments for the parametric domain problem, illustrating the efficiency of the proposed approach and providing further insight on numerical aspects. Although the methods and ideas are carried out for the steady-state diffusion equation, they extend easily to other elliptic and parabolic PDEs.},
  copyright = {https://www.edpsciences.org/en/authors/copyright-and-licensing},
  file = {/home/wouter/Zotero/storage/GGZU7J76/van Harten and Scarabosio - 2024 - Exploiting locality in sparse polynomial approximation of parametric elliptic PDEs and application t.pdf}
}

@inproceedings{vanharten2025,
  title = {Application of Particle-Based {{Bayesian}} Inversion to Underground Medium Voltage Power Cables in the {{Netherlands}}},
  booktitle = {{{CIRED}} 2025},
  author = {Harten, Wouter G. van and Heldens, Dirk and Scarabosio, Laura and Lord, Gabriel J. and Rieken, Sander},
  year = {2025},
  address = {Geneva}
}

@misc{vanharten2025a,
  title = {Distributed Preconditioning for the Parametric {{Helmholtz}} Equation},
  author = {Harten, Wouter G. van and Scarabosio, Laura},
  year = {2025},
  month = apr,
  number = {arXiv:2504.00886},
  eprint = {2504.00886},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.00886},
  urldate = {2025-04-24},
  abstract = {In this work, we address the efficient computation of parameterized systems of linear equations, with possible nonlinear parameter dependence. When the matrix is highly sensitive to the parameters, mean-based preconditioning might not be enough. For this scenario, we explore an approach in which several preconditioners are placed in the parameter space during a precomputation step. To determine the optimal placement of a limited number of preconditioners, we estimate the expected number of iterations with respect to a given preconditioner a priori and use a location-allocation strategy to optimize the placement of the preconditioners. We elaborate on our methodology for the Helmholtz problem with exterior Dirichlet scattering at high frequencies, and we estimate the expected number of GMRES iterations via a gray-box Gaussian process regression approach. We illustrate our approach in two practical applications: scattering in a domain with a parametric refractive index and scattering from a scatterer with parameterized shape. Using these numerical examples, we show how our methods leads to runtime savings of about an order of magnitude. Moreover, we investigate the effect of the parameter dimension and the importance of dimension anisotropy on their efficacy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Numerical Analysis,Mathematics - Numerical Analysis},
  file = {/home/wouter/Zotero/storage/383T59AX/Harten and Scarabosio - 2025 - Distributed preconditioning for the parametric Helmholtz equation.pdf;/home/wouter/Zotero/storage/FHJRKMVT/2504.html}
}

@article{venkovic2021,
  title = {Sampled Stochastic Elliptic Equations {{To}} Cite This Version : {{Recycling Krylov}} Subspace Strategies for Sequences of Sampled Stochastic Elliptic Equations},
  author = {Venkovic, Nicolas and Mycek, Paul and Giraud, Luc and Maitre, Olivier Le},
  year = {2021},
  file = {/home/wouter/Zotero/storage/P695LVG7/Venkovic et al. - 2021 - sampled stochastic elliptic equations To cite this version Recycling Krylov subspace strategies for sequences.pdf}
}

@article{venkovic2023,
  title = {Preconditioning Strategies for Stochastic Elliptic Partial Differential Equations {{To}} Cite This Version : {{HAL Id}} : Tel-04329556 {\textasciiacute} {{DE BORDEAUX DE L}} ' {{UNIVERSIT E Par Nicolas VENKOVIC Strat}} {\textasciiacute} Egies de Pr {\textasciiacute} Econditionnement Pour Equations Stochastiques Ellipt},
  author = {Venkovic, Nicolas},
  year = {2023},
  file = {/home/wouter/Zotero/storage/KPTKKLM6/Venkovic - 2023 - Preconditioning strategies for stochastic elliptic partial differential equations To cite this version HAL Id t.pdf}
}

@misc{venkovic2024,
  title = {Preconditioners Based on {{Voronoi}} Quantizers of Random Variable Coefficients for Stochastic Elliptic Partial Differential Equations},
  author = {Venkovic, Nicolas and Mycek, Paul and Ma{\^i}tre, Olivier Le and Giraud, Luc},
  year = {2024},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.07824},
  abstract = {A preconditioning strategy is proposed for the iterative solve of large numbers of linear systems with variable matrix and right-hand side which arise during the computation of solution statistics of stochastic elliptic partial differential equations with random variable coefficients sampled by Monte Carlo. Building on the assumption that a truncated Karhunen-Lo{\textbackslash}`\{e\}ve expansion of a known transform of the random variable coefficient is known, we introduce a compact representation of the random coefficient in the form of a Voronoi quantizer. The number of Voronoi cells, each of which is represented by a centroidal variable coefficient, is set to the prescribed number \$P\$ of preconditioners. Upon sampling the random variable coefficient, the linear system assembled with a given realization of the coefficient is solved with the preconditioner whose centroidal variable coefficient is the closest to the realization. We consider different ways to define and obtain the centroidal variable coefficients, and we investigate the properties of the induced preconditioning strategies in terms of average number of solver iterations for sequential simulations, and of load balancing for parallel simulations. Another approach, which is based on deterministic grids on the system of stochastic coordinates of the truncated representation of the random variable coefficient, is proposed with a stochastic dimension which increases with the number \$P\$ of preconditioners. This approach allows to bypass the need for preliminary computations in order to determine the optimal stochastic dimension of the truncated approximation of the random variable coefficient for a given number of preconditioners.},
  keywords = {1,are prevalent in modeling,elliptic partial differential equations,interative methods,introduction,numerous phenomena in physics,pdes,preconditioners,steady-state heat equation,stochastic pdes,such as the,tainty qantification,uncer-,voronoi quantizers},
  file = {/home/wouter/Zotero/storage/MC5H6W6F/Venkovic et al. - 2024 - Preconditioners based on Voronoi quantizers of random variable coefficients for stochastic elliptic partial dif.pdf}
}

@article{verma2017,
  title = {Polynomial Wavelets on the Unit Circle},
  author = {Verma, Ajeet Singh and Mathur, Pankaj},
  year = {2017},
  journal = {Numerical Algorithms},
  volume = {76},
  number = {4},
  pages = {977--992},
  publisher = {Numerical Algorithms},
  doi = {10.1007/s11075-017-0293-1},
  abstract = {In this paper, we have considered polynomial wavelets on unit circle. The scaling functions are considered to be the fundamental polynomials of the Lagrange interpolants on the equally spaced nodes different from the n roots of unity, which satisfy certain interpolatory conditions.},
  keywords = {Interpolation,Scaling functions,Two-scale relation,Wavelet},
  file = {/home/wouter/Zotero/storage/FAYVWWVY/Verma, Mathur - 2017 - Polynomial wavelets on the unit circle.pdf}
}

@article{vujadinovic2016,
  title = {On the {{Green Function}} of the {{Annulus}}},
  author = {Vujadinovic, Djordjije and Grossi, {\relax Massimo}.},
  year = {2016},
  month = jun,
  journal = {Analysis in Theory and Applications},
  volume = {32},
  number = {1},
  pages = {52--64},
  doi = {10.4208/ata.2016.v32.n1.5},
  abstract = {Using the Gegenbauer polynomials and the zonal harmonics functions we give some representation formula of the Green function in the annulus. We apply this result to prove some uniqueness results for some nonlinear elliptic problems.},
  file = {/home/wouter/Zotero/storage/T3BX85XX/Vujadinovic, Grossi - 2016 - On the Green Function of the Annulus.pdf}
}

@article{walter1999,
  title = {Periodic {{Wavelets}} from {{Scratch}}},
  author = {Walter, Gilbert G. and Cai, Luchuan},
  year = {1999},
  journal = {Journal of Computational Analysis and Applications},
  volume = {1},
  number = {1},
  pages = {25--41},
  doi = {10.1023/A:1022614519335},
  abstract = {Periodic wavelets can be constructed from most standard wavelets by periodization. In this work we first derive some of their properties and then construct the periodic wavelets directly from their Fourier series without reference to standard wavelets. Several examples are given some of which are not constructable from the usual wavelets on the real line.},
  keywords = {Dilation equation,Fourier series,Multiresolution,Orthogonal,Trigonometric polynomial},
  file = {/home/wouter/Zotero/storage/G88NGPBI/Walter, Cai - 1999 - Periodic Wavelets from Scratch.pdf}
}

@phdthesis{wang2018,
  title = {Preconditioning {{Stochastic Galerkin Methods}} of {{Diffusion Problems}} with {{Random Data}}},
  author = {Wang, Dongwu},
  year = {2018},
  school = {UC Irvine},
  file = {/home/wouter/Zotero/storage/Z9V9FG25/_.pdf}
}

@article{wang2019,
  title = {Efficient {{Spectral Stochastic Finite Element Methods}} for {{Helmholtz Equations}} with {{Random Inputs}}},
  author = {Wang, Guanjie and Liao, Qifeng},
  year = {2019},
  month = jan,
  journal = {East Asian Journal on Applied Mathematics},
  volume = {9},
  number = {3},
  pages = {601--621},
  issn = {2079-7370, 2079-7362},
  doi = {10.4208/eajam.140119.160219},
  urldate = {2025-02-24},
  file = {/home/wouter/Zotero/storage/3S95THRD/2019 - Efficient Spectral Stochastic Finite Element Methods for Helmholtz Equations with Random Inputs.pdf;/home/wouter/Zotero/storage/AFEQLCRB/eajm_2019.pdf}
}

@article{wang2022,
  title = {Block Triangular Preconditioning for Stochastic {{Galerkin}} Method},
  author = {Wang, Dongwu and Zheng, Bin and Chen, Long and Lin, Guang and Xu, Jinchao},
  year = {2022},
  month = oct,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {412},
  pages = {114298--114298},
  publisher = {Elsevier B.V.},
  doi = {10.1016/j.cam.2022.114298},
  abstract = {In this paper, we develop a new block triangular preconditioner for solving partial differential equations with random coefficients. We prove spectral bounds for the preconditioned system. Several numerical examples are provided to demonstrate the efficiency of this preconditioner, especially for stochastic problems with large variance.},
  keywords = {Block triangular preconditioner,Multigrid,Polynomial chaos,Stochastic Galerkin method},
  file = {/home/wouter/Zotero/storage/ZU8SNHLQ/Wang et al. - 2022 - Block triangular preconditioning for stochastic Galerkin method.pdf}
}

@article{wang2022a,
  title = {Variational Inference with {{NoFAS}}: {{Normalizing}} Flow with Adaptive Surrogate for Computationally Expensive Models},
  author = {Wang, Yu and Liu, Fang and Schiavazzi, Daniele E.},
  year = {2022},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {467},
  pages = {111454--111454},
  doi = {10.1016/j.jcp.2022.111454},
  abstract = {Fast inference of numerical model parameters from data is an important prerequisite to generate predictive models for a wide range of applications. Use of sampling-based approaches such as Markov chain Monte Carlo may become intractable when each likelihood evaluation is computationally expensive. New approaches combining variational inference with normalizing flow are characterized by a computational cost that grows only linearly with the dimensionality of the latent variable space, and rely on gradient-based optimization instead of sampling, providing a more efficient approach for Bayesian inference about the model parameters. Moreover, the cost of frequently evaluating an expensive likelihood can be mitigated by replacing the true model with an offline trained surrogate model, such as neural networks. However, this approach might generate significant bias when the surrogate is insufficiently accurate around the posterior modes. To reduce the computational cost without sacrificing inferential accuracy, we propose Normalizing Flow with Adaptive Surrogate (NoFAS), an optimization strategy that alternatively updates the normalizing flow parameters and surrogate model parameters. We also propose an efficient sample weighting scheme for surrogate model training that preserves global accuracy while effectively capturing high posterior density regions. We demonstrate the inferential and computational superiority of NoFAS against various benchmarks, including cases where the underlying model lacks identifiability. The source code and numerical experiments used for this study are available at https://github.com/cedricwangyu/NoFAS.},
  keywords = {Adaptive surrogate modeling,Alternated gradient-based optimization,Memory-aware loss function,Normalizing flow,Variational inference},
  file = {/home/wouter/Zotero/storage/9HPA4IZ4/Wang, Liu, Schiavazzi - 2022 - Variational inference with NoFAS Normalizing flow with adaptive surrogate for computationally expensive m.pdf}
}

@article{wang2024,
  title = {Accelerating {{Data Generation}} for {{Neural Operators}} via {{Krylov Subspace Recycling}}},
  author = {Wang, Hong and Hao, Zhongkai and Wang, Jie and Geng, Zijie and Wang, Zhen and Li, Bin and Wu, Feng},
  year = {2024},
  pages = {1--40},
  abstract = {Learning neural operators for solving partial differential equations (PDEs) has attracted great attention due to its high inference efficiency. However, training such operators requires generating a substantial amount of labeled data, i.e., PDE problems together with their solutions. The data generation process is exceptionally time-consuming, as it involves solving numerous systems of linear equations to obtain numerical solutions to the PDEs. Many existing methods solve these systems independently without considering their inherent similarities, resulting in extremely redundant computations. To tackle this problem, we propose a novel method, namely Sorting Krylov Recycling (SKR), to boost the efficiency of solving these systems, thus significantly accelerating data generation for neural operators training. To the best of our knowledge, SKR is the first attempt to address the time-consuming nature of data generation for learning neural operators. The working horse of SKR is Krylov subspace recycling, a powerful technique for solving a series of interrelated systems by leveraging their inherent similarities. Specifically, SKR employs a sorting algorithm to arrange these systems in a sequence, where adjacent systems exhibit high similarities. Then it equips a solver with Krylov subspace recycling to solve the systems sequentially instead of independently, thus effectively enhancing the solving efficiency. Both theoretical analysis and extensive experiments demonstrate that SKR can significantly accelerate neural operator data generation, achieving a remarkable speedup of up to 13.9 times.},
  file = {/home/wouter/Zotero/storage/9NY8VLDQ/Wang et al. - 2024 - Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling.pdf}
}

@article{wathen2015,
  title = {Preconditioning},
  author = {Wathen, Andrew J.},
  year = {2015},
  month = may,
  journal = {Acta Numerica},
  volume = {24},
  number = {3},
  pages = {329--376},
  doi = {10.1017/S0962492915000021},
  abstract = {The computational solution of problems can be restricted by the availability of solution methods for linear(ized) systems of equations. In conjunction with iterative methods, preconditioning is often the vital component in enabling the solution of such systems when the dimension is large. We attempt a broad review of preconditioning methods.},
  keywords = {Cones of matrices,Gradient method,Minimal residual method,Preconditioning},
  file = {/home/wouter/Zotero/storage/FMMXNQBE/Wathen - 2015 - Preconditioning.pdf}
}

@article{weiszfeld1937,
  title = {Sur Le Point Pour Lequel La Somme Des Distances de n  Points Donnes Est Minimum},
  author = {Weiszfeld, Endre},
  year = {1937},
  journal = {Tohoku Mathematical Journal},
  volume = {43},
  pages = {355--386},
  file = {/home/wouter/Zotero/storage/7GYP8I4V/Weiszfeld - Weiszfeld.pdf}
}

@article{wiener1938,
  title = {The Homogeneous Chaos},
  author = {Wiener, Norbert},
  year = {1938},
  journal = {American Journal of Mathematics},
  volume = {60},
  number = {4},
  pages = {897--936},
  publisher = {JSTOR}
}

@inproceedings{xie2024,
  title = {Cost-Aware {{Bayesian}} Optimization via the {{Pandora}}'s {{Box Gittins}} Index},
  booktitle = {38th {{Conference}} on {{Neural Information Processing Systems}}},
  author = {Xie, Qian and Astudillo, Raul and Frazier, Peter and Scully, Ziv and Terenin, Alexander},
  year = {2024},
  eprint = {2406.20062},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-08-20},
  abstract = {Bayesian optimization is a technique for efficiently optimizing unknown functions in a black-box manner. To handle practical settings where gathering data requires use of finite resources, it is desirable to explicitly incorporate function evaluation costs into Bayesian optimization policies. To understand how to do so, we develop a previously-unexplored connection between cost-aware Bayesian optimization and the Pandora's Box problem, a decision problem from economics. The Pandora's Box problem admits a Bayesian-optimal solution based on an expression called the Gittins index, which can be reinterpreted as an acquisition function. We study the use of this acquisition function for cost-aware Bayesian optimization, and demonstrate empirically that it performs well, particularly in medium-high dimensions. We further show that this performance carries over to classical Bayesian optimization without explicit evaluation costs. Our work constitutes a first step towards integrating techniques from Gittins index theory into Bayesian optimization.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/BEPMDSXX/Xie et al. - 2024 - Cost-aware Bayesian optimization via the Pandora's Box Gittins index.pdf;/home/wouter/Zotero/storage/BYZQEIE8/2406.html}
}

@article{xiu2002,
  title = {Modeling Uncertainty in Steady State Diffusion Problems via Generalized Polynomial Chaos},
  author = {Xiu, Dongbin and Em Karniadakis, George},
  year = {2002},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {191},
  number = {43},
  pages = {4927--4948},
  doi = {10.1016/S0045-7825(02)00421-8},
  abstract = {We present a generalized polynomial chaos algorithm for the solution of stochastic elliptic partial differential equations subject to uncertain inputs. In particular, we focus on the solution of the Poisson equation with random diffusivity, forcing and boundary conditions. The stochastic input and solution are represented spectrally by employing the orthogonal polynomial functionals from the Askey scheme, as a generalization of the original polynomial chaos idea of Wiener [Amer. J. Math. 60 (1938) 897]. A Galerkin projection in random space is applied to derive the equations in the weak form. The resulting set of deterministic equations for each random mode is solved iteratively by a block Gauss-Seidel iteration technique. Both discrete and continuous random distributions are considered, and convergence is verified in model problems and against Monte Carlo simulations. {\copyright} 2002 Elsevier Science B.V. All rights reserved.},
  keywords = {Polynomial chaos,Random diffusion,Uncertainty},
  file = {/home/wouter/Zotero/storage/PCM6FBKK/Xiu, Em Karniadakis - 2002 - Modeling uncertainty in steady state diffusion problems via generalized polynomial chaos.pdf}
}

@article{xiu2005,
  title = {High-{{Order Collocation Methods}} for {{Differential Equations}} with {{Random Inputs}}},
  author = {Xiu, Dongbin and Hesthaven, Jan S.},
  year = {2005},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {27},
  number = {3},
  pages = {1118--1139},
  doi = {10.1137/040615201},
  abstract = {Recently there has been a growing interest in designing efficient methods for the solution of ordinary/partial differential equations with random inputs. To this end, stochastic Galerkin methods appear to be superior to other nonsampling methods and, in many cases, to several sampling methods. However, when the governing equations take complicated forms, numerical implementations of stochastic Galerkin methods can become nontrivial and care is needed to design robust and efficient solvers for the resulting equations. On the other hand, the traditional sampling methods, e.g., Monte Carlo methods, are straightforward to implement, but they do not offer convergence as fast as stochastic Galerkin methods. In this paper, a high-order stochastic collocation approach is proposed. Similar to stochastic Galerkin methods, the collocation methods take advantage of an assumption of smoothness of the solution in random space to achieve fast convergence. However, the numerical implementation of stochastic collocation is trivial, as it requires only repetitive runs of an existing deterministic solver, similar to Monte Carlo methods. The computational cost of the collocation methods depends on the choice of the collocation points, and we present several feasible constructions. One particular choice, based on sparse grids, depends weakly on the dimensionality of the random space and is more suitable for highly accurate computations of practical applications with large dimensional random inputs. Numerical examples are presented to demonstrate the accuracy and efficiency of the stochastic collocation methods. {\copyright} 2005 Society for Industrial and Applied Mathematics.},
  keywords = {Collocation methods,Differential equations,Stochastic inputs,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/ZGC9S6JY/Xiu, Hesthaven - 2005 - High-Order Collocation Methods for Differential Equations with Random Inputs.pdf}
}

@article{xiu2006,
  title = {Numerical Methods for Differential Equations in Random Domains},
  author = {Xiu, Dongbin and Tartakovsky, Daniel M.},
  year = {2006},
  journal = {SIAM Journal on Scientific Computing},
  volume = {28},
  number = {3},
  pages = {1167--1185},
  doi = {10.1137/040613160},
  abstract = {Physical phenomena in domains with rough boundaries play an important role in a variety of applications. Often the topology of such boundaries cannot be accurately described in all of its relevant detail due to either insufficient data or measurement errors or both. This topological uncertainty can be efficiently handled by treating rough boundaries as random fields, so that an underlying physical phenomenon is described by deterministic or stochastic differential equations in random domains. To deal with this class of problems, we propose a novel computational framework, which is based on using stochastic mappings to transform the original deterministic/stochastic problem in a random domain into a stochastic problem in a deterministic domain. The latter problem has been studied more extensively, and existing analytical/numerical techniques can be readily applied. In this paper, we employ both a stochastic Galerkin method and Monte Carlo simulations to solve the transformed stochastic problem. We demonstrate our approach by applying it to an elliptic problem in single- and double-connected random domains, and comment on the accuracy and convergence of the numerical methods. {\copyright} 2006 Society for Industrial and Applied Mathematics.},
  keywords = {Differential equations,Random domain,Stochastic inputs,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/RPXDKHAU/Xiu, Tartakovsky - 2006 - Numerical methods for differential equations in random domains.pdf}
}

@article{xiu2009,
  title = {Fast Numerical Methods for Stochastic Computations: {{A}} Review},
  author = {Xiu, Dongbin},
  year = {2009},
  journal = {Communications in Computational Physics},
  volume = {5},
  number = {2-4},
  pages = {242--272},
  abstract = {This paper presents a review of the current state-of-the-art of numerical methods for stochastic computations. The focus is on efficient high-order methods suitable for practical applications, with a particular emphasis on those based on generalized polynomial chaos (gPC) methodology. The framework of gPC is reviewed, along with its Galerkin and collocation approaches for solving stochastic equations. Properties of these methods are summarized by using results from literature. This paper also attempts to present the gPC based methods in a unified framework based on an extension of the classical spectral methods into multi-dimensional random spaces. {\copyright} 2009 Global-Science Press.},
  keywords = {Generalized polynomial chaos,Spectral methods,Stochastic differential equations,Uncertainty quantification},
  file = {/home/wouter/Zotero/storage/NUEDHMTX/Xiu - 2009 - Fast numerical methods for stochastic computations A review.pdf}
}

@incollection{xiu2015,
  title = {Stochastic {{Collocation Methods}}: {{A Survey}}},
  shorttitle = {Stochastic {{Collocation Methods}}},
  booktitle = {Handbook of {{Uncertainty Quantification}}},
  author = {Xiu, Dongbin},
  editor = {Ghanem, Roger and Higdon, David and Owhadi, Houman},
  year = {2015},
  pages = {1--18},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-11259-6_26-1},
  urldate = {2025-04-29},
  isbn = {978-3-319-11259-6},
  langid = {english},
  file = {/home/wouter/Zotero/storage/JQX8VFJK/Xiu - 2015 - Stochastic Collocation Methods A Survey.pdf}
}

@techreport{yakovlev2003,
  title = {Basics of Wavelets Transform},
  author = {Yakovlev, A. N.},
  year = {2003},
  volume = {1},
  number = {3},
  pages = {79--79},
  file = {/home/wouter/Zotero/storage/Z65TI3ZJ/Yakovlev - 2003 - Basics of wavelets transform.pdf}
}

@inproceedings{yang2005,
  title = {Unstructured {{Dynamic Meshes}} with {{Higher-order Time Integration Schemes}} for the {{Unsteady Navier-Stokes Equations}}},
  booktitle = {43rd {{AIAA Aerospace Sciences Meeting}} and {{Exhibit}}},
  author = {Yang, Zhi and Mavriplis, Dimitri},
  year = {2005},
  month = jan,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  address = {Reno, Nevada},
  doi = {10.2514/6.2005-1222},
  urldate = {2025-04-28},
  isbn = {978-1-62410-064-2},
  langid = {english}
}

@article{yaseen2013,
  title = {Exact Solutions of {{Laplace}} Equation by {{DJ}} Method},
  author = {Yaseen, M. and Samraiz, M. and Naheed, S.},
  year = {2013},
  journal = {Results in Physics},
  volume = {3},
  pages = {38--40},
  publisher = {Elsevier B.V.},
  issn = {3334386996},
  doi = {10.1016/j.rinp.2013.01.001},
  abstract = {In this paper, the iterative method developed by Daftardar-Gejji and Jafari (DJ method) is employed for analytic treatment of Laplace equation with Dirichlet and Neumann boundary conditions. The method is demonstrated by several physical models of Laplace equation. The obtained results show that the present approach is highly accurate and requires reduced amount of calculations compared with the existing iterative methods. {\copyright} 2013 The Authors.},
  keywords = {DJ Method,Laplace equation},
  file = {/home/wouter/Zotero/storage/RUUHZB5Q/Yaseen, Samraiz, Naheed - 2013 - Exact solutions of Laplace equation by DJ method.pdf}
}

@article{ye2023,
  title = {Data-Driven Reduced-Order Modelling for Blood Flow Simulations with Geometry-Informed Snapshots},
  author = {Ye, Dongwei and Krzhizhanovskaya, Valeria and Hoekstra, Alfons G.},
  year = {2023},
  pages = {1--19},
  abstract = {Computational fluid dynamics is a common tool in cardiovascular science and engineering to simulate, predict and study hemodynamics in arteries. However, owing to the complexity and scale of cardiovascular flow problems, the evaluation of the model could be computationally expensive, especially in those cases where a large number of evaluations are required, such as uncertainty quantification and design optimisation. In such scenarios, the model may have to be repeatedly evaluated due to the changes or distinctions of simulation domains. In this work, a data-driven surrogate model is proposed for the efficient prediction of blood flow simulations on similar but distinct domains. The proposed surrogate model leverages surface registration to parameterise those similar but distinct shapes and formulate corresponding hemodynamics information into geometry-informed snapshots by the diffeomorphism constructed between the reference domain and target domain. A non-intrusive reduced-order model for geometrical parameters is subsequently constructed using proper orthogonal decomposition, and a radial basis function interpolator is trained for predicting the reduced coefficients of the reduced-order model based on reduced coefficients of geometrical parameters of the shape. Two examples of blood flowing through a stenosis and a bifurcation are presented and analysed. The proposed surrogate model demonstrates its accuracy and efficiency in hemodynamics prediction and shows its potential application toward real-time simulation or uncertainty quantification for complex patient-specific scenarios.},
  keywords = {blood flow,computational fluid dynamics,parametric pde,reduced-order modelling,simulation,surface registration,surrogate modelling},
  file = {/home/wouter/Zotero/storage/P234TU9K/Ye, Krzhizhanovskaya, Hoekstra - 2023 - Data-driven reduced-order modelling for blood flow simulations with geometry-informed snapshots.pdf}
}

@misc{ye2024,
  title = {{{PDE-constrained Gaussian}} Process Surrogate Modeling with Uncertain Data Locations},
  author = {Ye, Dongwei and Yan, Weihao and Brune, Christoph and Guo, Mengwu},
  year = {2024},
  month = dec,
  number = {arXiv:2305.11586},
  eprint = {2305.11586},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.11586},
  urldate = {2025-05-12},
  abstract = {Gaussian process regression is widely applied in computational science and engineering for surrogate modeling owning to its kernel-based and probabilistic nature. In this work, we propose a Bayesian approach that integrates the variability of input data into the Gaussian process regression for function and partial differential equation approximation. Leveraging two types of observables -- noise-corrupted outputs with certain inputs and those with prior-distribution-defined uncertain inputs, a posterior distribution of uncertain inputs is estimated via Bayesian inference. Thereafter, such quantified uncertainties of inputs are incorporated into Gaussian process predictions by means of marginalization. The setting of two types of data aligned with common scenarios of constructing surrogate models for the solutions of partial differential equations, where the data of boundary conditions and initial conditions are typically known while the data of solution may involve uncertainties due to the measurement or stochasticity. The effectiveness of the proposed method is demonstrated through several numerical examples including multiple one-dimensional functions, the heat equation and Allen-Cahn equation. A consistently good performance of generalization is observed, and a substantial reduction in the predictive uncertainties is achieved by the Bayesian inference of uncertain inputs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computational Engineering Finance and Science,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/wouter/Zotero/storage/E7F9Q4J5/Ye et al. - 2024 - PDE-constrained Gaussian process surrogate modeling with uncertain data locations.pdf;/home/wouter/Zotero/storage/AYYFFD4B/2305.html}
}

@article{zahm2016,
  title = {Interpolation of Inverse Operators for Preconditioning Parameter-Dependent Equations},
  author = {Zahm, Olivier and Nouy, Anthony},
  year = {2016},
  journal = {SIAM Journal on Scientific Computing},
  volume = {38},
  number = {2},
  pages = {A1044-A1074},
  doi = {10.1137/15M1019210},
  abstract = {We propose a method for the construction of preconditioners of parameter-dependent matrices for the solution of large systems of parameter-dependent equations. The proposed method is an interpolation of the matrix inverse based on a projection of the identity matrix with respect to the Frobenius norm. Approximations of the Frobenius norm using random matrices are introduced in order to handle large matrices. The resulting statistical estimators of the Frobenius norm yield quasi- optimal projections that are controlled with high probability. Strategies for the adaptive selection of interpolation points are then proposed for dierent objectives in the context of projection-based model order reduction methods: the improvement of residual-based error estimators, the improve- ment of the projection on a given reduced approximation space, and the reuse of computations for sampling-based model order reduction methods.},
  keywords = {Empirical interpolation,Parameter-dependent equations,Preconditioning,Projection-based model order reduction,Random matrices,Reduced basis},
  file = {/home/wouter/Zotero/storage/RWPRSEUV/Zahm, Nouy - 2016 - Interpolation of inverse operators for preconditioning parameter-dependent equations.pdf}
}

@article{zanjanifoumani2023,
  title = {Multi-Fidelity Cost-Aware {{Bayesian}} Optimization},
  author = {Zanjani Foumani, Zahra and Shishehbor, Mehdi and Yousefpour, Amin and Bostanabad, Ramin},
  year = {2023},
  month = mar,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {407},
  pages = {115937},
  issn = {00457825},
  doi = {10.1016/j.cma.2023.115937},
  urldate = {2024-09-24},
  langid = {english},
  file = {/home/wouter/Zotero/storage/TKA58U5W/Zanjani Foumani et al. - 2023 - Multi-fidelity cost-aware Bayesian optimization.pdf;/home/wouter/Zotero/storage/UVTIF862/1-s2.0-S0045782523000609-mainext.pdf}
}

@phdthesis{zech2018,
  title = {Sparse-{{Grid Approximation}} of {{High-Dimensional Parametric PDEs}}},
  author = {Zech, Jakob},
  year = {2018},
  number = {25683},
  doi = {10.3929/ethz-b-000340651},
  isbn = {9783906916552},
  school = {ETH Z{\"u}rich},
  file = {/home/wouter/Zotero/storage/SNIGT7M4/Zech - 2018 - Sparse-Grid Approximation of High-Dimensional Parametric PDEs.pdf}
}

@article{zech2020,
  title = {Convergence Rates of High Dimensional {{Smolyak}} Quadrature},
  author = {Zech, Jakob and Schwab, Christoph},
  year = {2020},
  month = jul,
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  volume = {54},
  number = {4},
  pages = {1259--1307},
  doi = {10.1051/m2an/2020003},
  abstract = {We analyse convergence rates of Smolyak integration for parametric maps u : U {$\rightarrow$} X taking values in a Banach space X , defined on the parameter domain U = [-1,1] N . For parametric maps which are sparse, as quantified by summability of their Taylor polynomial chaos coefficients, dimension-independent convergence rates superior to N -term approximation rates under the same sparsity are achievable. We propose a concrete Smolyak algorithm to a priori identify integrand-adapted sets of active multiindices (and thereby unisolvent sparse grids of quadrature points) via upper bounds for the integrands' Taylor gpc coefficients. For so-called ``( b , {$\varepsilon$} )-holomorphic'' integrands u with b {$\in$} l p (/) for some p {$\in$} (0, 1), we prove the dimension-independent convergence rate 2/ p - 1 in terms of the number of quadrature points. The proposed Smolyak algorithm is proved to yield (essentially) the same rate in terms of the total computational cost for both nested and non-nested univariate quadrature points. Numerical experiments and a mathematical sparsity analysis accounting for cancellations in quadratures and in the combination formula demonstrate that the asymptotic rate 2/ p - 1 is realized computationally for a moderate number of quadrature points under certain circumstances. By a refined analysis of model integrand classes we show that a generally large preasymptotic range otherwise precludes reaching the asymptotic rate 2/ p - 1 for practically relevant numbers of quadrature points.},
  keywords = {Convergence rates of high dimensional Smolyak quad,Generalized polynomial chaos,Holomorphy,Smolyak quadrature,Sparsity},
  file = {/home/wouter/Zotero/storage/9RC2T823/Zech, Schwab - 2020 - Convergence rates of high dimensional Smolyak quadrature.pdf}
}

@article{zhou2014,
  title = {A {{Stochastic Collocation Method}} for {{Delay Differential Equations}} with {{Random Input}}},
  author = {Zhou, Tao},
  year = {2014},
  month = aug,
  journal = {Advances in Applied Mathematics and Mechanics},
  volume = {6},
  number = {4},
  pages = {403--418},
  issn = {2070-0733, 2075-1354},
  doi = {10.4208/aamm.2012.m38},
  urldate = {2025-04-08},
  abstract = {Abstract             In this work, we concern with the numerical approach for delay differential equations with random coefficients. We first show that the exact solution of the problem considered admits good regularity in the random space, provided that the given data satisfy some reasonable assumptions. A stochastic collocation method is proposed to approximate the solution in the random space, and we use the Legendre spectral collocation method to solve the resulting deterministic delay differential equations. Convergence property of the proposed method is analyzed. It is shown that the numerical method yields the familiar exponential order of convergence in both the random space and the time space. Numerical examples are given to illustrate the theoretical results.},
  copyright = {https://www.cambridge.org/core/terms},
  langid = {english}
}

@article{zieniuk2021,
  title = {Interval Arithmetic in Modeling and Solving {{Laplace}}'s Equation Problems with Uncertainly Defined Boundary Shape},
  author = {Zieniuk, Eugeniusz and Kapturczak, Marta},
  year = {2021},
  journal = {Engineering Analysis with Boundary Elements},
  volume = {125},
  number = {February},
  pages = {110--123},
  publisher = {Elsevier Ltd},
  doi = {10.1016/j.enganabound.2021.01.016},
  abstract = {The paper presents the problem of modeling the uncertainty of the boundary shape in boundary problems (described by Laplace's equation) and proposes a method for solving so-defined problems. The uncertainty of the boundary shape is modeled using interval numbers. The interval coordinates of control points, defined using classical and directed interval arithmetic, are considered in this paper. However, because of some disadvantages of well-known interval arithmetic, the authors propose a modification of directed interval arithmetic. This arithmetic is also used in the proposed modification of the traditional parametric integral equation system (PIES) method (previously used for exactly defined problems) to solve so-defined problems. Control points of the appropriate curves, necessary to define the boundary shape, are directly included in the mathematical formalism of the mentioned method. The developed interval method is tested on problems of various shapes, modeled with linear and curvilinear segments. The correctness of the obtained solutions is verified using proposed alternative methods. The obtained solutions indicate a very high potential of the proposed method in solving problems with an uncertainly defined boundary shape.},
  keywords = {Boundary value problems,Interval arithmetic,Parametric integral equations system,Uncertainty modeling},
  file = {/home/wouter/Zotero/storage/HPIIUGH2/Zieniuk, Kapturczak - 2021 - Interval arithmetic in modeling and solving Laplace's equation problems with uncertainly defined boundary s.pdf}
}

@techreport{zotero-16,
  title = {The {{Laplacian}} in Stretched Polar Co-Ordinates and {{Applications}}},
  keywords = {and phrases,dirichlet problem,laplace equation,starlike domain},
  file = {/home/wouter/Zotero/storage/9S4BR892/Unknown - Unknown - The Laplacian in stretched polar co-ordinates and Applications.pdf}
}

@phdthesis{zotero-175,
  title = {Numerical Ranges of Linear Pencils.Pdf},
  file = {/home/wouter/Zotero/storage/M3UI8YPE/Unknown - Unknown - Numerical ranges of linear pencils.pdf.pdf}
}

@article{zotero-560,
  title = {2007\_{{Book}}\_{{NumericalMathematics-1}}.Pdf},
  file = {/home/wouter/Zotero/storage/GLRWCJ94/Unknown - Unknown - 2007_Book_NumericalMathematics-1.pdf.pdf}
}

@article{zotero-683,
  title = {({{Applied Mathematical Sciences}} 115) {{Michael E}}},
  file = {/home/wouter/Zotero/storage/7XHJKW38/Unknown - Unknown - (Applied Mathematical Sciences 115) Michael E.djvu}
}

@article{zubeldia2012,
  title = {Energy Concentration and Explicit {{Sommerfeld}} Radiation Condition for the Electromagnetic {{Helmholtz}} Equation},
  author = {Zubeldia, Miren},
  year = {2012},
  journal = {Journal of Functional Analysis},
  volume = {263},
  number = {9},
  pages = {2832--2862},
  publisher = {Elsevier Inc.},
  doi = {10.1016/j.jfa.2012.08.014},
  abstract = {We study the electromagnetic Helmholtz equation. (∇;+ib(x)) 2u(x)+n(x)u(x)=f(x),x{$\in$}R d, with the magnetic vector potential b(x) and n(x) a variable index of refraction that does not necessarily converge to a constant at infinity, but can have an angular dependence like n(x){$\rightarrow$}n{$\infty$}(x{\textbar}x{\textbar}) as {\textbar}x{\textbar}{$\rightarrow$} {$\infty$}. We prove an explicit Sommerfeld radiation condition for solutions obtained from the limiting absorption principle and we also give a new energy estimate, which explains the main physical effect of the angular dependence of n at infinity and deduces that the energy concentrates in the directions given by the critical points of the potential. {\copyright} 2012 Elsevier Inc.},
  keywords = {Energy concentration,Helmholtz equation,Magnetic potential,Sommerfeld condition},
  file = {/home/wouter/Zotero/storage/U6RWBG93/Zubeldia - 2012 - Energy concentration and explicit Sommerfeld radiation condition for the electromagnetic Helmholtz equation.pdf}
}
